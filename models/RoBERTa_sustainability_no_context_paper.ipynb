{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ex_4NNmtMT2",
        "outputId": "d5f682b5-babf-44ff-bc5b-9d2539dbb0c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 90.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 72.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n",
            "\u001b[K     |████████████████████████████████| 306 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 73.2 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 82.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 79.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.10)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 64.5 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 69.1 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 77.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.2.0 fsspec-2022.1.0 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n",
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install pytorch-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Utm8lRFa7Tdt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import  DataLoader\n",
        "from torchcrf import CRF\n",
        "\n",
        "import transformers\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import RobertaTokenizer \n",
        "from transformers.models.roberta import RobertaModel\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_metric\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9kckp85tQGY",
        "outputId": "a8c5b02e-9b79-44e8-afb0-6d441eabdbd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI3EsaCQicd8",
        "outputId": "d6eb86a9-6b06-43d3-9dd7-26d46868903d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "%cd /content/drive/MyDrive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chQJjqSw7Tdu",
        "outputId": "aebd6231-6340-4c99-da64-b4ae64cabb06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "print(use_cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TR1-pIFXtB9t"
      },
      "outputs": [],
      "source": [
        "# Create list of training data files\n",
        "def load_from_directory(directory):\n",
        "    \"\"\"\n",
        "    Utility function to load all json-converted reports into a dataset.\n",
        "    params: directory: string representing location on disk of json files\n",
        "    returns: dataset: list of deserialised jsons\n",
        "    \"\"\"\n",
        "    path = os.getcwd()\n",
        "    path = os.path.join(path, directory)\n",
        "    json_files = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')]\n",
        "\n",
        "    dataset = [] \n",
        "\n",
        "    for filename in json_files: \n",
        "        with open(path+filename, \"r\", encoding='utf-8') as read_file:\n",
        "            dataset.append(json.load(read_file))\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "train_folder = 'json_train/'\n",
        "train_dataset = load_from_directory(train_folder)\n",
        "\n",
        "dev_folder = 'json_develop/'\n",
        "development_dataset = load_from_directory(dev_folder)\n",
        "\n",
        "test_folder = 'json_test/'\n",
        "test_dataset = load_from_directory(test_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xG-4ESe7tB9u"
      },
      "outputs": [],
      "source": [
        "def filter_dataset(input_dataset):\n",
        "    \"\"\" \n",
        "    Utility function to convert input dataset into custom data structure\n",
        "    params: input_dataset: list of deserialised jsons\n",
        "    returns: dictionary with the following structure:\n",
        "            key:  sentence_global_idx value , value:list of dictionaries\n",
        "            dict0: key: report_no, value: int \n",
        "            dict1: key: text, value: string\n",
        "            dict2: key: has_initiative, value: boolean\n",
        "            dict3: key: list_of_initiatives, value: list of strings with initiative IDs\n",
        "            dict4: key: sector, value: list of strings\n",
        "            dict5: key: sdg, value: list of sgd strings (representing sgd number)\n",
        "            dict6: key: sentence_length, value: int  \n",
        "    \"\"\"\n",
        "    structured_data = {}\n",
        "    total_no_reports = len(input_dataset)\n",
        "    sentence_global_idx = 0\n",
        "    re_punctuation_string = '[“”|()%&\\s,_:;/\\'!?-]'\n",
        "\n",
        "    for report_no in range(total_no_reports): \n",
        "        no_sentences_per_report = len(input_dataset[report_no]['tokenised_sentences'])\n",
        "        for sentence_no in range(no_sentences_per_report):\n",
        "            tokenized_sentence = re.split(re_punctuation_string, input_dataset[report_no]['tokenised_sentences'][sentence_no]['text'])\n",
        "            tokenized_sentence = list(filter(None, tokenized_sentence))\n",
        "            if (len(tokenized_sentence) == 0):           \n",
        "                continue\n",
        "            else:\n",
        "                structured_data[sentence_global_idx] = []\n",
        "                structured_data[sentence_global_idx].append({'report_no':report_no}) \n",
        "                structured_data[sentence_global_idx].append({'text':' '.join([elem.lower() for elem in tokenized_sentence])})\n",
        "                if len(input_dataset[report_no]['tokenised_sentences'][sentence_no]['initiative_ids']) > 0:\n",
        "                  structured_data[sentence_global_idx].append({'has_initiative':1})\n",
        "                else:\n",
        "                   structured_data[sentence_global_idx].append({'has_initiative':0})\n",
        "                structured_data[sentence_global_idx].append({'list_of_initiatives': input_dataset[report_no]['tokenised_sentences'][sentence_no]['initiative_ids']}) \n",
        "                \n",
        "                structured_data[sentence_global_idx].append({'sentence_length':len(tokenized_sentence)}) \n",
        "                sentence_global_idx +=1\n",
        "    \n",
        "    return structured_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rqb_rDqdtB9w"
      },
      "outputs": [],
      "source": [
        "# Set up datasets from json files\n",
        "training_data = filter_dataset(train_dataset)\n",
        "development_data = filter_dataset(development_dataset)\n",
        "testing_data = filter_dataset(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uJ2h2bUHtB9y"
      },
      "outputs": [],
      "source": [
        "def assisted_labelling(data, lower_threshold, upper_threshold):\n",
        "    \"\"\"\n",
        "    Utility function which labels all sentences with fewer than the threshold number of tokens as not having a sustainability initiative.\n",
        "    params: data: list of dictionaries\n",
        "            threshold: int representing number of tokens\n",
        "    returns: dictionary {global_sentence_index:boolean label}\n",
        "    \"\"\"\n",
        "    labeled_dataset = {}\n",
        "    for sentence_no in range(len(data)):\n",
        "        tokenized_sentence = re.split(' ', data[sentence_no][1]['text'])\n",
        "        tokenized_sentence_with_alphabetical_chars = [word for word in tokenized_sentence if re.search('[a-zA-Z]', word)]\n",
        "        if (data[sentence_no][4]['sentence_length'] > lower_threshold) & (len(tokenized_sentence_with_alphabetical_chars)!=0) & (data[sentence_no][4]['sentence_length']<upper_threshold):\n",
        "            labeled_dataset[sentence_no] = 1 \n",
        "        else:\n",
        "            labeled_dataset[sentence_no] = 0 # label short, long and non-alphabetical sentences as not having an initiative\n",
        "    return labeled_dataset\n",
        "\n",
        "assistant_labeled_training_data = assisted_labelling(training_data,lower_threshold=5, upper_threshold=100)\n",
        "assistant_labeled_dev_data = assisted_labelling(development_data,lower_threshold=5, upper_threshold=100)\n",
        "assistant_labeled_test_data = assisted_labelling(testing_data, lower_threshold=5, upper_threshold=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Lq_Q9UCl33gd"
      },
      "outputs": [],
      "source": [
        "def reader(dataset, assisted_labels, initiative_dict):\n",
        "    \"\"\"\n",
        "    Utility function read in the data together with assisted labels and return a train dictionary and a pre-labelled dictionary.\n",
        "    params: dataset: dict {global_sentence_index : list of 7 dictionaries}\n",
        "            assisted_labels: dict {global_sentence_index : assistant label}\n",
        "    returns: train_dict: dict\n",
        "             pre_labelled_dict\n",
        "    \"\"\"\n",
        "    texts = []\n",
        "    labels = []\n",
        "    positions = []\n",
        "    initiative_IDs = []\n",
        "    report_no = []\n",
        "    \n",
        "    pre_labeled_texts =[]\n",
        "    pre_labeled_labels =[]\n",
        "    pre_labeled_positions =[]\n",
        "    pre_labeled_IDs = []\n",
        "\n",
        "    for sentence_no in range(len(dataset)):\n",
        "        if assisted_labels[sentence_no] == 1:\n",
        "            report_no.append(dataset[sentence_no][0]['report_no'])\n",
        "            texts.append(dataset[sentence_no][1]['text'])\n",
        "            if dataset[sentence_no][3]['list_of_initiatives']: #check whether the sentence has an initiative\n",
        "              initiative_unique_reference = dataset[sentence_no][3]['list_of_initiatives'][0] + '_' + str(dataset[sentence_no][0]['report_no'])\n",
        "              if len(initiative_dict[initiative_unique_reference]) == 1:\n",
        "                labels.append(dataset[sentence_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "              elif initiative_dict[initiative_unique_reference].index(sentence_no) == 0:\n",
        "                labels.append(2) #append 2 for beginning of initiative\n",
        "              elif initiative_dict[initiative_unique_reference].index(sentence_no) == (len(initiative_dict[initiative_unique_reference]) - 1):\n",
        "                labels.append(4) #append 4 for end of initiative\n",
        "              else:\n",
        "                labels.append(3) #append 3 for inside an initiative\n",
        "            else:\n",
        "              labels.append(dataset[sentence_no][2]['has_initiative'])\n",
        "            positions.append(sentence_no)\n",
        "            initiative_IDs.append(dataset[sentence_no][3]['list_of_initiatives'])\n",
        "        else:\n",
        "            pre_labeled_texts.append(dataset[sentence_no][1]['text'])\n",
        "            pre_labeled_labels.append(assisted_labels[sentence_no]) # append 0 for non-initiative sentences\n",
        "            pre_labeled_positions.append(sentence_no)\n",
        "            pre_labeled_IDs.append(dataset[sentence_no][3]['list_of_initiatives'])\n",
        "\n",
        "    actual_data_dict = {'texts':texts, 'labels':labels, 'positions':positions, 'ID_list':initiative_IDs, 'report_no':report_no}\n",
        "    pre_labeled_dict = {'texts':pre_labeled_texts, 'labels':pre_labeled_labels, 'positions': pre_labeled_positions, 'ID_list':pre_labeled_IDs}\n",
        "            \n",
        "    return actual_data_dict, pre_labeled_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FrxI7zhZzd_I"
      },
      "outputs": [],
      "source": [
        "def context_builder(data_dict, left_context_size = 0, right_context_size = 0):\n",
        "    context = []\n",
        "    multi_sentence_labels = []\n",
        "    for sentence_index in range(len(data_dict['texts'])):\n",
        "        sentence_context = []\n",
        "        sentence_context_labels = []\n",
        "        if (sentence_index - left_context_size >= 0) and (sentence_index + right_context_size < len(data_dict['texts'])):\n",
        "            # test if target sentence is in the middle of the corpus\n",
        "            for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                if data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]:\n",
        "                    sentence_context.append(data_dict['texts'][context_index])\n",
        "                    sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        elif sentence_index - left_context_size >= 0: #if target sentence is at end of the corpus \n",
        "            for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                if context_index < len(data_dict['texts']): # add in a smaller context window at end of the corpus\n",
        "                    if (data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]):\n",
        "                        sentence_context.append(data_dict['texts'][context_index])\n",
        "                        sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        elif sentence_index + right_context_size < len(data_dict['texts']): #if target sentence is at beginning of the corpus \n",
        "                for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                    if context_index >= 0: # add in smaller context window at the beginning of the corpus\n",
        "                        if (data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]):\n",
        "                            sentence_context.append(data_dict['texts'][context_index])\n",
        "                            sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        context.append(sentence_context)\n",
        "        while len(sentence_context_labels) < (1 + left_context_size + right_context_size): # pad with 0 labels for senteces with a smaller context eg. beginning/end of docs\n",
        "          sentence_context_labels.append(0)\n",
        "        multi_sentence_labels.append(sentence_context_labels)\n",
        "    return context, multi_sentence_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9D9lIa3R6cRb"
      },
      "outputs": [],
      "source": [
        "class SustainableDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Dataset class inheriting from pytorch to be used by dataloaders.\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer, input_set, input_context, input_multi_sentence_labels, max_paragraph_length, global_target_sentence_index):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = input_set['texts']\n",
        "        self.labels = input_set['labels']\n",
        "        self.report_nos = input_set['report_no']\n",
        "        self.contexts = input_context\n",
        "        self.context_labels = input_multi_sentence_labels\n",
        "        self.max_paragraph_length = max_paragraph_length\n",
        "        self.global_target_sentence_index = global_target_sentence_index\n",
        "        \n",
        "        \n",
        "    def collate_fn(self, batch):\n",
        "        texts = [b['text'] for b in batch]\n",
        "        labels = [b['label'] for b in batch]\n",
        "        contexts = [b['context'] for b in batch]\n",
        "        context_labels = [b['context_label'] for b in batch]\n",
        "        encodings, sep_positions = self.custom_tokenizer(batch = contexts) \n",
        "        encodings['labels'] =  torch.tensor(context_labels) # pass through labels for all sentences\n",
        "        encodings['sep_positions'] = sep_positions\n",
        "        return encodings\n",
        "    \n",
        "    def custom_collate_fn(self, batch):\n",
        "      texts = [b['text'] for b in batch]\n",
        "      labels = [b['label'] for b in batch]\n",
        "      contexts = [b['context'] for b in batch]\n",
        "      context_labels = [b['context_label'] for b in batch]\n",
        "      return {'texts':texts, 'labels':labels, 'contexts':contexts, 'context_labels':context_labels}\n",
        "    \n",
        "\n",
        "    def custom_tokenizer(self, batch):\n",
        "      \"\"\" Utility functions to tokenize a list of sentences using [SEP] at the beginning of each sentence with fixed positions.\n",
        "      \"\"\"\n",
        "      batch_sequences = []\n",
        "      batch_sep_positions = []\n",
        "      for sequence_list in batch:\n",
        "        augmented_sequence = ' '\n",
        "        for sentence in sequence_list:     \n",
        "          if sentence != sequence_list[-1]:\n",
        "                augmented_sequence += sentence + ' </s> '\n",
        "          else:\n",
        "            augmented_sequence += sentence\n",
        "        batch_sequences.append(augmented_sequence)\n",
        "      encoded_batch = self.tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt')\n",
        "      for encoded_sequence in encoded_batch['input_ids']:\n",
        "          sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==2]\n",
        "          while len(sep_positions) < self.max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "            sep_positions.append(sep_positions[-1])\n",
        "          batch_sep_positions.append(sep_positions)\n",
        "       \n",
        "      return encoded_batch, batch_sep_positions\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {'text': self.texts[idx],\n",
        "                'label': self.labels[idx],\n",
        "                'context': self.contexts[idx],\n",
        "                'context_label' : self.context_labels[idx],\n",
        "                }\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U9odLvcadGWg"
      },
      "outputs": [],
      "source": [
        "def get_sep_positions(data_loader, global_target_sentence_index, max_paragraph_length, tokenizer):\n",
        "  \"\"\" Utility function to get sep positions for given dataset.\n",
        "  \"\"\"\n",
        "  dataset_sep_positions = []\n",
        "  for batch in data_loader:\n",
        "      batch_sep_positions = []\n",
        "      batch_sequences = []\n",
        "      for sequence_list in batch['contexts']:\n",
        "        augmented_sequence = ' '\n",
        "        for sentence in sequence_list:\n",
        "            if sentence != sequence_list[-1]:\n",
        "              augmented_sequence += sentence + ' </s> '\n",
        "            else:\n",
        "              augmented_sequence += sentence\n",
        "        batch_sequences.append(augmented_sequence)\n",
        "      encoded_batch = tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt')\n",
        "      for encoded_sequence in encoded_batch['input_ids']:\n",
        "          sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==2]\n",
        "          while len(sep_positions) < max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "            sep_positions.append(sep_positions[-1])\n",
        "          batch_sep_positions.append(sep_positions)\n",
        "      dataset_sep_positions.extend([sublist[:-1] for sublist in batch_sep_positions]) \n",
        "  return dataset_sep_positions\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "r92owFJgsoJV"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary with ID_reportNo as keys and values as list of sentence indices\n",
        "def create_init_dict(data):\n",
        "    \"\"\" Utility function to extract individual initiatives as keys of a dict and a list of corresponding global sentence indices.\n",
        "    \"\"\"\n",
        "    initiative_dict = {} #keys are initiative IDs, values are counts of IDs \n",
        "    for sentence_no in range(len(data)):\n",
        "        if data[sentence_no][2]['has_initiative']:\n",
        "            initiative_ID = data[sentence_no][3]['list_of_initiatives'][0]\n",
        "            if (initiative_ID + '_' + str(data[sentence_no][0]['report_no'])) not in initiative_dict.keys():\n",
        "                initiative_dict[initiative_ID + '_' + str(data[sentence_no][0]['report_no'])] = [sentence_no]\n",
        "            else:\n",
        "                initiative_dict[initiative_ID + '_' + str(data[sentence_no][0]['report_no'])].append(sentence_no)\n",
        "    return initiative_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "cc0ae3d1d1784bbf9ccfeee1b2d7c32e",
            "892f07cc4ec34cd8b1179dac3aad19c6",
            "25fd27de662648d9b4b396dd589f76b9",
            "e70db47d39e840b2b9144a791eff55cd",
            "7f1f5d6c69854a65909afe54fee11c30",
            "c795550bcf4c4057acd1109b8b3b624c",
            "440db1a025d74937859a7babb34cafba",
            "8ec6c6653f4c4e6c9bde0a44728a57d5",
            "e981ddc9ccd14d8c9e9771f72e30a4ce",
            "b8004b8ecfca419e8cf712bc22ffa3db",
            "ac511cc118c14182a2a183be784de833",
            "71aa567296244787abd6bfc243fa63f6",
            "a2664555b4bf4391b51d5b50aa10b7c7",
            "4f4a2644378d4b3a9f786516516fd468",
            "4069cd427b044d0dbb4750807c9ebf01",
            "8bca407b20984b2c889c236e80f90210",
            "2cf2038e854948c5a274b4085d9cf79d",
            "8cb89aa45f644d2b809438146bdb7f7e",
            "cba47935080c4c6e869c4e4b0f3654e7",
            "40690a5d7c3844aa85fdeb150cd4b63c",
            "d18bab00e8b943aa89426e8ac08956d9",
            "fe79e89e5849495d9d70e4476e866269",
            "72968ce778494a47a102a18dafac001c",
            "819b8b3337714947b3771b612d45f5f7",
            "e09a32ed2fd34a9faa5dda693e72d272",
            "4787a4555cfe40afb58e6fb89ea24b05",
            "9718b62b853f4358a93f947118de28bc",
            "8626221f4a014eb788f970399f4aa771",
            "0dd3e6d802e748aaa227bd02cd7deedc",
            "53c3f5b3d5864b8faac8401dac314830",
            "5e27b638279743e7af9f109557fe519d",
            "d9d62ab6c7c44c4f8e0e7f788f7fa526",
            "03a109afcb0b40289cc001c7d667389e",
            "5235a0a7e141469eadfbdbad3984661b",
            "7b3478a473774f738fd300bda90ad76c",
            "edf22710fffc4a548f64c5d9a0d2e5a9",
            "3590dc234ba347c89e146ed8bc00158e",
            "eb9469a6ff484f78ab78f00df8b05e62",
            "4458934ee7ab433cae31b441f0c04065",
            "03a0f8eae9db472b9ce82042ca87f3a5",
            "0235aa83c32a4808b0459d8f35067289",
            "6c674033a2c94e4dabf094c3dbcfabef",
            "373875de968843b7ab7c089fee24b8dc",
            "e68529aabc9f44b49c2e85af9cc176a1"
          ]
        },
        "id": "TyZQtXwj4ixr",
        "outputId": "d29fd715-fa16-414b-dc24-d7d6c159835f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc0ae3d1d1784bbf9ccfeee1b2d7c32e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71aa567296244787abd6bfc243fa63f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72968ce778494a47a102a18dafac001c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5235a0a7e141469eadfbdbad3984661b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "global_target_sentence_index = 0 \n",
        "\n",
        "# Create gold standard initiative dictionaries\n",
        "train_initiative_dict = create_init_dict(training_data)\n",
        "dev_initiative_dict = create_init_dict(development_data)\n",
        "test_initiative_dict = create_init_dict(testing_data)\n",
        "\n",
        "# Read in training and dev data and split into data to feed into the model and pre-labeled data\n",
        "train_data, pre_labeled_train_data = reader(training_data, assistant_labeled_training_data, train_initiative_dict)\n",
        "dev_data, pre_labeled_dev_data = reader(development_data, assistant_labeled_dev_data, dev_initiative_dict)\n",
        "test_data, pre_labeled_test_data = reader(testing_data, assistant_labeled_test_data, test_initiative_dict)\n",
        "\n",
        "# Construct context around each sentence per dataset\n",
        "train_context, train_multi_sentence_labels = context_builder(train_data, left_context_size = 0, right_context_size = 0) \n",
        "dev_context, dev_multi_sentence_labels = context_builder(dev_data, left_context_size = 0, right_context_size = 0) \n",
        "test_context, test_multi_sentence_labels = context_builder(test_data, left_context_size = 0, right_context_size = 0)\n",
        "\n",
        "max_paragraph_length = max([len(label_sequence) for label_sequence in train_multi_sentence_labels])\n",
        "\n",
        "# Only data to be fed into the model is built into datasets\n",
        "train_dataset = SustainableDataset(tokenizer, train_data, train_context, train_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "dev_dataset = SustainableDataset(tokenizer, dev_data, dev_context, dev_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "test_dataset = SustainableDataset(tokenizer, test_data, test_context, test_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "\n",
        "# Create train and dev dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, collate_fn = train_dataset.custom_collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False, collate_fn = dev_dataset.custom_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn = test_dataset.custom_collate_fn)\n",
        "\n",
        "# Record sep positions for dev dataset (to be used for early stopping during training)\n",
        "dev_sep_positions = get_sep_positions(dev_loader, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "N-KwKMBsULGd"
      },
      "outputs": [],
      "source": [
        "# Unit tests for building context assuming a window\n",
        "mock_train_context, mock_train_multi_sentence_labels = context_builder(train_data, left_context_size = 1, right_context_size = 1)\n",
        "mock_dev_context, mock_dev_multi_sentence_labels = context_builder(dev_data, left_context_size = 1, right_context_size = 1)\n",
        "mock_train_dataset = SustainableDataset(tokenizer, train_data, mock_train_context, mock_train_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "mock_dev_dataset = SustainableDataset(tokenizer, dev_data, mock_dev_context, mock_dev_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "assert mock_train_dataset.contexts[11] == [mock_train_dataset.texts[10], mock_train_dataset.texts[11], mock_train_dataset.texts[12]]  #random corpus context\n",
        "assert len(mock_train_dataset.contexts) == len(mock_train_dataset.texts) #there is a context for every target sentence in the train set\n",
        "assert mock_dev_dataset.contexts[11] == [mock_dev_dataset.texts[10], mock_dev_dataset.texts[11], dev_dataset.texts[12]] #random corpus context\n",
        "assert len(mock_dev_dataset.contexts) == len(mock_dev_dataset.texts) #there is a context for every target sentence in the dev set\n",
        "assert [mock_train_dataset.texts[0], mock_train_dataset.texts[1] , mock_train_dataset.texts[2]] ==  mock_train_dataset.contexts[1] #the context for the first sentence in the corpus is only the following sentence\n",
        "assert [mock_train_dataset.texts[-2] , mock_train_dataset.texts[-1]] == mock_train_dataset.contexts[-1] #the context for the last sentence in the corpus is only the preceding sentence\n",
        "assert [mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)] , mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)+1]]== mock_train_dataset.contexts[mock_train_dataset.report_nos.index(1)] # first sentence of second report should have a context of only its following sentence\n",
        "assert [mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)-2], mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)-1]] == mock_train_dataset.contexts[mock_train_dataset.report_nos.index(1)-1] # last sentence of first report should have a context of only its preceding sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5Fyf-E4gtB90"
      },
      "outputs": [],
      "source": [
        "# Unit tests -> check if assisted data labelling has been performed correctly\n",
        "assert len(set(pre_labeled_train_data['positions']).intersection(set(train_data['positions']))) == 0 \n",
        "assert (len(train_data['texts']) + len(pre_labeled_train_data['texts'])) == len(training_data)\n",
        "assert set(pre_labeled_train_data['positions']).union(set(train_data['positions'])) == set(range(len(training_data)))\n",
        "assert (len(dev_data['texts']) + len(pre_labeled_dev_data['texts'])) == len(development_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NUOfidVU_zE8"
      },
      "outputs": [],
      "source": [
        "class Sustainable_RoBERTa(RobertaModel):\n",
        "    \"\"\" Transformer model class with custom output layer for fine-tuning.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.roberta = RobertaModel(config)\n",
        "        self.projection = torch.nn.Sequential(torch.nn.Dropout(0.1), torch.nn.Linear(config.hidden_size, 5))              \n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_values=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,):\n",
        " \n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids, \n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        logits = self.projection(outputs.last_hidden_state) \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "O2aWTy5uAHGj"
      },
      "outputs": [],
      "source": [
        "class Trainer_Sustainable(Trainer):\n",
        "    \"\"\" Class inheriting from Trainer to configure loss function used.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "        crf_model,\n",
        "        model = None,\n",
        "        args = None,\n",
        "        data_collator = None,\n",
        "        train_dataset = None,\n",
        "        eval_dataset = None,\n",
        "        tokenizer = None,\n",
        "        model_init = None,\n",
        "        compute_metrics = None,\n",
        "        callbacks = None,\n",
        "        optimizers = (None, None),        \n",
        "        ):\n",
        "        super().__init__(model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\n",
        "        self.crf_model = crf_model\n",
        "\n",
        "    def compute_loss(self, model, inputs, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, return_outputs=False):\n",
        "\n",
        "        labels = inputs.pop('labels')\n",
        "        sep_positions = inputs.pop('sep_positions') # take all sep positions\n",
        "        outputs = model(**inputs)\n",
        "        batch_preds = []\n",
        "        for i, sentence_sep_positions in zip(range(outputs.shape[0]), sep_positions):\n",
        "          sentence_preds = []\n",
        "          for j in sentence_sep_positions:\n",
        "            sentence_preds.append(outputs[i,j])\n",
        "          batch_preds.append(torch.cat(sentence_preds[:-1])) #ignore last sep token as we don't predict from it\n",
        "\n",
        "        preds = torch.cat(batch_preds).reshape((-1, max_paragraph_length, 5)).permute(1,0,2)\n",
        "        labels = labels.permute(1,0)\n",
        " \n",
        "        loss = -1 * self.crf_model(preds, labels)\n",
        "        \n",
        "        if return_outputs: \n",
        "            return (loss, (loss, outputs)) \n",
        "        else:\n",
        "            return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oxRyedCktB91"
      },
      "outputs": [],
      "source": [
        "def model_predict(model, tokenizer, dataloader, device, global_target_sentence_index, max_paragraph_length, crf_model):\n",
        "    \"\"\" Utility function to set the model to GPU and infer of given dataloader.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch_sequences = []\n",
        "            batch_sep_positions = []\n",
        "            for sequence_list in batch['contexts']:\n",
        "              augmented_sequence = ' '\n",
        "              for sentence in sequence_list:\n",
        "                if sentence != sequence_list[-1]:\n",
        "                  augmented_sequence += sentence + ' </s> '\n",
        "                else:\n",
        "                  augmented_sequence += sentence\n",
        "              batch_sequences.append(augmented_sequence)\n",
        "            encoded_batch = tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt').to(device)\n",
        "            for encoded_sequence in encoded_batch['input_ids']:\n",
        "                sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==2]\n",
        "                while len(sep_positions) < max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "                  sep_positions.append(sep_positions[-1])\n",
        "                batch_sep_positions.append(sep_positions)\n",
        "                      \n",
        "            output = model(**encoded_batch) \n",
        "            batch_preds = []\n",
        "            \n",
        "            for i, sentence_sep_positions in zip(range(output.shape[0]), batch_sep_positions):\n",
        "              sentence_preds = []\n",
        "              for j in sentence_sep_positions:\n",
        "                sentence_preds.append(output[i,j])\n",
        "              batch_preds.append(torch.cat(sentence_preds[:-1])) #ignore last sep token as we don't predict from it\n",
        "\n",
        "            preds = torch.cat(batch_preds).reshape((-1, max_paragraph_length, 5)).permute(1,0,2)\n",
        "            predicted_tags = [tag[global_target_sentence_index] for tag in crf_model.decode(preds)]\n",
        "            predictions.extend(predicted_tags)\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d73aad96771043a29104e17f1a090905",
            "e5ebb6c1839f4ffdb0dbb816ce70c36a",
            "e07e80f977ac402eaab805d59df76903",
            "2a3508d60bf6468a8d6d44b14b1b1fa4",
            "a25b99ca6a294ba6ab381d71b005a377",
            "160e1f903de74898a1b2a3247e2f091c",
            "7b0754bb9011402ab52d2f81b70a5af8",
            "dc6b80b648604cf2aa80a296efcde39d",
            "7a05cbd087644ae9b9e5a78c42abaefe",
            "c317eb5630c74d4d8da99261188d8e91",
            "c2b58a6150364345a00f361671b7d185",
            "59f02a9030a849eeb16a6a2578030d11",
            "1c7e64122b984a12a765feccbdf324bb",
            "1f58622244524f2ba45e7dbb5b9a9525",
            "10038b0e665d462fb6461e48bbe6448f",
            "1056addab44447c4b171511349763351",
            "e06e316dc62b4a0dafd0045c72011de2",
            "227a171d61e14108a97c0d4c29c3bc6d",
            "cfa0720eeadb484589fa540f711358a0",
            "77bcc373e68242dd9b620a4df314caea",
            "badfa61007124632b7db70d7dde2c227",
            "626a80e442a745ff97d650bc7ab39bac"
          ]
        },
        "id": "8MJmka-LAYIV",
        "outputId": "41deec06-3508-4a34-93b7-1759334d8389"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d73aad96771043a29104e17f1a090905",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing Sustainable_RoBERTa: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing Sustainable_RoBERTa from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Sustainable_RoBERTa from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Sustainable_RoBERTa were not initialized from the model checkpoint at roberta-base and are newly initialized: ['encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'projection.1.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'projection.1.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.self.value.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59f02a9030a849eeb16a6a2578030d11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 36920\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 23070\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23070' max='23070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23070/23070 1:05:09, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.739800</td>\n",
              "      <td>3.073979</td>\n",
              "      <td>0.204447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.815400</td>\n",
              "      <td>2.594097</td>\n",
              "      <td>0.273152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.442700</td>\n",
              "      <td>2.931637</td>\n",
              "      <td>0.297468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.105600</td>\n",
              "      <td>3.527941</td>\n",
              "      <td>0.307324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.812900</td>\n",
              "      <td>4.086094</td>\n",
              "      <td>0.328993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.570400</td>\n",
              "      <td>4.900525</td>\n",
              "      <td>0.324299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.360300</td>\n",
              "      <td>5.533994</td>\n",
              "      <td>0.329874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.176700</td>\n",
              "      <td>6.412498</td>\n",
              "      <td>0.323319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.005800</td>\n",
              "      <td>6.995834</td>\n",
              "      <td>0.325648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.843800</td>\n",
              "      <td>7.277067</td>\n",
              "      <td>0.323298</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-2307\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-2307/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-2307/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-4614\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-4614/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-4614/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-6921\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-6921/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-6921/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper_1_sent/checkpoint-2307] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-9228\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-9228/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-9228/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper_1_sent/checkpoint-4614] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-11535\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-11535/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-11535/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper_1_sent/checkpoint-6921] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-13842\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-13842/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-13842/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper_1_sent/checkpoint-9228] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-16149\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-16149/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-16149/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper_1_sent/checkpoint-11535] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-18456\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-18456/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-18456/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper_1_sent/checkpoint-13842] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-20763\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-20763/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-20763/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper_1_sent/checkpoint-18456] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper_1_sent/checkpoint-23070\n",
            "Configuration saved in ./roberta_paper_1_sent/checkpoint-23070/config.json\n",
            "Model weights saved in ./roberta_paper_1_sent/checkpoint-23070/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper_1_sent/checkpoint-20763] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./roberta_paper_1_sent/checkpoint-16149 (score: 0.32987351833128825).\n",
            "Saving model checkpoint to ./final_roberta_no_context_paper\n",
            "Configuration saved in ./final_roberta_no_context_paper/config.json\n",
            "Model weights saved in ./final_roberta_no_context_paper/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "# Instantiate and train model\n",
        "model = Sustainable_RoBERTa.from_pretrained('roberta-base').to(device)\n",
        "\n",
        "total_epochs = 10   \n",
        "learning_rate = 1e-5 \n",
        "\n",
        "# Create evaluation metric F1 score \n",
        "metric = load_metric('f1')\n",
        "\n",
        "def compute_metrics(eval_pred, sep_positions = dev_sep_positions, global_target_sentence_index = global_target_sentence_index):\n",
        "    raw_predictions, raw_labels = eval_pred \n",
        "    pooled_labels = [label[global_target_sentence_index] for label in raw_labels]\n",
        "    pooled_predictions = []\n",
        "    for i, sentence_sep_positions in zip(range(len(raw_predictions)), sep_positions):\n",
        "        sentence_preds = []\n",
        "        for j in sentence_sep_positions:\n",
        "            sentence_preds.append(torch.tensor(raw_predictions[i,j]))\n",
        "        pred = torch.cat(sentence_preds).reshape((-1, max_paragraph_length, 5)).permute(1,0,2).to(device)\n",
        "        predicted_tag = trainer.crf_model.decode(pred)[0][global_target_sentence_index] \n",
        "        pooled_predictions.append(predicted_tag)   \n",
        "    torch.save(trainer.crf_model, f='crf_RoBERTa_no_context_paper.pt')  # save trained crf model to use at inference time\n",
        "    return metric.compute(predictions=pooled_predictions, references=pooled_labels, average = 'macro')\n",
        "\n",
        "# Define optimizer and lr schedule\n",
        "optimizer = transformers.AdamW(model.parameters(),\n",
        "                  lr = learning_rate, \n",
        "                  )\n",
        "\n",
        "total_steps = len(train_loader) * total_epochs \n",
        "warmup = 0.06 * total_steps\n",
        " \n",
        "# Create the learning rate scheduler.\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup, \n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "# Create training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./roberta_paper_1_sent',\n",
        "    save_total_limit = 2,\n",
        "    learning_rate = learning_rate, \n",
        "    logging_strategy = 'epoch',\n",
        "    per_device_train_batch_size=8, \n",
        "    num_train_epochs = total_epochs, \n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    metric_for_best_model = 'f1',\n",
        "    eval_accumulation_steps=0.1*len(dev_loader),\n",
        "    gradient_accumulation_steps = 2, # effective training batch size of 16\n",
        "    )\n",
        "\n",
        "# Define trainer module\n",
        "trainer = Trainer_Sustainable(\n",
        "    model=model,                         \n",
        "    args=training_args,                 \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,                   \n",
        "    data_collator=train_dataset.collate_fn,\n",
        "    callbacks =[transformers.EarlyStoppingCallback(early_stopping_patience = 5, early_stopping_threshold=-0.03)],\n",
        "    compute_metrics = compute_metrics,\n",
        "    optimizers = (optimizer, scheduler),\n",
        "    crf_model = CRF(num_tags=5).to(device),\n",
        "    )\n",
        "\n",
        "trainer.train() \n",
        "\n",
        "trainer.save_model('./final_roberta_no_context_paper')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nqpGGvvisoJU"
      },
      "outputs": [],
      "source": [
        "def reconcile_mapping(model_data, pre_labeled_data, model_predictions):\n",
        "    \"\"\" Utility function to reconcile mapping between pre-labeled data and model predictions.\n",
        "    params: predictions: list of model predictions\n",
        "            pre_labeled_data: dictionary outputted from reader function\n",
        "    returns: pred_mapping: dict\n",
        "             predictions: dict\n",
        "    \"\"\"\n",
        "    pred_mapping = {}\n",
        "    for dataset_text, text_position, prediction in zip(model_data['texts'], model_data['positions'], model_predictions):\n",
        "        pred_mapping[text_position] = (dataset_text, prediction)\n",
        "\n",
        "    pre_labeled_mapping = {}\n",
        "    for text, pos, label in zip(pre_labeled_data['texts'], pre_labeled_data['positions'], pre_labeled_data['labels']):\n",
        "        pre_labeled_mapping[pos] = (text, label)\n",
        "\n",
        "\n",
        "    pred_mapping.update(pre_labeled_mapping)\n",
        "\n",
        "    pred_mapping = {k: v for k, v in sorted(pred_mapping.items(), key=lambda item: item[0])}\n",
        "\n",
        "    predictions =[element[1] for element in list(pred_mapping.values())] \n",
        "\n",
        "    return pred_mapping, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5i2N8mqKULGh"
      },
      "outputs": [],
      "source": [
        "# Create predictions dictionary spanning initiatives\n",
        "def sentence_to_initiative_aggregation(predictions, predictions_report_numbers):\n",
        "    \"\"\" Utility function which takes in a list of IOBES predictions per sentence and aggregates these into a dictionary of initiatives.\n",
        "    params: predictions: list of multi-class predictions\n",
        "    returns: predictions_dict: {initiative_number_report_number:list of sentence positions}\n",
        "    \"\"\"\n",
        "    predictions_dict = {}\n",
        "    initiative_index = 0\n",
        "    prediction_index = 0\n",
        "    while prediction_index < len(predictions):\n",
        "      if predictions[prediction_index] == 0: #no initiative\n",
        "        prediction_index += 1\n",
        "      elif predictions[prediction_index] == 1: #singleton\n",
        "        prediction_span = [prediction_index]\n",
        "        predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "        initiative_index += 1\n",
        "        prediction_index += 1\n",
        "      elif predictions[prediction_index] == 2: #beginning of initiative\n",
        "        if predictions[prediction_index + 1] == 4: # 2 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 2\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 4): #3 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 3\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 3) and (predictions[prediction_index + 3] == 4): #4 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2, prediction_index + 3]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 4\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 3) and (predictions[prediction_index + 3] == 3) and (predictions[prediction_index + 4] == 4): #5 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2, prediction_index + 3, prediction_index + 3]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 5\n",
        "        else:\n",
        "          prediction_span = [prediction_index]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 1\n",
        "      else: # all other initiative predictions which do not form a complete BIE structure are labeled as individual singletons\n",
        "        prediction_span = [prediction_index]\n",
        "        predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "        initiative_index += 1\n",
        "        prediction_index += 1\n",
        "\n",
        "    return predictions_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kncs_eEhsoJV"
      },
      "outputs": [],
      "source": [
        "class Initiative_Evaluation():\n",
        "    \"\"\" Class used to evaluate what % of initiatives have been correctly indentified.\n",
        "    \"\"\"\n",
        "    def __init__(self, initiative_dict, predictions_dict):\n",
        "        self.initiative_dict = initiative_dict\n",
        "        self.predictions_dict = predictions_dict\n",
        "        self.no_initiatives = len(self.initiative_dict)\n",
        "    \n",
        "    def evaluate(self):\n",
        "        if len(self.initiative_dict) == len(self.predictions_dict) == 0:\n",
        "            fully_correctly_labeled_proportion =  1\n",
        "            half_correctly_labeled_proportion = 1\n",
        "            min_correctly_labeled_proportion = 1\n",
        "            fully_correct_F1 = 1\n",
        "            half_correct_F1 = 1\n",
        "            min_correct_F1 = 1\n",
        "            return fully_correctly_labeled_proportion, half_correctly_labeled_proportion, min_correctly_labeled_proportion, fully_correct_F1, half_correct_F1, min_correct_F1\n",
        "        else:\n",
        "            # initiatize counters for true positive predictions\n",
        "            fully_correct_TP = 0\n",
        "            half_correct_TP = 0\n",
        "            min_correct_TP = 0\n",
        "            \n",
        "            # initialize lists which contain prediction IDs\\\n",
        "            #  for the first correct prediction encountered across all initatives\n",
        "            fully_correct_double_count = []\n",
        "            half_correct_double_count = []\n",
        "            min_correct_double_count = []\n",
        "\n",
        "            for initiative_ID, initiative_positions_list in self.initiative_dict.items():\n",
        "                # Keep a record of the first prediction id considered to be a success for each initiative\n",
        "                fully_correct_match_pred_ID = []\n",
        "                half_correct_match_pred_ID = []\n",
        "                min_correct_match_pred_ID = []\n",
        "                for prediction_ID, prediction_positions_list in self.predictions_dict.items():\n",
        "                    if set(initiative_positions_list).intersection(prediction_positions_list): #check if the initiative span overlaps with the predicted span\n",
        "                        if (len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) == 1)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) == 1):\n",
        "                                if (len(fully_correct_match_pred_ID) == 0) and (prediction_ID not in fully_correct_double_count): \n",
        "                                    fully_correct_match_pred_ID.append(prediction_ID)\n",
        "                                    fully_correct_TP += 1\n",
        "                        if(len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) >= 0.5)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) >= 0.5):\n",
        "                                if (len(half_correct_match_pred_ID) == 0) and (prediction_ID not in half_correct_double_count):\n",
        "                                    half_correct_match_pred_ID.append(prediction_ID)\n",
        "                                    half_correct_TP += 1\n",
        "                        if(len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) > 0)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) > 0):\n",
        "                                if (len(min_correct_match_pred_ID) == 0) and (prediction_ID not in min_correct_double_count): \n",
        "                                        min_correct_match_pred_ID.append(prediction_ID)\n",
        "                                        min_correct_TP += 1\n",
        "                fully_correct_double_count.extend(fully_correct_match_pred_ID)\n",
        "                half_correct_double_count.extend(half_correct_match_pred_ID)\n",
        "                min_correct_double_count.extend(min_correct_match_pred_ID)\n",
        "                        \n",
        "\n",
        "            fully_correct_FN, fully_correct_FP = self.compute_FN_FP(fully_correct_TP)\n",
        "            fully_correct_F1, fully_correct_precision, fully_correct_recall = self.compute_F1(fully_correct_TP, fully_correct_FP, fully_correct_FN)\n",
        "\n",
        "            half_correct_FN, half_correct_FP = self.compute_FN_FP(half_correct_TP)\n",
        "            half_correct_F1, half_correct_precision, half_correct_recall = self.compute_F1(half_correct_TP, half_correct_FP, half_correct_FN)\n",
        "\n",
        "            min_correct_FN, min_correct_FP = self.compute_FN_FP(min_correct_TP)\n",
        "            min_correct_F1, min_correct_precision, min_correct_recall = self.compute_F1(min_correct_TP, min_correct_FP, min_correct_FN)\n",
        "\n",
        "            fully_correctly_labeled_proportion = fully_correct_TP/self.no_initiatives\n",
        "            half_correctly_labeled_proportion = half_correct_TP/self.no_initiatives\n",
        "            min_correctly_labeled_proportion = min_correct_TP/self.no_initiatives\n",
        "            \n",
        "            return fully_correctly_labeled_proportion, half_correctly_labeled_proportion, min_correctly_labeled_proportion, fully_correct_F1, half_correct_F1, min_correct_F1, fully_correct_precision, fully_correct_recall, half_correct_precision, half_correct_recall, min_correct_precision, min_correct_recall\n",
        "    \n",
        "    def compute_F1(self, TP, FP, FN):\n",
        "        \"\"\" Utility method to compute F1 score\n",
        "        \"\"\"\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        if precision == recall == 0:\n",
        "            F1 = 0\n",
        "        else:\n",
        "            F1 = 2 * precision * recall /(precision + recall)\n",
        "        return F1, precision, recall\n",
        "    \n",
        "    def compute_FN_FP(self, TP):\n",
        "        \"\"\" Utility method to compute FN and FP initiatives given the no of TP \n",
        "        (defined as the set intersection between gold initiative span and prediction span)\n",
        "        \"\"\"\n",
        "        FN = len(self.initiative_dict) - TP\n",
        "        FP = len(self.predictions_dict) - TP\n",
        "        return FN, FP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7R7dTM4hULGj"
      },
      "outputs": [],
      "source": [
        "# Unit tests for Initiative_Evaluation Class\n",
        "mock_initiative_dict_1 = {1:[1,2], 2:[3,4]}\n",
        "mock_predictions_dict_1 = {1: [1,2], 2:[3], 3:[4]}\n",
        "mock_evaluation_1 = Initiative_Evaluation(mock_initiative_dict_1, mock_predictions_dict_1)\n",
        "mock_init_strict_accuracy_1, mock_init_medium_accuracy_1, mock_init_lenient_accuracy_1, mock1_fully_correct_F1, mock1_half_correct_F1, mock1_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_1.evaluate()\n",
        "assert mock_init_strict_accuracy_1 == 0.5\n",
        "assert mock_init_medium_accuracy_1 == 1\n",
        "assert mock_init_lenient_accuracy_1 == 1\n",
        "assert mock1_fully_correct_F1 == 0.4\n",
        "assert mock1_half_correct_F1 == mock1_min_correct_F1 == 0.8\n",
        "\n",
        "\n",
        "mock_initiative_dict_2 = {1:[1,2], 2:[4,5,6]}\n",
        "mock_predictions_dict_2 = {1: [1,2], 2:[4,5,6]}\n",
        "mock_evaluation_2 = Initiative_Evaluation(mock_initiative_dict_2, mock_predictions_dict_2)\n",
        "mock_init_strict_accuracy_2, mock_init_medium_accuracy_2, mock_init_lenient_accuracy_2, mock2_fully_correct_F1, mock2_half_correct_F1, mock2_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_2.evaluate()\n",
        "assert mock_init_strict_accuracy_2 == 1\n",
        "assert mock_init_medium_accuracy_2 == 1\n",
        "assert mock_init_lenient_accuracy_2 == 1\n",
        "assert mock2_fully_correct_F1 == mock2_half_correct_F1 == mock2_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_3 = {1:[1,2], 2:[3,4]}\n",
        "mock_predictions_dict_3 = {1: [1,2], 2:[3,4]}\n",
        "mock_evaluation_3 = Initiative_Evaluation(mock_initiative_dict_3, mock_predictions_dict_3)\n",
        "mock_init_strict_accuracy_3, mock_init_medium_accuracy_3, mock_init_lenient_accuracy_3, mock3_fully_correct_F1, mock3_half_correct_F1, mock3_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_3.evaluate()\n",
        "assert mock_init_strict_accuracy_3 == 1\n",
        "assert mock_init_medium_accuracy_3 == 1\n",
        "assert mock_init_lenient_accuracy_3 == 1\n",
        "assert mock3_fully_correct_F1 == mock3_half_correct_F1 == mock3_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_4 = {}\n",
        "mock_predictions_dict_4 = {}\n",
        "mock_evaluation_4 = Initiative_Evaluation(mock_initiative_dict_4, mock_predictions_dict_4)\n",
        "mock_init_strict_accuracy_4, mock_init_medium_accuracy_4, mock_init_lenient_accuracy_4, mock4_fully_correct_F1, mock4_half_correct_F1, mock4_min_correct_F1 = mock_evaluation_4.evaluate()\n",
        "assert mock_init_strict_accuracy_4 == 1\n",
        "assert mock_init_medium_accuracy_4 == 1\n",
        "assert mock_init_lenient_accuracy_4 == 1\n",
        "assert mock4_fully_correct_F1 == mock4_half_correct_F1 == mock4_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_5 = {1:[1,2], 2:[3,4,5], 3:[6]}\n",
        "mock_predictions_dict_5 = {1:[1], 2:[2], 3:[3], 4:[4], 5:[5]}\n",
        "mock_evaluation_5 = Initiative_Evaluation(mock_initiative_dict_5, mock_predictions_dict_5)\n",
        "mock_init_strict_accuracy_5, mock_init_medium_accuracy_5, mock_init_lenient_accuracy_5, mock5_fully_correct_F1, mock5_half_correct_F1, mock5_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_5.evaluate()\n",
        "assert mock_init_strict_accuracy_5 == 0\n",
        "assert mock_init_medium_accuracy_5 == 1/3\n",
        "assert mock_init_lenient_accuracy_5 == 2/3\n",
        "assert mock5_fully_correct_F1 == 0\n",
        "assert mock5_half_correct_F1 == 0.25\n",
        "assert mock5_min_correct_F1 == 0.5\n",
        "\n",
        "mock_initiative_dict_6 = {1:[1,2], 2:[3,4,5], 3:[6]}\n",
        "mock_predictions_dict_6 = {1:[1,2,3,4,5,6]}\n",
        "mock_evaluation_6 = Initiative_Evaluation(mock_initiative_dict_6, mock_predictions_dict_6)\n",
        "mock_init_strict_accuracy_6, mock_init_medium_accuracy_6, mock_init_lenient_accuracy_6, mock6_fully_correct_F1, mock6_half_correct_F1, mock6_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_6.evaluate()\n",
        "assert mock_init_strict_accuracy_6 == 0\n",
        "assert mock_init_medium_accuracy_6 == 1/3\n",
        "assert mock_init_lenient_accuracy_6 == 1/3\n",
        "assert mock6_fully_correct_F1 == 0\n",
        "assert mock6_half_correct_F1 == mock6_min_correct_F1 == 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM5U12qZtB92",
        "outputId": "52b20a9e-e41c-4036-c6fe-7a7f7abf1ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file final_roberta_no_context_paper/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"Sustainable_RoBERTa\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.15.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file final_roberta_no_context_paper/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing Sustainable_RoBERTa.\n",
            "\n",
            "All the weights of Sustainable_RoBERTa were initialized from the model checkpoint at final_roberta_no_context_paper.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Sustainable_RoBERTa for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting results on dev set took 78.8885223865509 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform context predictions on dev dataset\n",
        "start_time = time.time()\n",
        "sustainable_model = Sustainable_RoBERTa.from_pretrained('final_roberta_no_context_paper') \n",
        "loaded_crf_model = torch.load('crf_RoBERTa_no_context_paper.pt') \n",
        "dev_predictions_list = model_predict(sustainable_model, tokenizer, dev_loader, device, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, crf_model = loaded_crf_model)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on dev set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the dev set\n",
        "dev_pred_mapping, dev_predictions = reconcile_mapping(dev_data, pre_labeled_dev_data, dev_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioIJdeSTtB92",
        "outputId": "b4a3dffb-d643-4ff0-d6b1-4aad0d18d42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report on the Development Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9790    0.9836    0.9813     53854\n",
            "    Singleton     0.3935    0.2163    0.2791       504\n",
            "    Beginning     0.1959    0.2162    0.2055       481\n",
            "       Inside     0.0697    0.0839    0.0761       310\n",
            "          End     0.1676    0.1185    0.1389       481\n",
            "\n",
            "     accuracy                         0.9575     55630\n",
            "    macro avg     0.3611    0.3237    0.3362     55630\n",
            " weighted avg     0.9548    0.9575    0.9559     55630\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract ground truth dev data labels\n",
        "dev_label_values = []\n",
        "dev_report_numbers = []\n",
        "for sent_no in range(len(development_data)):\n",
        "  dev_report_numbers.append(development_data[sent_no][0]['report_no'])\n",
        "  if development_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = development_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(development_data[sent_no][0]['report_no'])\n",
        "    if len(dev_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      dev_label_values.append(development_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif dev_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      dev_label_values.append(2) #append 2 for beginning of initiative\n",
        "    elif dev_initiative_dict[initiative_unique_reference].index(sent_no) == (len(dev_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      dev_label_values.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      dev_label_values.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    dev_label_values.append(development_data[sent_no][2]['has_initiative'])\n",
        "\n",
        "\n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Development Dataset \\n')\n",
        "print(classification_report(dev_label_values, np.array(dev_predictions), target_names = target_names, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkeXSSd8soJW",
        "outputId": "076d0247-c4e4-4465-9fb9-a490098db9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 53.81% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 43.25% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 25.18% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 42.93% \n",
            "\n",
            "Precision score where at least 1 sentence is identified is 35.71% \n",
            "\n",
            "Recall score where at least 1 sentence is identified is 53.81% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 34.51% \n",
            "\n",
            "Precision score where 50% of sentences are identified is 28.71% \n",
            "\n",
            "Recal score where 50% of sentences are identified is 43.25% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 20.09% \n",
            "\n",
            "Precision score where 100% of sentences are identified is 16.71% \n",
            "\n",
            "Recall score where 100% of sentences are identified is 25.18% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "dev_predictions_dict = sentence_to_initiative_aggregation(dev_predictions, dev_report_numbers)\n",
        "dev_init_evaluation = Initiative_Evaluation(dev_initiative_dict, dev_predictions_dict)\n",
        "dev_init_strict_accuracy, dev_init_medium_accuracy, dev_init_lenient_accuracy, dev_strict_F1, dev_medium_F1, dev_lenient_F1, dev_strict_precision, dev_strict_recall, dev_medium_precision, dev_medium_recall, dev_lenient_precision, dev_lenient_recall = dev_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {dev_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {dev_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {dev_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {dev_lenient_F1:.2%} \\n')\n",
        "print(f'Precision score where at least 1 sentence is identified is {dev_lenient_precision:.2%} \\n')\n",
        "print(f'Recall score where at least 1 sentence is identified is {dev_lenient_recall:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {dev_medium_F1:.2%} \\n')\n",
        "print(f'Precision score where 50% of sentences are identified is {dev_medium_precision:.2%} \\n')\n",
        "print(f'Recal score where 50% of sentences are identified is {dev_medium_recall:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {dev_strict_F1:.2%} \\n')\n",
        "print(f'Precision score where 100% of sentences are identified is {dev_strict_precision:.2%} \\n')\n",
        "print(f'Recall score where 100% of sentences are identified is {dev_strict_recall:.2%} \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TKuUMTlaWZp",
        "outputId": "e450c5e9-2e9c-4f78-feb2-2d95892374c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting results on test set took 83.89918375015259 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform predictions on test dataset\n",
        "start_time = time.time()\n",
        "test_predictions_list = model_predict(sustainable_model, tokenizer, test_loader, device,  global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, crf_model = loaded_crf_model)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on test set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the train set\n",
        "test_pred_mapping, test_predictions = reconcile_mapping(test_data, pre_labeled_test_data, test_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5UC4ohhaWZp",
        "outputId": "f38bac17-0a30-4dce-e303-0f14cc8445de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report on the Test Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9786    0.9741    0.9763     48175\n",
            "    Singleton     0.2708    0.2028    0.2319       577\n",
            "    Beginning     0.1564    0.1991    0.1752       447\n",
            "       Inside     0.0835    0.1845    0.1150       233\n",
            "          End     0.1471    0.1342    0.1404       447\n",
            "\n",
            "     accuracy                         0.9470     49879\n",
            "    macro avg     0.3273    0.3390    0.3278     49879\n",
            " weighted avg     0.9514    0.9470    0.9490     49879\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_label_values = []\n",
        "test_report_numbers = []\n",
        "for sent_no in range(len(testing_data)):\n",
        "  test_report_numbers.append(testing_data[sent_no][0]['report_no'])\n",
        "  if testing_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = testing_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(testing_data[sent_no][0]['report_no'])\n",
        "    if len(test_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      test_label_values.append(testing_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif test_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      test_label_values.append(2) #append 2 for beginning of initiative\n",
        "    elif test_initiative_dict[initiative_unique_reference].index(sent_no) == (len(test_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      test_label_values.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      test_label_values.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    test_label_values.append(testing_data[sent_no][2]['has_initiative'])\n",
        "\n",
        "\n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Test Dataset \\n')\n",
        "print(classification_report(test_label_values, np.array(test_predictions), target_names = target_names, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHREX4AzaWZp",
        "outputId": "f416a09d-2f65-404e-f842-df7840cd3a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 52.25% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 42.09% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 26.46% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 36.95% \n",
            "\n",
            "Precision score where at least 1 sentence is identified is 28.58% \n",
            "\n",
            "Recall score where at least 1 sentence is identified is 52.25% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 29.77% \n",
            "\n",
            "Precision score where 50% of sentences are identified is 23.02% \n",
            "\n",
            "Recal score where 50% of sentences are identified is 42.09% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 18.72% \n",
            "\n",
            "Precision score where 100% of sentences are identified is 14.48% \n",
            "\n",
            "Recall score where 100% of sentences are identified is 26.46% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "test_predictions_dict = sentence_to_initiative_aggregation(test_predictions, test_report_numbers)\n",
        "test_init_evaluation = Initiative_Evaluation(test_initiative_dict, test_predictions_dict)\n",
        "test_init_strict_accuracy, test_init_medium_accuracy, test_init_lenient_accuracy, test_strict_F1, test_medium_F1, test_lenient_F1, test_strict_precision, test_strict_recall, test_medium_precision, test_medium_recall, test_lenient_precision, test_lenient_recall  = test_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {test_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {test_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {test_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {test_lenient_F1:.2%} \\n')\n",
        "print(f'Precision score where at least 1 sentence is identified is {test_lenient_precision:.2%} \\n')\n",
        "print(f'Recall score where at least 1 sentence is identified is {test_lenient_recall:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {test_medium_F1:.2%} \\n')\n",
        "print(f'Precision score where 50% of sentences are identified is {test_medium_precision:.2%} \\n')\n",
        "print(f'Recal score where 50% of sentences are identified is {test_medium_recall:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {test_strict_F1:.2%} \\n')\n",
        "print(f'Precision score where 100% of sentences are identified is {test_strict_precision:.2%} \\n')\n",
        "print(f'Recall score where 100% of sentences are identified is {test_strict_recall:.2%} \\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf2aN65ztB92",
        "outputId": "315673b1-ee95-4e2f-a85e-6684f47e279d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting results on train set took 131.2131278514862 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform predictions on train dataset\n",
        "start_time = time.time()\n",
        "train_predictions_list = model_predict(sustainable_model, tokenizer, train_loader, device,  global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, crf_model = loaded_crf_model)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on train set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the train set\n",
        "train_pred_mapping, train_predictions = reconcile_mapping(train_data, pre_labeled_train_data, train_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daVKMN0stB93",
        "outputId": "280dfa6e-d940-4ad6-b464-438cf4b5edbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report on the Training Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9979    0.9969    0.9974     83801\n",
            "    Singleton     0.9314    0.8450    0.8861      1045\n",
            "    Beginning     0.7925    0.8714    0.8301       995\n",
            "       Inside     0.6901    0.7599    0.7233       633\n",
            "          End     0.7923    0.8090    0.8006       995\n",
            "\n",
            "     accuracy                         0.9898     87469\n",
            "    macro avg     0.8409    0.8564    0.8475     87469\n",
            " weighted avg     0.9902    0.9898    0.9900     87469\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_labels = []\n",
        "train_report_numbers = []\n",
        "for sent_no in range(len(training_data)):\n",
        "  train_report_numbers.append(training_data[sent_no][0]['report_no'])\n",
        "  if training_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = training_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(training_data[sent_no][0]['report_no'])\n",
        "    if len(train_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      training_labels.append(training_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif train_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      training_labels.append(2) #append 2 for beginning of initiative\n",
        "    elif train_initiative_dict[initiative_unique_reference].index(sent_no) == (len(train_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      training_labels.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      training_labels.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    training_labels.append(training_data[sent_no][2]['has_initiative'])\n",
        "    \n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Training Dataset \\n')\n",
        "print(classification_report(training_labels, np.array(train_predictions), target_names = target_names, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY5BwgnLsoJX",
        "outputId": "57e3332e-1ae1-4867-f898-89e4785df779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 97.40% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 89.36% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 73.87% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 80.19% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 73.57% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 60.82% \n",
            "\n",
            "Evaluating initiatives on the train set took 2.186173439025879 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "train_predictions_dict = sentence_to_initiative_aggregation(train_predictions, train_report_numbers)\n",
        "train_init_evaluation = Initiative_Evaluation(train_initiative_dict, train_predictions_dict)\n",
        "train_init_strict_accuracy, train_init_medium_accuracy, train_init_lenient_accuracy, train_strict_F1, train_medium_F1, train_lenient_F1, train_strict_precision, train_strict_recall, train_medium_precision, train_medium_recall, train_lenient_precision, train_lenient_recall  = train_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {train_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {train_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {train_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {train_lenient_F1:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {train_medium_F1:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {train_strict_F1:.2%} \\n')\n",
        "end_time = time.time()\n",
        "print(f'Evaluating initiatives on the train set took {end_time-start_time} seconds')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "RoBERTa_sustainability_no_context_paper.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "83822c0cf896608929095f1043a98f7e1bb9e3e58b660cf90b3c0a24621313f4"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('sustainability': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc0ae3d1d1784bbf9ccfeee1b2d7c32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_892f07cc4ec34cd8b1179dac3aad19c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_25fd27de662648d9b4b396dd589f76b9",
              "IPY_MODEL_e70db47d39e840b2b9144a791eff55cd",
              "IPY_MODEL_7f1f5d6c69854a65909afe54fee11c30"
            ]
          }
        },
        "892f07cc4ec34cd8b1179dac3aad19c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25fd27de662648d9b4b396dd589f76b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c795550bcf4c4057acd1109b8b3b624c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_440db1a025d74937859a7babb34cafba"
          }
        },
        "e70db47d39e840b2b9144a791eff55cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ec6c6653f4c4e6c9bde0a44728a57d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e981ddc9ccd14d8c9e9771f72e30a4ce"
          }
        },
        "7f1f5d6c69854a65909afe54fee11c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b8004b8ecfca419e8cf712bc22ffa3db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 878k/878k [00:01&lt;00:00, 1.13MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac511cc118c14182a2a183be784de833"
          }
        },
        "c795550bcf4c4057acd1109b8b3b624c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "440db1a025d74937859a7babb34cafba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ec6c6653f4c4e6c9bde0a44728a57d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e981ddc9ccd14d8c9e9771f72e30a4ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8004b8ecfca419e8cf712bc22ffa3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac511cc118c14182a2a183be784de833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71aa567296244787abd6bfc243fa63f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2664555b4bf4391b51d5b50aa10b7c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f4a2644378d4b3a9f786516516fd468",
              "IPY_MODEL_4069cd427b044d0dbb4750807c9ebf01",
              "IPY_MODEL_8bca407b20984b2c889c236e80f90210"
            ]
          }
        },
        "a2664555b4bf4391b51d5b50aa10b7c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f4a2644378d4b3a9f786516516fd468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2cf2038e854948c5a274b4085d9cf79d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8cb89aa45f644d2b809438146bdb7f7e"
          }
        },
        "4069cd427b044d0dbb4750807c9ebf01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cba47935080c4c6e869c4e4b0f3654e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40690a5d7c3844aa85fdeb150cd4b63c"
          }
        },
        "8bca407b20984b2c889c236e80f90210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d18bab00e8b943aa89426e8ac08956d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 446k/446k [00:00&lt;00:00, 392kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe79e89e5849495d9d70e4476e866269"
          }
        },
        "2cf2038e854948c5a274b4085d9cf79d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8cb89aa45f644d2b809438146bdb7f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cba47935080c4c6e869c4e4b0f3654e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40690a5d7c3844aa85fdeb150cd4b63c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d18bab00e8b943aa89426e8ac08956d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe79e89e5849495d9d70e4476e866269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72968ce778494a47a102a18dafac001c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_819b8b3337714947b3771b612d45f5f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e09a32ed2fd34a9faa5dda693e72d272",
              "IPY_MODEL_4787a4555cfe40afb58e6fb89ea24b05",
              "IPY_MODEL_9718b62b853f4358a93f947118de28bc"
            ]
          }
        },
        "819b8b3337714947b3771b612d45f5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e09a32ed2fd34a9faa5dda693e72d272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8626221f4a014eb788f970399f4aa771",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0dd3e6d802e748aaa227bd02cd7deedc"
          }
        },
        "4787a4555cfe40afb58e6fb89ea24b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_53c3f5b3d5864b8faac8401dac314830",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e27b638279743e7af9f109557fe519d"
          }
        },
        "9718b62b853f4358a93f947118de28bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d9d62ab6c7c44c4f8e0e7f788f7fa526",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.29M/1.29M [00:01&lt;00:00, 1.25MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03a109afcb0b40289cc001c7d667389e"
          }
        },
        "8626221f4a014eb788f970399f4aa771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0dd3e6d802e748aaa227bd02cd7deedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53c3f5b3d5864b8faac8401dac314830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e27b638279743e7af9f109557fe519d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9d62ab6c7c44c4f8e0e7f788f7fa526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03a109afcb0b40289cc001c7d667389e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5235a0a7e141469eadfbdbad3984661b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b3478a473774f738fd300bda90ad76c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_edf22710fffc4a548f64c5d9a0d2e5a9",
              "IPY_MODEL_3590dc234ba347c89e146ed8bc00158e",
              "IPY_MODEL_eb9469a6ff484f78ab78f00df8b05e62"
            ]
          }
        },
        "7b3478a473774f738fd300bda90ad76c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edf22710fffc4a548f64c5d9a0d2e5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4458934ee7ab433cae31b441f0c04065",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03a0f8eae9db472b9ce82042ca87f3a5"
          }
        },
        "3590dc234ba347c89e146ed8bc00158e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0235aa83c32a4808b0459d8f35067289",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c674033a2c94e4dabf094c3dbcfabef"
          }
        },
        "eb9469a6ff484f78ab78f00df8b05e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_373875de968843b7ab7c089fee24b8dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 20.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e68529aabc9f44b49c2e85af9cc176a1"
          }
        },
        "4458934ee7ab433cae31b441f0c04065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03a0f8eae9db472b9ce82042ca87f3a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0235aa83c32a4808b0459d8f35067289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c674033a2c94e4dabf094c3dbcfabef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "373875de968843b7ab7c089fee24b8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e68529aabc9f44b49c2e85af9cc176a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d73aad96771043a29104e17f1a090905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5ebb6c1839f4ffdb0dbb816ce70c36a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e07e80f977ac402eaab805d59df76903",
              "IPY_MODEL_2a3508d60bf6468a8d6d44b14b1b1fa4",
              "IPY_MODEL_a25b99ca6a294ba6ab381d71b005a377"
            ]
          }
        },
        "e5ebb6c1839f4ffdb0dbb816ce70c36a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e07e80f977ac402eaab805d59df76903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_160e1f903de74898a1b2a3247e2f091c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b0754bb9011402ab52d2f81b70a5af8"
          }
        },
        "2a3508d60bf6468a8d6d44b14b1b1fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc6b80b648604cf2aa80a296efcde39d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a05cbd087644ae9b9e5a78c42abaefe"
          }
        },
        "a25b99ca6a294ba6ab381d71b005a377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c317eb5630c74d4d8da99261188d8e91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 478M/478M [00:08&lt;00:00, 66.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2b58a6150364345a00f361671b7d185"
          }
        },
        "160e1f903de74898a1b2a3247e2f091c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b0754bb9011402ab52d2f81b70a5af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc6b80b648604cf2aa80a296efcde39d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a05cbd087644ae9b9e5a78c42abaefe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c317eb5630c74d4d8da99261188d8e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2b58a6150364345a00f361671b7d185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59f02a9030a849eeb16a6a2578030d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c7e64122b984a12a765feccbdf324bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f58622244524f2ba45e7dbb5b9a9525",
              "IPY_MODEL_10038b0e665d462fb6461e48bbe6448f",
              "IPY_MODEL_1056addab44447c4b171511349763351"
            ]
          }
        },
        "1c7e64122b984a12a765feccbdf324bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f58622244524f2ba45e7dbb5b9a9525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e06e316dc62b4a0dafd0045c72011de2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_227a171d61e14108a97c0d4c29c3bc6d"
          }
        },
        "10038b0e665d462fb6461e48bbe6448f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfa0720eeadb484589fa540f711358a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2069,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2069,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77bcc373e68242dd9b620a4df314caea"
          }
        },
        "1056addab44447c4b171511349763351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_badfa61007124632b7db70d7dde2c227",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.29k/? [00:00&lt;00:00, 228kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_626a80e442a745ff97d650bc7ab39bac"
          }
        },
        "e06e316dc62b4a0dafd0045c72011de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "227a171d61e14108a97c0d4c29c3bc6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfa0720eeadb484589fa540f711358a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77bcc373e68242dd9b620a4df314caea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "badfa61007124632b7db70d7dde2c227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "626a80e442a745ff97d650bc7ab39bac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}