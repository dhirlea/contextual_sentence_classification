{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ex_4NNmtMT2",
        "outputId": "12c4cce6-ba47-4e0f-a03c-46822b5eb670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 33.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 29.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.2\n",
            "Collecting datasets\n",
            "  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 35.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.17)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 55.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 datasets-1.12.1 fsspec-2021.10.0 multidict-5.2.0 xxhash-2.0.2 yarl-1.6.3\n",
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install pytorch-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utm8lRFa7Tdt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import  DataLoader\n",
        "from torchcrf import CRF\n",
        "\n",
        "import transformers\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import RobertaTokenizer \n",
        "from transformers.models.roberta import RobertaModel\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_metric\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9kckp85tQGY",
        "outputId": "5aa5b0e7-e78f-45da-f223-bc9a62416e0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI3EsaCQicd8",
        "outputId": "fd8714fe-d1d4-4ef0-f0ab-9dc28a0af5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "%cd /content/drive/MyDrive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chQJjqSw7Tdu",
        "outputId": "400395dc-30f8-4a85-9006-543a32f1d958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "print(use_cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR1-pIFXtB9t"
      },
      "outputs": [],
      "source": [
        "# Create list of training data files\n",
        "def load_from_directory(directory):\n",
        "    \"\"\"\n",
        "    Utility function to load all json-converted reports into a dataset.\n",
        "    params: directory: string representing location on disk of json files\n",
        "    returns: dataset: list of deserialised jsons\n",
        "    \"\"\"\n",
        "    path = os.getcwd()\n",
        "    path = os.path.join(path, directory)\n",
        "    json_files = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')]\n",
        "\n",
        "    dataset = [] \n",
        "\n",
        "    for filename in json_files: \n",
        "        with open(path+filename, \"r\", encoding='utf-8') as read_file:\n",
        "            dataset.append(json.load(read_file))\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "train_folder = 'json_train/'\n",
        "train_dataset = load_from_directory(train_folder)\n",
        "\n",
        "dev_folder = 'json_develop/'\n",
        "development_dataset = load_from_directory(dev_folder)\n",
        "\n",
        "test_folder = 'json_test/'\n",
        "test_dataset = load_from_directory(test_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG-4ESe7tB9u"
      },
      "outputs": [],
      "source": [
        "def filter_dataset(input_dataset):\n",
        "    \"\"\" \n",
        "    Utility function to convert input dataset into custom data structure\n",
        "    params: input_dataset: list of deserialised jsons\n",
        "    returns: dictionary with the following structure:\n",
        "            key:  sentence_global_idx value , value:list of dictionaries\n",
        "            dict0: key: report_no, value: int \n",
        "            dict1: key: text, value: string\n",
        "            dict2: key: has_initiative, value: boolean\n",
        "            dict3: key: list_of_initiatives, value: list of strings with initiative IDs\n",
        "            dict4: key: sector, value: list of strings\n",
        "            dict5: key: sdg, value: list of sgd strings (representing sgd number)\n",
        "            dict6: key: sentence_length, value: int  \n",
        "    \"\"\"\n",
        "    structured_data = {}\n",
        "    total_no_reports = len(input_dataset)\n",
        "    sentence_global_idx = 0\n",
        "    re_punctuation_string = '[“”|()%&\\s,_:;/\\'!?-]'\n",
        "\n",
        "    for report_no in range(total_no_reports): \n",
        "        no_sentences_per_report = len(input_dataset[report_no]['tokenised_sentences'])\n",
        "        for sentence_no in range(no_sentences_per_report):\n",
        "            tokenized_sentence = re.split(re_punctuation_string, input_dataset[report_no]['tokenised_sentences'][sentence_no]['text'])\n",
        "            tokenized_sentence = list(filter(None, tokenized_sentence))\n",
        "            if (len(tokenized_sentence) == 0):           \n",
        "                continue\n",
        "            else:\n",
        "                structured_data[sentence_global_idx] = []\n",
        "                structured_data[sentence_global_idx].append({'report_no':report_no}) \n",
        "                structured_data[sentence_global_idx].append({'text':' '.join([elem.lower() for elem in tokenized_sentence])})\n",
        "                if len(input_dataset[report_no]['tokenised_sentences'][sentence_no]['initiative_ids']) > 0:\n",
        "                  structured_data[sentence_global_idx].append({'has_initiative':1})\n",
        "                else:\n",
        "                   structured_data[sentence_global_idx].append({'has_initiative':0})\n",
        "                structured_data[sentence_global_idx].append({'list_of_initiatives': input_dataset[report_no]['tokenised_sentences'][sentence_no]['initiative_ids']}) \n",
        "                \n",
        "                structured_data[sentence_global_idx].append({'sentence_length':len(tokenized_sentence)}) \n",
        "                sentence_global_idx +=1\n",
        "    \n",
        "    return structured_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqb_rDqdtB9w"
      },
      "outputs": [],
      "source": [
        "# Set up datasets from json files\n",
        "training_data = filter_dataset(train_dataset)\n",
        "development_data = filter_dataset(development_dataset)\n",
        "testing_data = filter_dataset(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ2h2bUHtB9y"
      },
      "outputs": [],
      "source": [
        "def assisted_labelling(data, lower_threshold, upper_threshold):\n",
        "    \"\"\"\n",
        "    Utility function which labels all sentences with fewer than the threshold number of tokens as not having a sustainability initiative.\n",
        "    params: data: list of dictionaries\n",
        "            threshold: int representing number of tokens\n",
        "    returns: dictionary {global_sentence_index:boolean label}\n",
        "    \"\"\"\n",
        "    labeled_dataset = {}\n",
        "    for sentence_no in range(len(data)):\n",
        "        tokenized_sentence = re.split(' ', data[sentence_no][1]['text'])\n",
        "        tokenized_sentence_with_alphabetical_chars = [word for word in tokenized_sentence if re.search('[a-zA-Z]', word)]\n",
        "        if (data[sentence_no][4]['sentence_length'] > lower_threshold) & (len(tokenized_sentence_with_alphabetical_chars)!=0) & (data[sentence_no][4]['sentence_length']<upper_threshold):\n",
        "            labeled_dataset[sentence_no] = 1 \n",
        "        else:\n",
        "            labeled_dataset[sentence_no] = 0 # label short, long and non-alphabetical sentences as not having an initiative\n",
        "    return labeled_dataset\n",
        "\n",
        "assistant_labeled_training_data = assisted_labelling(training_data,lower_threshold=5, upper_threshold=100)\n",
        "assistant_labeled_dev_data = assisted_labelling(development_data,lower_threshold=5, upper_threshold=100)\n",
        "assistant_labeled_test_data = assisted_labelling(testing_data, lower_threshold=5, upper_threshold=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq_Q9UCl33gd"
      },
      "outputs": [],
      "source": [
        "def reader(dataset, assisted_labels, initiative_dict):\n",
        "    \"\"\"\n",
        "    Utility function read in the data together with assisted labels and return a train dictionary and a pre-labelled dictionary.\n",
        "    params: dataset: dict {global_sentence_index : list of 7 dictionaries}\n",
        "            assisted_labels: dict {global_sentence_index : assistant label}\n",
        "    returns: train_dict: dict\n",
        "             pre_labelled_dict\n",
        "    \"\"\"\n",
        "    texts = []\n",
        "    labels = []\n",
        "    positions = []\n",
        "    initiative_IDs = []\n",
        "    report_no = []\n",
        "    \n",
        "    pre_labeled_texts =[]\n",
        "    pre_labeled_labels =[]\n",
        "    pre_labeled_positions =[]\n",
        "    pre_labeled_IDs = []\n",
        "\n",
        "    for sentence_no in range(len(dataset)):\n",
        "        if assisted_labels[sentence_no] == 1:\n",
        "            report_no.append(dataset[sentence_no][0]['report_no'])\n",
        "            texts.append(dataset[sentence_no][1]['text'])\n",
        "            if dataset[sentence_no][3]['list_of_initiatives']: #check whether the sentence has an initiative\n",
        "              initiative_unique_reference = dataset[sentence_no][3]['list_of_initiatives'][0] + '_' + str(dataset[sentence_no][0]['report_no'])\n",
        "              if len(initiative_dict[initiative_unique_reference]) == 1:\n",
        "                labels.append(dataset[sentence_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "              elif initiative_dict[initiative_unique_reference].index(sentence_no) == 0:\n",
        "                labels.append(2) #append 2 for beginning of initiative\n",
        "              elif initiative_dict[initiative_unique_reference].index(sentence_no) == (len(initiative_dict[initiative_unique_reference]) - 1):\n",
        "                labels.append(4) #append 4 for end of initiative\n",
        "              else:\n",
        "                labels.append(3) #append 3 for inside an initiative\n",
        "            else:\n",
        "              labels.append(dataset[sentence_no][2]['has_initiative'])\n",
        "            positions.append(sentence_no)\n",
        "            initiative_IDs.append(dataset[sentence_no][3]['list_of_initiatives'])\n",
        "        else:\n",
        "            pre_labeled_texts.append(dataset[sentence_no][1]['text'])\n",
        "            pre_labeled_labels.append(assisted_labels[sentence_no]) # append 0 for non-initiative sentences\n",
        "            pre_labeled_positions.append(sentence_no)\n",
        "            pre_labeled_IDs.append(dataset[sentence_no][3]['list_of_initiatives'])\n",
        "\n",
        "    actual_data_dict = {'texts':texts, 'labels':labels, 'positions':positions, 'ID_list':initiative_IDs, 'report_no':report_no}\n",
        "    pre_labeled_dict = {'texts':pre_labeled_texts, 'labels':pre_labeled_labels, 'positions': pre_labeled_positions, 'ID_list':pre_labeled_IDs}\n",
        "            \n",
        "    return actual_data_dict, pre_labeled_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrxI7zhZzd_I"
      },
      "outputs": [],
      "source": [
        "def context_builder(data_dict, left_context_size = 0, right_context_size = 0):\n",
        "    context = []\n",
        "    multi_sentence_labels = []\n",
        "    for sentence_index in range(len(data_dict['texts'])):\n",
        "        sentence_context = []\n",
        "        sentence_context_labels = []\n",
        "        if (sentence_index - left_context_size >= 0) and (sentence_index + right_context_size < len(data_dict['texts'])):\n",
        "            # test if target sentence is in the middle of the corpus\n",
        "            for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                if data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]:\n",
        "                    sentence_context.append(data_dict['texts'][context_index])\n",
        "                    sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        elif sentence_index - left_context_size >= 0: #if target sentence is at end of the corpus \n",
        "            for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                if context_index < len(data_dict['texts']): # add in a smaller context window at end of the corpus\n",
        "                    if (data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]):\n",
        "                        sentence_context.append(data_dict['texts'][context_index])\n",
        "                        sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        elif sentence_index + right_context_size < len(data_dict['texts']): #if target sentence is at beginning of the corpus \n",
        "                for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                    if context_index >= 0: # add in smaller context window at the beginning of the corpus\n",
        "                        if (data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]):\n",
        "                            sentence_context.append(data_dict['texts'][context_index])\n",
        "                            sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        context.append(sentence_context)\n",
        "        while len(sentence_context_labels) < (1 + left_context_size + right_context_size): # pad with 0 labels for senteces with a smaller context eg. beginning/end of docs\n",
        "          sentence_context_labels.append(0)\n",
        "        multi_sentence_labels.append(sentence_context_labels)\n",
        "    return context, multi_sentence_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D9lIa3R6cRb"
      },
      "outputs": [],
      "source": [
        "class SustainableDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Dataset class inheriting from pytorch to be used by dataloaders.\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer, input_set, input_context, input_multi_sentence_labels, max_paragraph_length, global_target_sentence_index):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = input_set['texts']\n",
        "        self.labels = input_set['labels']\n",
        "        self.report_nos = input_set['report_no']\n",
        "        self.contexts = input_context\n",
        "        self.context_labels = input_multi_sentence_labels\n",
        "        self.max_paragraph_length = max_paragraph_length\n",
        "        self.global_target_sentence_index = global_target_sentence_index\n",
        "        \n",
        "        \n",
        "    def collate_fn(self, batch):\n",
        "        texts = [b['text'] for b in batch]\n",
        "        labels = [b['label'] for b in batch]\n",
        "        contexts = [b['context'] for b in batch]\n",
        "        context_labels = [b['context_label'] for b in batch]\n",
        "        encodings, sep_positions = self.custom_tokenizer(batch = contexts) \n",
        "        encodings['labels'] =  torch.tensor(context_labels) # pass through labels for all sentences\n",
        "        encodings['sep_positions'] = sep_positions\n",
        "        return encodings\n",
        "    \n",
        "    def custom_collate_fn(self, batch):\n",
        "      texts = [b['text'] for b in batch]\n",
        "      labels = [b['label'] for b in batch]\n",
        "      contexts = [b['context'] for b in batch]\n",
        "      context_labels = [b['context_label'] for b in batch]\n",
        "      return {'texts':texts, 'labels':labels, 'contexts':contexts, 'context_labels':context_labels}\n",
        "    \n",
        "\n",
        "    def custom_tokenizer(self, batch):\n",
        "      \"\"\" Utility functions to tokenize a list of sentences using [SEP] at the beginning of each sentence with fixed positions.\n",
        "      \"\"\"\n",
        "      batch_sequences = []\n",
        "      batch_sep_positions = []\n",
        "      for sequence_list in batch:\n",
        "        augmented_sequence = ' '\n",
        "        for sentence in sequence_list:     \n",
        "          if sentence != sequence_list[-1]:\n",
        "                augmented_sequence += sentence + ' </s> '\n",
        "          else:\n",
        "            augmented_sequence += sentence\n",
        "        batch_sequences.append(augmented_sequence)\n",
        "      encoded_batch = self.tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt')\n",
        "      for encoded_sequence in encoded_batch['input_ids']:\n",
        "          sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==2]\n",
        "          while len(sep_positions) < self.max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "            sep_positions.append(sep_positions[-1])\n",
        "          batch_sep_positions.append(sep_positions)\n",
        "       \n",
        "      return encoded_batch, batch_sep_positions\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {'text': self.texts[idx],\n",
        "                'label': self.labels[idx],\n",
        "                'context': self.contexts[idx],\n",
        "                'context_label' : self.context_labels[idx],\n",
        "                }\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9odLvcadGWg"
      },
      "outputs": [],
      "source": [
        "def get_sep_positions(data_loader, global_target_sentence_index, max_paragraph_length, tokenizer):\n",
        "  \"\"\" Utility function to get sep positions for given dataset.\n",
        "  \"\"\"\n",
        "  dataset_sep_positions = []\n",
        "  for batch in data_loader:\n",
        "      batch_sep_positions = []\n",
        "      batch_sequences = []\n",
        "      for sequence_list in batch['contexts']:\n",
        "        augmented_sequence = ' '\n",
        "        for sentence in sequence_list:\n",
        "            if sentence != sequence_list[-1]:\n",
        "              augmented_sequence += sentence + ' </s> '\n",
        "            else:\n",
        "              augmented_sequence += sentence\n",
        "        batch_sequences.append(augmented_sequence)\n",
        "      encoded_batch = tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt')\n",
        "      for encoded_sequence in encoded_batch['input_ids']:\n",
        "          sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==2]\n",
        "          while len(sep_positions) < max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "            sep_positions.append(sep_positions[-1])\n",
        "          batch_sep_positions.append(sep_positions)\n",
        "      dataset_sep_positions.extend([sublist[:-1] for sublist in batch_sep_positions]) \n",
        "  return dataset_sep_positions\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r92owFJgsoJV"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary with ID_reportNo as keys and values as list of sentence indices\n",
        "def create_init_dict(data):\n",
        "    \"\"\" Utility function to extract individual initiatives as keys of a dict and a list of corresponding global sentence indices.\n",
        "    \"\"\"\n",
        "    initiative_dict = {} #keys are initiative IDs, values are counts of IDs \n",
        "    for sentence_no in range(len(data)):\n",
        "        if data[sentence_no][2]['has_initiative']:\n",
        "            initiative_ID = data[sentence_no][3]['list_of_initiatives'][0]\n",
        "            if (initiative_ID + '_' + str(data[sentence_no][0]['report_no'])) not in initiative_dict.keys():\n",
        "                initiative_dict[initiative_ID + '_' + str(data[sentence_no][0]['report_no'])] = [sentence_no]\n",
        "            else:\n",
        "                initiative_dict[initiative_ID + '_' + str(data[sentence_no][0]['report_no'])].append(sentence_no)\n",
        "    return initiative_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "a1bf21da90694452b37c030f33a1ff36",
            "28f019e7247943bba565306a69b3234f",
            "b9ec26e98e8c45dfbc5ee038481b2f87",
            "eb83ded728f14ac5a71d07f21b0fafe0",
            "2d937500c5f941069e6d582f234b3b0c",
            "496d0b8f73ee4b48b7de5de97e807baf",
            "1b4613e7962d4098ae28561023788bfd",
            "ef23eddf101847dc88a7b99ce821a562",
            "6f1ca37d01404fa19f48d591d0401b23",
            "b6e6d9f717fc4c9497f0078646d2dc29",
            "9e6fd78228414ce89c37ac7854b7daef",
            "40020e4c964e4833a881540e8277a244",
            "e1eba24f36e44f4a84f35c9750a754c4",
            "30dee97a0d35424c99d05283963dd64b",
            "3ee288bb667947259c3e24048c8296f2",
            "a3036e59fc154e9cb4bfbdccb279c38e",
            "da4139276d0e4211bf42b6ce79510dcd",
            "35fd8d5658134ab7a85ea7f6bb10d89a",
            "9e701c415b4d4696880223b38395aa28",
            "f3b1399c6b3c42ed916c24a3adac98ab",
            "4aa4478a7034490383f9c5d389f3e774",
            "f8705c1ed3e34dbb823289c3f26bb725",
            "bc7388752c944bd2a13d19fc994403e7",
            "6c130dddc9154c13941be986fc7e3422",
            "550591b550d8455fa0a1cddbe9864889",
            "8cf481d391564eff92f58b1d9a80d9cb",
            "21594558872141458c6b00c36247c5be",
            "8cfd580048db4830b28a8ce84f007ef0",
            "e705cbb4af4f46ed84b34c3420eaa845",
            "d17777fc82094edfa2a845931402dab0",
            "1768148e3bc148dfa0df5213c1c267a2",
            "f76eea2d29f246598346a60d2a2cda6c",
            "26d86352d090424f93db82de2e835384",
            "e8285a6d849a47e790ea1a8288093493",
            "69116deebf084cdabcda4a7fba80cf83",
            "2a33ac57dc124d629eb2bbc7c77e4fb3",
            "fbfbaa07ea354ea188e5616ec371b588",
            "b05cb25ff11842288f1a0992195674a2",
            "5f66e6c7d83c409995fe30fda463b0d1",
            "05a205bbd6714d96aa45ab56dbf6fd9b",
            "d7e69309c14f4aea8c44af4126433ad9",
            "89ac185e81094a72bb5419995311635a",
            "f9993deb114b4a9db5fcf2d731e519e9",
            "2d9af150b641481da705db2d0e370d32"
          ]
        },
        "id": "TyZQtXwj4ixr",
        "outputId": "786ea7fd-eff8-4b9e-d03b-2b0aa8ec88db"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1bf21da90694452b37c030f33a1ff36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40020e4c964e4833a881540e8277a244",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc7388752c944bd2a13d19fc994403e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8285a6d849a47e790ea1a8288093493",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "global_target_sentence_index = 2 \n",
        "\n",
        "# Create gold standard initiative dictionaries\n",
        "train_initiative_dict = create_init_dict(training_data)\n",
        "dev_initiative_dict = create_init_dict(development_data)\n",
        "test_initiative_dict = create_init_dict(testing_data)\n",
        "\n",
        "# Read in training and dev data and split into data to feed into the model and pre-labeled data\n",
        "train_data, pre_labeled_train_data = reader(training_data, assistant_labeled_training_data, train_initiative_dict)\n",
        "dev_data, pre_labeled_dev_data = reader(development_data, assistant_labeled_dev_data, dev_initiative_dict)\n",
        "test_data, pre_labeled_test_data = reader(testing_data, assistant_labeled_test_data, test_initiative_dict)\n",
        "\n",
        "# Construct context around each sentence per dataset\n",
        "train_context, train_multi_sentence_labels = context_builder(train_data, left_context_size = 2, right_context_size = 2) \n",
        "dev_context, dev_multi_sentence_labels = context_builder(dev_data, left_context_size = 2, right_context_size = 2) \n",
        "test_context, test_multi_sentence_labels = context_builder(test_data, left_context_size = 2, right_context_size = 2)\n",
        "\n",
        "max_paragraph_length = max([len(label_sequence) for label_sequence in train_multi_sentence_labels])\n",
        "\n",
        "# Only data to be fed into the model is built into datasets\n",
        "train_dataset = SustainableDataset(tokenizer, train_data, train_context, train_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "dev_dataset = SustainableDataset(tokenizer, dev_data, dev_context, dev_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "test_dataset = SustainableDataset(tokenizer, test_data, test_context, test_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "\n",
        "# Create train and dev dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, collate_fn = train_dataset.custom_collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False, collate_fn = dev_dataset.custom_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn = test_dataset.custom_collate_fn)\n",
        "\n",
        "# Record sep positions for dev dataset (to be used for early stopping during training)\n",
        "dev_sep_positions = get_sep_positions(dev_loader, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-KwKMBsULGd"
      },
      "outputs": [],
      "source": [
        "# Unit tests for building context assuming a window\n",
        "mock_train_context, mock_train_multi_sentence_labels = context_builder(train_data, left_context_size = 1, right_context_size = 1)\n",
        "mock_dev_context, mock_dev_multi_sentence_labels = context_builder(dev_data, left_context_size = 1, right_context_size = 1)\n",
        "mock_train_dataset = SustainableDataset(tokenizer, train_data, mock_train_context, mock_train_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "mock_dev_dataset = SustainableDataset(tokenizer, dev_data, mock_dev_context, mock_dev_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "assert mock_train_dataset.contexts[11] == [mock_train_dataset.texts[10], mock_train_dataset.texts[11], mock_train_dataset.texts[12]]  #random corpus context\n",
        "assert len(mock_train_dataset.contexts) == len(mock_train_dataset.texts) #there is a context for every target sentence in the train set\n",
        "assert mock_dev_dataset.contexts[11] == [mock_dev_dataset.texts[10], mock_dev_dataset.texts[11], dev_dataset.texts[12]] #random corpus context\n",
        "assert len(mock_dev_dataset.contexts) == len(mock_dev_dataset.texts) #there is a context for every target sentence in the dev set\n",
        "assert [mock_train_dataset.texts[0], mock_train_dataset.texts[1] , mock_train_dataset.texts[2]] ==  mock_train_dataset.contexts[1] #the context for the first sentence in the corpus is only the following sentence\n",
        "assert [mock_train_dataset.texts[-2] , mock_train_dataset.texts[-1]] == mock_train_dataset.contexts[-1] #the context for the last sentence in the corpus is only the preceding sentence\n",
        "assert [mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)] , mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)+1]]== mock_train_dataset.contexts[mock_train_dataset.report_nos.index(1)] # first sentence of second report should have a context of only its following sentence\n",
        "assert [mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)-2], mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)-1]] == mock_train_dataset.contexts[mock_train_dataset.report_nos.index(1)-1] # last sentence of first report should have a context of only its preceding sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fyf-E4gtB90"
      },
      "outputs": [],
      "source": [
        "# Unit tests -> check if assisted data labelling has been performed correctly\n",
        "assert len(set(pre_labeled_train_data['positions']).intersection(set(train_data['positions']))) == 0 \n",
        "assert (len(train_data['texts']) + len(pre_labeled_train_data['texts'])) == len(training_data)\n",
        "assert set(pre_labeled_train_data['positions']).union(set(train_data['positions'])) == set(range(len(training_data)))\n",
        "assert (len(dev_data['texts']) + len(pre_labeled_dev_data['texts'])) == len(development_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUOfidVU_zE8"
      },
      "outputs": [],
      "source": [
        "class Sustainable_RoBERTa(RobertaModel):\n",
        "    \"\"\" Transformer model class with custom output layer for fine-tuning.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.roberta = RobertaModel(config)\n",
        "        self.projection = torch.nn.Sequential(torch.nn.Dropout(0.1), torch.nn.Linear(config.hidden_size, 5))              \n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_values=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,):\n",
        " \n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids, \n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        logits = self.projection(outputs.last_hidden_state) \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2aWTy5uAHGj"
      },
      "outputs": [],
      "source": [
        "class Trainer_Sustainable(Trainer):\n",
        "    \"\"\" Class inheriting from Trainer to configure loss function used.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "        crf_model,\n",
        "        model = None,\n",
        "        args = None,\n",
        "        data_collator = None,\n",
        "        train_dataset = None,\n",
        "        eval_dataset = None,\n",
        "        tokenizer = None,\n",
        "        model_init = None,\n",
        "        compute_metrics = None,\n",
        "        callbacks = None,\n",
        "        optimizers = (None, None),        \n",
        "        ):\n",
        "        super().__init__(model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\n",
        "        self.crf_model = crf_model\n",
        "\n",
        "    def compute_loss(self, model, inputs, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, return_outputs=False):\n",
        "\n",
        "        labels = inputs.pop('labels')\n",
        "        sep_positions = inputs.pop('sep_positions') # take all sep positions\n",
        "        outputs = model(**inputs)\n",
        "        batch_preds = []\n",
        "        for i, sentence_sep_positions in zip(range(outputs.shape[0]), sep_positions):\n",
        "          sentence_preds = []\n",
        "          for j in sentence_sep_positions:\n",
        "            sentence_preds.append(outputs[i,j])\n",
        "          batch_preds.append(torch.cat(sentence_preds[:-1])) #ignore last sep token as we don't predict from it\n",
        "\n",
        "        preds = torch.cat(batch_preds).reshape((-1, max_paragraph_length, 5)).permute(1,0,2)\n",
        "        labels = labels.permute(1,0)\n",
        " \n",
        "        loss = -1 * self.crf_model(preds, labels)\n",
        "        \n",
        "        if return_outputs: \n",
        "            return (loss, (loss, outputs)) \n",
        "        else:\n",
        "            return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxRyedCktB91"
      },
      "outputs": [],
      "source": [
        "def model_predict(model, tokenizer, dataloader, device, global_target_sentence_index, max_paragraph_length, crf_model):\n",
        "    \"\"\" Utility function to set the model to GPU and infer of given dataloader.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch_sequences = []\n",
        "            batch_sep_positions = []\n",
        "            for sequence_list in batch['contexts']:\n",
        "              augmented_sequence = ' '\n",
        "              for sentence in sequence_list:\n",
        "                if sentence != sequence_list[-1]:\n",
        "                  augmented_sequence += sentence + ' </s> '\n",
        "                else:\n",
        "                  augmented_sequence += sentence\n",
        "              batch_sequences.append(augmented_sequence)\n",
        "            encoded_batch = tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt').to(device)\n",
        "            for encoded_sequence in encoded_batch['input_ids']:\n",
        "                sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==2]\n",
        "                while len(sep_positions) < max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "                  sep_positions.append(sep_positions[-1])\n",
        "                batch_sep_positions.append(sep_positions)\n",
        "                      \n",
        "            output = model(**encoded_batch) \n",
        "            batch_preds = []\n",
        "            \n",
        "            for i, sentence_sep_positions in zip(range(output.shape[0]), batch_sep_positions):\n",
        "              sentence_preds = []\n",
        "              for j in sentence_sep_positions:\n",
        "                sentence_preds.append(output[i,j])\n",
        "              batch_preds.append(torch.cat(sentence_preds[:-1])) #ignore last sep token as we don't predict from it\n",
        "\n",
        "            preds = torch.cat(batch_preds).reshape((-1, max_paragraph_length, 5)).permute(1,0,2)\n",
        "            predicted_tags = [tag[global_target_sentence_index] for tag in crf_model.decode(preds)]\n",
        "            predictions.extend(predicted_tags)\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "589171d1e8734c98a5005fade5fae482",
            "ba2881c5ee9b4b45ad4002e5e86f5a8a",
            "7e25a366883b4ef8bb26a2286f5eb67d",
            "df018cc9dbd447a3882ffb5675ab26cf",
            "8e3adf87f6ab401ab2130339b9aa803d",
            "8afde644ebd84318ad478d1e6d5f3f01",
            "3edde62876004b5dab9528b09e5f9853",
            "2aae3649596341e79e1906ce07fa67f5",
            "6de306b9deb64e08b6f4eb604dff4d69",
            "dd39d7e841174ee284c5fb11fa36d34b",
            "9f9d9e1024ee4026bd68a5ca438ddf3d",
            "ae710338a80c4ee0b5a1204995b87a86",
            "8ec14c129667461baa4a2cdb98d2a3e2",
            "62ccdb1d12b14c4c85ded8402f10fa8e",
            "5f333eab26ef4c038343f4c4aa32d053",
            "81c95544e2ac498fa2ddd389103c7ba2",
            "8d6eb18ebfc84a3996914f29b6a08c53",
            "e6977934515040f99d13cddd493cd15e",
            "31666f2daecd4d62b2e5c18d28d9902e",
            "b7e69de6e4754f48975d784e6f3f7504",
            "9ca85d52278d493989a905c60a565402",
            "9ec56abbdc3c478f865aad15658853e4"
          ]
        },
        "id": "8MJmka-LAYIV",
        "outputId": "a7ac35da-768f-4b6e-9394-78276c460a1f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "589171d1e8734c98a5005fade5fae482",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing Sustainable_RoBERTa: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing Sustainable_RoBERTa from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Sustainable_RoBERTa from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Sustainable_RoBERTa were not initialized from the model checkpoint at roberta-base and are newly initialized: ['encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'projection.1.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'projection.1.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae710338a80c4ee0b5a1204995b87a86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.96k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 36920\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 23070\n",
            "/usr/local/lib/python3.7/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorCompare.cpp:255.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23070' max='23070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23070/23070 3:17:13, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>16.176500</td>\n",
              "      <td>12.311797</td>\n",
              "      <td>0.332018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>8.716100</td>\n",
              "      <td>15.683454</td>\n",
              "      <td>0.378079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.706000</td>\n",
              "      <td>20.150368</td>\n",
              "      <td>0.378086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.698100</td>\n",
              "      <td>27.303513</td>\n",
              "      <td>0.363191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.798400</td>\n",
              "      <td>31.570950</td>\n",
              "      <td>0.364373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.299600</td>\n",
              "      <td>39.110821</td>\n",
              "      <td>0.378103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.108500</td>\n",
              "      <td>43.717281</td>\n",
              "      <td>0.388032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.793900</td>\n",
              "      <td>46.714153</td>\n",
              "      <td>0.355813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.624800</td>\n",
              "      <td>47.478996</td>\n",
              "      <td>0.377242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.392300</td>\n",
              "      <td>47.982384</td>\n",
              "      <td>0.370025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-2307\n",
            "Configuration saved in ./roberta_paper/checkpoint-2307/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-2307/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-4674] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-4614\n",
            "Configuration saved in ./roberta_paper/checkpoint-4614/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-4614/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-7011] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-6921\n",
            "Configuration saved in ./roberta_paper/checkpoint-6921/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-6921/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-2307] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-9228\n",
            "Configuration saved in ./roberta_paper/checkpoint-9228/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-9228/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-4614] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-11535\n",
            "Configuration saved in ./roberta_paper/checkpoint-11535/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-11535/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-9228] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-13842\n",
            "Configuration saved in ./roberta_paper/checkpoint-13842/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-13842/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-6921] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-16149\n",
            "Configuration saved in ./roberta_paper/checkpoint-16149/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-16149/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-11535] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-18456\n",
            "Configuration saved in ./roberta_paper/checkpoint-18456/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-18456/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-13842] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-20763\n",
            "Configuration saved in ./roberta_paper/checkpoint-20763/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-20763/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-18456] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-23070\n",
            "Configuration saved in ./roberta_paper/checkpoint-23070/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-23070/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-20763] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./roberta_paper/checkpoint-16149 (score: 0.3880317992781592).\n",
            "Saving model checkpoint to ./final_roberta_paper\n",
            "Configuration saved in ./final_roberta_paper/config.json\n",
            "Model weights saved in ./final_roberta_paper/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "# Instantiate and train model\n",
        "model = Sustainable_RoBERTa.from_pretrained('roberta-base').to(device)\n",
        "\n",
        "total_epochs = 10   \n",
        "learning_rate = 1e-5 \n",
        "\n",
        "# Create evaluation metric F1 score \n",
        "metric = load_metric('f1')\n",
        "\n",
        "def compute_metrics(eval_pred, sep_positions = dev_sep_positions, global_target_sentence_index = global_target_sentence_index):\n",
        "    raw_predictions, raw_labels = eval_pred \n",
        "    pooled_labels = [label[global_target_sentence_index] for label in raw_labels]\n",
        "    pooled_predictions = []\n",
        "    for i, sentence_sep_positions in zip(range(len(raw_predictions)), sep_positions):\n",
        "        sentence_preds = []\n",
        "        for j in sentence_sep_positions:\n",
        "            sentence_preds.append(torch.tensor(raw_predictions[i,j]))\n",
        "        pred = torch.cat(sentence_preds).reshape((-1, max_paragraph_length, 5)).permute(1,0,2).to(device)\n",
        "        predicted_tag = trainer.crf_model.decode(pred)[0][global_target_sentence_index] \n",
        "        pooled_predictions.append(predicted_tag)   \n",
        "    torch.save(trainer.crf_model, f='crf_RoBERTa_2_sent_paper.pt')  # save trained crf model to use at inference time\n",
        "    return metric.compute(predictions=pooled_predictions, references=pooled_labels, average = 'macro')\n",
        "\n",
        "# Define optimizer and lr schedule\n",
        "optimizer = transformers.AdamW(model.parameters(),\n",
        "                  lr = learning_rate, \n",
        "                  )\n",
        "\n",
        "total_steps = len(train_loader) * total_epochs \n",
        "warmup = 0.06 * total_steps\n",
        " \n",
        "# Create the learning rate scheduler.\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup, \n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "# Create training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./roberta_2_sent_paper',\n",
        "    save_total_limit = 2,\n",
        "    learning_rate = learning_rate, \n",
        "    logging_strategy = 'epoch',\n",
        "    per_device_train_batch_size=8, \n",
        "    num_train_epochs = total_epochs, \n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    metric_for_best_model = 'f1',\n",
        "    eval_accumulation_steps=0.1*len(dev_loader),\n",
        "    gradient_accumulation_steps = 2, # effective training batch size of 16\n",
        "    )\n",
        "\n",
        "# Define trainer module\n",
        "trainer = Trainer_Sustainable(\n",
        "    model=model,                         \n",
        "    args=training_args,                 \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,                   \n",
        "    data_collator=train_dataset.collate_fn,\n",
        "    callbacks =[transformers.EarlyStoppingCallback(early_stopping_patience = 5, early_stopping_threshold=-0.03)],\n",
        "    compute_metrics = compute_metrics,\n",
        "    optimizers = (optimizer, scheduler),\n",
        "    crf_model = CRF(num_tags=5).to(device),\n",
        "    )\n",
        "\n",
        "trainer.train() \n",
        "\n",
        "trainer.save_model('./final_roberta_2_sent_paper')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqpGGvvisoJU"
      },
      "outputs": [],
      "source": [
        "def reconcile_mapping(model_data, pre_labeled_data, model_predictions):\n",
        "    \"\"\" Utility function to reconcile mapping between pre-labeled data and model predictions.\n",
        "    params: predictions: list of model predictions\n",
        "            pre_labeled_data: dictionary outputted from reader function\n",
        "    returns: pred_mapping: dict\n",
        "             predictions: dict\n",
        "    \"\"\"\n",
        "    pred_mapping = {}\n",
        "    for dataset_text, text_position, prediction in zip(model_data['texts'], model_data['positions'], model_predictions):\n",
        "        pred_mapping[text_position] = (dataset_text, prediction)\n",
        "\n",
        "    pre_labeled_mapping = {}\n",
        "    for text, pos, label in zip(pre_labeled_data['texts'], pre_labeled_data['positions'], pre_labeled_data['labels']):\n",
        "        pre_labeled_mapping[pos] = (text, label)\n",
        "\n",
        "\n",
        "    pred_mapping.update(pre_labeled_mapping)\n",
        "\n",
        "    pred_mapping = {k: v for k, v in sorted(pred_mapping.items(), key=lambda item: item[0])}\n",
        "\n",
        "    predictions =[element[1] for element in list(pred_mapping.values())] \n",
        "\n",
        "    return pred_mapping, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i2N8mqKULGh"
      },
      "outputs": [],
      "source": [
        "# Create predictions dictionary spanning initiatives\n",
        "def sentence_to_initiative_aggregation(predictions, predictions_report_numbers):\n",
        "    \"\"\" Utility function which takes in a list of IOBES predictions per sentence and aggregates these into a dictionary of initiatives.\n",
        "    params: predictions: list of multi-class predictions\n",
        "    returns: predictions_dict: {initiative_number_report_number:list of sentence positions}\n",
        "    \"\"\"\n",
        "    predictions_dict = {}\n",
        "    initiative_index = 0\n",
        "    prediction_index = 0\n",
        "    while prediction_index < len(predictions):\n",
        "      if predictions[prediction_index] == 0: #no initiative\n",
        "        prediction_index += 1\n",
        "      elif predictions[prediction_index] == 1: #singleton\n",
        "        prediction_span = [prediction_index]\n",
        "        predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "        initiative_index += 1\n",
        "        prediction_index += 1\n",
        "      elif predictions[prediction_index] == 2: #beginning of initiative\n",
        "        if predictions[prediction_index + 1] == 4: # 2 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 2\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 4): #3 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 3\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 3) and (predictions[prediction_index + 3] == 4): #4 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2, prediction_index + 3]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 4\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 3) and (predictions[prediction_index + 3] == 3) and (predictions[prediction_index + 4] == 4): #5 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2, prediction_index + 3, prediction_index + 3]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 5\n",
        "        else:\n",
        "          prediction_span = [prediction_index]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 1\n",
        "      else: # all other initiative predictions which do not form a complete BIE structure are labeled as individual singletons\n",
        "        prediction_span = [prediction_index]\n",
        "        predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "        initiative_index += 1\n",
        "        prediction_index += 1\n",
        "\n",
        "    return predictions_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kncs_eEhsoJV"
      },
      "outputs": [],
      "source": [
        "class Initiative_Evaluation():\n",
        "    \"\"\" Class used to evaluate what % of initiatives have been correctly indentified.\n",
        "    \"\"\"\n",
        "    def __init__(self, initiative_dict, predictions_dict):\n",
        "        self.initiative_dict = initiative_dict\n",
        "        self.predictions_dict = predictions_dict\n",
        "        self.no_initiatives = len(self.initiative_dict)\n",
        "    \n",
        "    def evaluate(self):\n",
        "        if len(self.initiative_dict) == len(self.predictions_dict) == 0:\n",
        "            fully_correctly_labeled_proportion =  1\n",
        "            half_correctly_labeled_proportion = 1\n",
        "            min_correctly_labeled_proportion = 1\n",
        "            fully_correct_F1 = 1\n",
        "            half_correct_F1 = 1\n",
        "            min_correct_F1 = 1\n",
        "            return fully_correctly_labeled_proportion, half_correctly_labeled_proportion, min_correctly_labeled_proportion, fully_correct_F1, half_correct_F1, min_correct_F1\n",
        "        else:\n",
        "            # initiatize counters for true positive predictions\n",
        "            fully_correct_TP = 0\n",
        "            half_correct_TP = 0\n",
        "            min_correct_TP = 0\n",
        "            \n",
        "            # initialize lists which contain prediction IDs\\\n",
        "            #  for the first correct prediction encountered across all initatives\n",
        "            fully_correct_double_count = []\n",
        "            half_correct_double_count = []\n",
        "            min_correct_double_count = []\n",
        "\n",
        "            for initiative_ID, initiative_positions_list in self.initiative_dict.items():\n",
        "                # Keep a record of the first prediction id considered to be a success for each initiative\n",
        "                fully_correct_match_pred_ID = []\n",
        "                half_correct_match_pred_ID = []\n",
        "                min_correct_match_pred_ID = []\n",
        "                for prediction_ID, prediction_positions_list in self.predictions_dict.items():\n",
        "                    if set(initiative_positions_list).intersection(prediction_positions_list): #check if the initiative span overlaps with the predicted span\n",
        "                        if (len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) == 1)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) == 1):\n",
        "                                if (len(fully_correct_match_pred_ID) == 0) and (prediction_ID not in fully_correct_double_count): \n",
        "                                    fully_correct_match_pred_ID.append(prediction_ID)\n",
        "                                    fully_correct_TP += 1\n",
        "                        if(len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) >= 0.5)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) >= 0.5):\n",
        "                                if (len(half_correct_match_pred_ID) == 0) and (prediction_ID not in half_correct_double_count):\n",
        "                                    half_correct_match_pred_ID.append(prediction_ID)\n",
        "                                    half_correct_TP += 1\n",
        "                        if(len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) > 0)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) > 0):\n",
        "                                if (len(min_correct_match_pred_ID) == 0) and (prediction_ID not in min_correct_double_count): \n",
        "                                        min_correct_match_pred_ID.append(prediction_ID)\n",
        "                                        min_correct_TP += 1\n",
        "                fully_correct_double_count.extend(fully_correct_match_pred_ID)\n",
        "                half_correct_double_count.extend(half_correct_match_pred_ID)\n",
        "                min_correct_double_count.extend(min_correct_match_pred_ID)\n",
        "                        \n",
        "\n",
        "            fully_correct_FN, fully_correct_FP = self.compute_FN_FP(fully_correct_TP)\n",
        "            fully_correct_F1, fully_correct_precision, fully_correct_recall = self.compute_F1(fully_correct_TP, fully_correct_FP, fully_correct_FN)\n",
        "\n",
        "            half_correct_FN, half_correct_FP = self.compute_FN_FP(half_correct_TP)\n",
        "            half_correct_F1, half_correct_precision, half_correct_recall = self.compute_F1(half_correct_TP, half_correct_FP, half_correct_FN)\n",
        "\n",
        "            min_correct_FN, min_correct_FP = self.compute_FN_FP(min_correct_TP)\n",
        "            min_correct_F1, min_correct_precision, min_correct_recall = self.compute_F1(min_correct_TP, min_correct_FP, min_correct_FN)\n",
        "\n",
        "            fully_correctly_labeled_proportion = fully_correct_TP/self.no_initiatives\n",
        "            half_correctly_labeled_proportion = half_correct_TP/self.no_initiatives\n",
        "            min_correctly_labeled_proportion = min_correct_TP/self.no_initiatives\n",
        "            \n",
        "            return fully_correctly_labeled_proportion, half_correctly_labeled_proportion, min_correctly_labeled_proportion, fully_correct_F1, half_correct_F1, min_correct_F1, fully_correct_precision, fully_correct_recall, half_correct_precision, half_correct_recall, min_correct_precision, min_correct_recall\n",
        "    \n",
        "    def compute_F1(self, TP, FP, FN):\n",
        "        \"\"\" Utility method to compute F1 score\n",
        "        \"\"\"\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        if precision == recall == 0:\n",
        "            F1 = 0\n",
        "        else:\n",
        "            F1 = 2 * precision * recall /(precision + recall)\n",
        "        return F1, precision, recall\n",
        "    \n",
        "    def compute_FN_FP(self, TP):\n",
        "        \"\"\" Utility method to compute FN and FP initiatives given the no of TP \n",
        "        (defined as the set intersection between gold initiative span and prediction span)\n",
        "        \"\"\"\n",
        "        FN = len(self.initiative_dict) - TP\n",
        "        FP = len(self.predictions_dict) - TP\n",
        "        return FN, FP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R7dTM4hULGj"
      },
      "outputs": [],
      "source": [
        "# Unit tests for Initiative_Evaluation Class\n",
        "mock_initiative_dict_1 = {1:[1,2], 2:[3,4]}\n",
        "mock_predictions_dict_1 = {1: [1,2], 2:[3], 3:[4]}\n",
        "mock_evaluation_1 = Initiative_Evaluation(mock_initiative_dict_1, mock_predictions_dict_1)\n",
        "mock_init_strict_accuracy_1, mock_init_medium_accuracy_1, mock_init_lenient_accuracy_1, mock1_fully_correct_F1, mock1_half_correct_F1, mock1_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_1.evaluate()\n",
        "assert mock_init_strict_accuracy_1 == 0.5\n",
        "assert mock_init_medium_accuracy_1 == 1\n",
        "assert mock_init_lenient_accuracy_1 == 1\n",
        "assert mock1_fully_correct_F1 == 0.4\n",
        "assert mock1_half_correct_F1 == mock1_min_correct_F1 == 0.8\n",
        "\n",
        "\n",
        "mock_initiative_dict_2 = {1:[1,2], 2:[4,5,6]}\n",
        "mock_predictions_dict_2 = {1: [1,2], 2:[4,5,6]}\n",
        "mock_evaluation_2 = Initiative_Evaluation(mock_initiative_dict_2, mock_predictions_dict_2)\n",
        "mock_init_strict_accuracy_2, mock_init_medium_accuracy_2, mock_init_lenient_accuracy_2, mock2_fully_correct_F1, mock2_half_correct_F1, mock2_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_2.evaluate()\n",
        "assert mock_init_strict_accuracy_2 == 1\n",
        "assert mock_init_medium_accuracy_2 == 1\n",
        "assert mock_init_lenient_accuracy_2 == 1\n",
        "assert mock2_fully_correct_F1 == mock2_half_correct_F1 == mock2_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_3 = {1:[1,2], 2:[3,4]}\n",
        "mock_predictions_dict_3 = {1: [1,2], 2:[3,4]}\n",
        "mock_evaluation_3 = Initiative_Evaluation(mock_initiative_dict_3, mock_predictions_dict_3)\n",
        "mock_init_strict_accuracy_3, mock_init_medium_accuracy_3, mock_init_lenient_accuracy_3, mock3_fully_correct_F1, mock3_half_correct_F1, mock3_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_3.evaluate()\n",
        "assert mock_init_strict_accuracy_3 == 1\n",
        "assert mock_init_medium_accuracy_3 == 1\n",
        "assert mock_init_lenient_accuracy_3 == 1\n",
        "assert mock3_fully_correct_F1 == mock3_half_correct_F1 == mock3_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_4 = {}\n",
        "mock_predictions_dict_4 = {}\n",
        "mock_evaluation_4 = Initiative_Evaluation(mock_initiative_dict_4, mock_predictions_dict_4)\n",
        "mock_init_strict_accuracy_4, mock_init_medium_accuracy_4, mock_init_lenient_accuracy_4, mock4_fully_correct_F1, mock4_half_correct_F1, mock4_min_correct_F1 = mock_evaluation_4.evaluate()\n",
        "assert mock_init_strict_accuracy_4 == 1\n",
        "assert mock_init_medium_accuracy_4 == 1\n",
        "assert mock_init_lenient_accuracy_4 == 1\n",
        "assert mock4_fully_correct_F1 == mock4_half_correct_F1 == mock4_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_5 = {1:[1,2], 2:[3,4,5], 3:[6]}\n",
        "mock_predictions_dict_5 = {1:[1], 2:[2], 3:[3], 4:[4], 5:[5]}\n",
        "mock_evaluation_5 = Initiative_Evaluation(mock_initiative_dict_5, mock_predictions_dict_5)\n",
        "mock_init_strict_accuracy_5, mock_init_medium_accuracy_5, mock_init_lenient_accuracy_5, mock5_fully_correct_F1, mock5_half_correct_F1, mock5_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_5.evaluate()\n",
        "assert mock_init_strict_accuracy_5 == 0\n",
        "assert mock_init_medium_accuracy_5 == 1/3\n",
        "assert mock_init_lenient_accuracy_5 == 2/3\n",
        "assert mock5_fully_correct_F1 == 0\n",
        "assert mock5_half_correct_F1 == 0.25\n",
        "assert mock5_min_correct_F1 == 0.5\n",
        "\n",
        "mock_initiative_dict_6 = {1:[1,2], 2:[3,4,5], 3:[6]}\n",
        "mock_predictions_dict_6 = {1:[1,2,3,4,5,6]}\n",
        "mock_evaluation_6 = Initiative_Evaluation(mock_initiative_dict_6, mock_predictions_dict_6)\n",
        "mock_init_strict_accuracy_6, mock_init_medium_accuracy_6, mock_init_lenient_accuracy_6, mock6_fully_correct_F1, mock6_half_correct_F1, mock6_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_6.evaluate()\n",
        "assert mock_init_strict_accuracy_6 == 0\n",
        "assert mock_init_medium_accuracy_6 == 1/3\n",
        "assert mock_init_lenient_accuracy_6 == 1/3\n",
        "assert mock6_fully_correct_F1 == 0\n",
        "assert mock6_half_correct_F1 == mock6_min_correct_F1 == 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM5U12qZtB92",
        "outputId": "ca6f884f-6c55-42ef-8b9e-0e55af25afbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file final_roberta_paper/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"Sustainable_RoBERTa\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.11.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file final_roberta_paper/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing Sustainable_RoBERTa.\n",
            "\n",
            "All the weights of Sustainable_RoBERTa were initialized from the model checkpoint at final_roberta_paper.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Sustainable_RoBERTa for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting results on dev set took 382.4022033214569 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform context predictions on dev dataset\n",
        "start_time = time.time()\n",
        "sustainable_model = Sustainable_RoBERTa.from_pretrained('final_roberta_2_sent_paper') \n",
        "loaded_crf_model = torch.load('crf_RoBERTa_2_sent_paper.pt') \n",
        "dev_predictions_list = model_predict(sustainable_model, tokenizer, dev_loader, device, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, crf_model = loaded_crf_model)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on dev set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the dev set\n",
        "dev_pred_mapping, dev_predictions = reconcile_mapping(dev_data, pre_labeled_dev_data, dev_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioIJdeSTtB92",
        "outputId": "397ff7c3-3000-4d01-8a6c-2220bc2f87bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on the Development Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9793    0.9870    0.9831     53854\n",
            "    Singleton     0.3380    0.2877    0.3108       504\n",
            "    Beginning     0.3482    0.2599    0.2976       481\n",
            "       Inside     0.2338    0.1161    0.1552       310\n",
            "          End     0.2379    0.2037    0.2195       481\n",
            "\n",
            "     accuracy                         0.9627     55630\n",
            "    macro avg     0.4274    0.3709    0.3932     55630\n",
            " weighted avg     0.9575    0.9627    0.9599     55630\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract ground truth dev data labels\n",
        "dev_label_values = []\n",
        "dev_report_numbers = []\n",
        "for sent_no in range(len(development_data)):\n",
        "  dev_report_numbers.append(development_data[sent_no][0]['report_no'])\n",
        "  if development_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = development_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(development_data[sent_no][0]['report_no'])\n",
        "    if len(dev_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      dev_label_values.append(development_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif dev_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      dev_label_values.append(2) #append 2 for beginning of initiative\n",
        "    elif dev_initiative_dict[initiative_unique_reference].index(sent_no) == (len(dev_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      dev_label_values.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      dev_label_values.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    dev_label_values.append(development_data[sent_no][2]['has_initiative'])\n",
        "\n",
        "\n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Development Dataset \\n')\n",
        "print(classification_report(dev_label_values, np.array(dev_predictions), target_names = target_names, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkeXSSd8soJW",
        "outputId": "a3ccb2e2-43ea-484d-e7dc-edb49833c78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 48.73% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 40.30% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 24.87% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 45.52% \n",
            "\n",
            "Precision score where at least 1 sentence is identified is 42.70% \n",
            "\n",
            "Recall score where at least 1 sentence is identified is 48.73% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 37.65% \n",
            "\n",
            "Precision score where 50% of sentences are identified is 35.32% \n",
            "\n",
            "Recal score where 50% of sentences are identified is 40.30% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 23.23% \n",
            "\n",
            "Precision score where 100% of sentences are identified is 21.80% \n",
            "\n",
            "Recall score where 100% of sentences are identified is 24.87% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "dev_predictions_dict = sentence_to_initiative_aggregation(dev_predictions, dev_report_numbers)\n",
        "dev_init_evaluation = Initiative_Evaluation(dev_initiative_dict, dev_predictions_dict)\n",
        "dev_init_strict_accuracy, dev_init_medium_accuracy, dev_init_lenient_accuracy, dev_strict_F1, dev_medium_F1, dev_lenient_F1, dev_strict_precision, dev_strict_recall, dev_medium_precision, dev_medium_recall, dev_lenient_precision, dev_lenient_recall = dev_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {dev_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {dev_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {dev_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {dev_lenient_F1:.2%} \\n')\n",
        "print(f'Precision score where at least 1 sentence is identified is {dev_lenient_precision:.2%} \\n')\n",
        "print(f'Recall score where at least 1 sentence is identified is {dev_lenient_recall:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {dev_medium_F1:.2%} \\n')\n",
        "print(f'Precision score where 50% of sentences are identified is {dev_medium_precision:.2%} \\n')\n",
        "print(f'Recal score where 50% of sentences are identified is {dev_medium_recall:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {dev_strict_F1:.2%} \\n')\n",
        "print(f'Precision score where 100% of sentences are identified is {dev_strict_precision:.2%} \\n')\n",
        "print(f'Recall score where 100% of sentences are identified is {dev_strict_recall:.2%} \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TKuUMTlaWZp",
        "outputId": "6e89a7ee-58f6-4909-ec65-5346bbd8c96a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file final_roberta_paper/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"Sustainable_RoBERTa\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.11.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file final_roberta_paper/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing Sustainable_RoBERTa.\n",
            "\n",
            "All the weights of Sustainable_RoBERTa were initialized from the model checkpoint at final_roberta_paper.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Sustainable_RoBERTa for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting results on test set took 335.60777282714844 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform predictions on test dataset\n",
        "start_time = time.time()\n",
        "sustainable_model = Sustainable_RoBERTa.from_pretrained('final_roberta_2_sent_paper')\n",
        "loaded_crf_model = torch.load('crf_RoBERTa_2_sent_paper.pt') \n",
        "test_predictions_list = model_predict(sustainable_model, tokenizer, test_loader, device,  global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, crf_model = loaded_crf_model)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on test set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the train set\n",
        "test_pred_mapping, test_predictions = reconcile_mapping(test_data, pre_labeled_test_data, test_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5UC4ohhaWZp",
        "outputId": "c15b6bc2-a002-41b4-d76b-1ccaa90368d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on the Test Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9793    0.9764    0.9778     48175\n",
            "    Singleton     0.2730    0.3137    0.2919       577\n",
            "    Beginning     0.2674    0.2662    0.2668       447\n",
            "       Inside     0.1900    0.1803    0.1850       233\n",
            "          End     0.2229    0.2573    0.2388       447\n",
            "\n",
            "     accuracy                         0.9522     49879\n",
            "    macro avg     0.3865    0.3988    0.3921     49879\n",
            " weighted avg     0.9542    0.9522    0.9532     49879\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_label_values = []\n",
        "test_report_numbers = []\n",
        "for sent_no in range(len(testing_data)):\n",
        "  test_report_numbers.append(testing_data[sent_no][0]['report_no'])\n",
        "  if testing_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = testing_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(testing_data[sent_no][0]['report_no'])\n",
        "    if len(test_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      test_label_values.append(testing_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif test_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      test_label_values.append(2) #append 2 for beginning of initiative\n",
        "    elif test_initiative_dict[initiative_unique_reference].index(sent_no) == (len(test_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      test_label_values.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      test_label_values.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    test_label_values.append(testing_data[sent_no][2]['has_initiative'])\n",
        "\n",
        "\n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Test Dataset \\n')\n",
        "print(classification_report(test_label_values, np.array(test_predictions), target_names = target_names, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHREX4AzaWZp",
        "outputId": "1f38ec95-9a5a-46b9-b46e-301d7960081e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 50.10% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 42.97% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 26.66% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 39.66% \n",
            "\n",
            "Precision score where at least 1 sentence is identified is 32.82% \n",
            "\n",
            "Recall score where at least 1 sentence is identified is 50.10% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 34.02% \n",
            "\n",
            "Precision score where 50% of sentences are identified is 28.15% \n",
            "\n",
            "Recal score where 50% of sentences are identified is 42.97% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 21.11% \n",
            "\n",
            "Precision score where 100% of sentences are identified is 17.47% \n",
            "\n",
            "Recall score where 100% of sentences are identified is 26.66% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "test_predictions_dict = sentence_to_initiative_aggregation(test_predictions, test_report_numbers)\n",
        "test_init_evaluation = Initiative_Evaluation(test_initiative_dict, test_predictions_dict)\n",
        "test_init_strict_accuracy, test_init_medium_accuracy, test_init_lenient_accuracy, test_strict_F1, test_medium_F1, test_lenient_F1, test_strict_precision, test_strict_recall, test_medium_precision, test_medium_recall, test_lenient_precision, test_lenient_recall  = test_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {test_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {test_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {test_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {test_lenient_F1:.2%} \\n')\n",
        "print(f'Precision score where at least 1 sentence is identified is {test_lenient_precision:.2%} \\n')\n",
        "print(f'Recall score where at least 1 sentence is identified is {test_lenient_recall:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {test_medium_F1:.2%} \\n')\n",
        "print(f'Precision score where 50% of sentences are identified is {test_medium_precision:.2%} \\n')\n",
        "print(f'Recal score where 50% of sentences are identified is {test_medium_recall:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {test_strict_F1:.2%} \\n')\n",
        "print(f'Precision score where 100% of sentences are identified is {test_strict_precision:.2%} \\n')\n",
        "print(f'Recall score where 100% of sentences are identified is {test_strict_recall:.2%} \\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf2aN65ztB92",
        "outputId": "9ac4510b-1238-4b44-fc74-1328ab29cc7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting results on train set took 553.196225643158 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform predictions on train dataset\n",
        "start_time = time.time()\n",
        "train_predictions_list = model_predict(sustainable_model, tokenizer, train_loader, device,  global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, crf_model = loaded_crf_model)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on train set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the train set\n",
        "train_pred_mapping, train_predictions = reconcile_mapping(train_data, pre_labeled_train_data, train_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daVKMN0stB93",
        "outputId": "4229e90b-377d-4199-cea9-27bea9acf4b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on the Training Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9997    0.9989    0.9993     83801\n",
            "    Singleton     0.9857    0.9876    0.9866      1045\n",
            "    Beginning     0.9793    0.9970    0.9880       995\n",
            "       Inside     0.9330    0.9905    0.9609       633\n",
            "          End     0.9821    0.9940    0.9880       995\n",
            "\n",
            "     accuracy                         0.9986     87469\n",
            "    macro avg     0.9760    0.9936    0.9846     87469\n",
            " weighted avg     0.9986    0.9986    0.9986     87469\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_labels = []\n",
        "train_report_numbers = []\n",
        "for sent_no in range(len(training_data)):\n",
        "  train_report_numbers.append(training_data[sent_no][0]['report_no'])\n",
        "  if training_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = training_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(training_data[sent_no][0]['report_no'])\n",
        "    if len(train_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      training_labels.append(training_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif train_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      training_labels.append(2) #append 2 for beginning of initiative\n",
        "    elif train_initiative_dict[initiative_unique_reference].index(sent_no) == (len(train_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      training_labels.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      training_labels.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    training_labels.append(training_data[sent_no][2]['has_initiative'])\n",
        "    \n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Training Dataset \\n')\n",
        "print(classification_report(training_labels, np.array(train_predictions), target_names = target_names, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY5BwgnLsoJX",
        "outputId": "b9ec41c5-51fb-4d0a-9be7-948a6c8b2ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 99.51% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 93.63% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 88.38% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 88.32% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 83.10% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 78.44% \n",
            "\n",
            "Evaluating initiatives on the train set took 2.393892526626587 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "train_predictions_dict = sentence_to_initiative_aggregation(train_predictions, train_report_numbers)\n",
        "train_init_evaluation = Initiative_Evaluation(train_initiative_dict, train_predictions_dict)\n",
        "train_init_strict_accuracy, train_init_medium_accuracy, train_init_lenient_accuracy, train_strict_F1, train_medium_F1, train_lenient_F1, train_strict_precision, train_strict_recall, train_medium_precision, train_medium_recall, train_lenient_precision, train_lenient_recall  = train_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {train_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {train_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {train_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {train_lenient_F1:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {train_medium_F1:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {train_strict_F1:.2%} \\n')\n",
        "end_time = time.time()\n",
        "print(f'Evaluating initiatives on the train set took {end_time-start_time} seconds')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RoBERTa_sustainability_2_sent_context_paper.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "83822c0cf896608929095f1043a98f7e1bb9e3e58b660cf90b3c0a24621313f4"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('sustainability': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05a205bbd6714d96aa45ab56dbf6fd9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1768148e3bc148dfa0df5213c1c267a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b4613e7962d4098ae28561023788bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21594558872141458c6b00c36247c5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26d86352d090424f93db82de2e835384",
            "placeholder": "​",
            "style": "IPY_MODEL_f76eea2d29f246598346a60d2a2cda6c",
            "value": " 1.29M/1.29M [00:01&lt;00:00, 1.79MB/s]"
          }
        },
        "26d86352d090424f93db82de2e835384": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f019e7247943bba565306a69b3234f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a33ac57dc124d629eb2bbc7c77e4fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a205bbd6714d96aa45ab56dbf6fd9b",
            "placeholder": "​",
            "style": "IPY_MODEL_5f66e6c7d83c409995fe30fda463b0d1",
            "value": "Downloading: 100%"
          }
        },
        "2aae3649596341e79e1906ce07fa67f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d937500c5f941069e6d582f234b3b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e6fd78228414ce89c37ac7854b7daef",
            "placeholder": "​",
            "style": "IPY_MODEL_b6e6d9f717fc4c9497f0078646d2dc29",
            "value": " 878k/878k [00:00&lt;00:00, 757kB/s]"
          }
        },
        "2d9af150b641481da705db2d0e370d32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30dee97a0d35424c99d05283963dd64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35fd8d5658134ab7a85ea7f6bb10d89a",
            "placeholder": "​",
            "style": "IPY_MODEL_da4139276d0e4211bf42b6ce79510dcd",
            "value": "Downloading: 100%"
          }
        },
        "31666f2daecd4d62b2e5c18d28d9902e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35fd8d5658134ab7a85ea7f6bb10d89a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3edde62876004b5dab9528b09e5f9853": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee288bb667947259c3e24048c8296f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b1399c6b3c42ed916c24a3adac98ab",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e701c415b4d4696880223b38395aa28",
            "value": 456318
          }
        },
        "40020e4c964e4833a881540e8277a244": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30dee97a0d35424c99d05283963dd64b",
              "IPY_MODEL_3ee288bb667947259c3e24048c8296f2",
              "IPY_MODEL_a3036e59fc154e9cb4bfbdccb279c38e"
            ],
            "layout": "IPY_MODEL_e1eba24f36e44f4a84f35c9750a754c4"
          }
        },
        "496d0b8f73ee4b48b7de5de97e807baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aa4478a7034490383f9c5d389f3e774": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "550591b550d8455fa0a1cddbe9864889": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e705cbb4af4f46ed84b34c3420eaa845",
            "placeholder": "​",
            "style": "IPY_MODEL_8cfd580048db4830b28a8ce84f007ef0",
            "value": "Downloading: 100%"
          }
        },
        "589171d1e8734c98a5005fade5fae482": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e25a366883b4ef8bb26a2286f5eb67d",
              "IPY_MODEL_df018cc9dbd447a3882ffb5675ab26cf",
              "IPY_MODEL_8e3adf87f6ab401ab2130339b9aa803d"
            ],
            "layout": "IPY_MODEL_ba2881c5ee9b4b45ad4002e5e86f5a8a"
          }
        },
        "5f333eab26ef4c038343f4c4aa32d053": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e69de6e4754f48975d784e6f3f7504",
            "max": 1957,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31666f2daecd4d62b2e5c18d28d9902e",
            "value": 1957
          }
        },
        "5f66e6c7d83c409995fe30fda463b0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62ccdb1d12b14c4c85ded8402f10fa8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6977934515040f99d13cddd493cd15e",
            "placeholder": "​",
            "style": "IPY_MODEL_8d6eb18ebfc84a3996914f29b6a08c53",
            "value": "Downloading: "
          }
        },
        "69116deebf084cdabcda4a7fba80cf83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c130dddc9154c13941be986fc7e3422": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de306b9deb64e08b6f4eb604dff4d69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f1ca37d01404fa19f48d591d0401b23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e25a366883b4ef8bb26a2286f5eb67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3edde62876004b5dab9528b09e5f9853",
            "placeholder": "​",
            "style": "IPY_MODEL_8afde644ebd84318ad478d1e6d5f3f01",
            "value": "Downloading: 100%"
          }
        },
        "81c95544e2ac498fa2ddd389103c7ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ec56abbdc3c478f865aad15658853e4",
            "placeholder": "​",
            "style": "IPY_MODEL_9ca85d52278d493989a905c60a565402",
            "value": " 4.64k/? [00:00&lt;00:00, 92.8kB/s]"
          }
        },
        "89ac185e81094a72bb5419995311635a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8afde644ebd84318ad478d1e6d5f3f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cf481d391564eff92f58b1d9a80d9cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1768148e3bc148dfa0df5213c1c267a2",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d17777fc82094edfa2a845931402dab0",
            "value": 1355863
          }
        },
        "8cfd580048db4830b28a8ce84f007ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d6eb18ebfc84a3996914f29b6a08c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e3adf87f6ab401ab2130339b9aa803d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f9d9e1024ee4026bd68a5ca438ddf3d",
            "placeholder": "​",
            "style": "IPY_MODEL_dd39d7e841174ee284c5fb11fa36d34b",
            "value": " 478M/478M [00:15&lt;00:00, 32.3MB/s]"
          }
        },
        "8ec14c129667461baa4a2cdb98d2a3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca85d52278d493989a905c60a565402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e6fd78228414ce89c37ac7854b7daef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e701c415b4d4696880223b38395aa28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ec56abbdc3c478f865aad15658853e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f9d9e1024ee4026bd68a5ca438ddf3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1bf21da90694452b37c030f33a1ff36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9ec26e98e8c45dfbc5ee038481b2f87",
              "IPY_MODEL_eb83ded728f14ac5a71d07f21b0fafe0",
              "IPY_MODEL_2d937500c5f941069e6d582f234b3b0c"
            ],
            "layout": "IPY_MODEL_28f019e7247943bba565306a69b3234f"
          }
        },
        "a3036e59fc154e9cb4bfbdccb279c38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8705c1ed3e34dbb823289c3f26bb725",
            "placeholder": "​",
            "style": "IPY_MODEL_4aa4478a7034490383f9c5d389f3e774",
            "value": " 446k/446k [00:00&lt;00:00, 514kB/s]"
          }
        },
        "ae710338a80c4ee0b5a1204995b87a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62ccdb1d12b14c4c85ded8402f10fa8e",
              "IPY_MODEL_5f333eab26ef4c038343f4c4aa32d053",
              "IPY_MODEL_81c95544e2ac498fa2ddd389103c7ba2"
            ],
            "layout": "IPY_MODEL_8ec14c129667461baa4a2cdb98d2a3e2"
          }
        },
        "b05cb25ff11842288f1a0992195674a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d9af150b641481da705db2d0e370d32",
            "placeholder": "​",
            "style": "IPY_MODEL_f9993deb114b4a9db5fcf2d731e519e9",
            "value": " 481/481 [00:00&lt;00:00, 12.9kB/s]"
          }
        },
        "b6e6d9f717fc4c9497f0078646d2dc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7e69de6e4754f48975d784e6f3f7504": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ec26e98e8c45dfbc5ee038481b2f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4613e7962d4098ae28561023788bfd",
            "placeholder": "​",
            "style": "IPY_MODEL_496d0b8f73ee4b48b7de5de97e807baf",
            "value": "Downloading: 100%"
          }
        },
        "ba2881c5ee9b4b45ad4002e5e86f5a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7388752c944bd2a13d19fc994403e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_550591b550d8455fa0a1cddbe9864889",
              "IPY_MODEL_8cf481d391564eff92f58b1d9a80d9cb",
              "IPY_MODEL_21594558872141458c6b00c36247c5be"
            ],
            "layout": "IPY_MODEL_6c130dddc9154c13941be986fc7e3422"
          }
        },
        "d17777fc82094edfa2a845931402dab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7e69309c14f4aea8c44af4126433ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da4139276d0e4211bf42b6ce79510dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd39d7e841174ee284c5fb11fa36d34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df018cc9dbd447a3882ffb5675ab26cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de306b9deb64e08b6f4eb604dff4d69",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2aae3649596341e79e1906ce07fa67f5",
            "value": 501200538
          }
        },
        "e1eba24f36e44f4a84f35c9750a754c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6977934515040f99d13cddd493cd15e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e705cbb4af4f46ed84b34c3420eaa845": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8285a6d849a47e790ea1a8288093493": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a33ac57dc124d629eb2bbc7c77e4fb3",
              "IPY_MODEL_fbfbaa07ea354ea188e5616ec371b588",
              "IPY_MODEL_b05cb25ff11842288f1a0992195674a2"
            ],
            "layout": "IPY_MODEL_69116deebf084cdabcda4a7fba80cf83"
          }
        },
        "eb83ded728f14ac5a71d07f21b0fafe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f1ca37d01404fa19f48d591d0401b23",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef23eddf101847dc88a7b99ce821a562",
            "value": 898823
          }
        },
        "ef23eddf101847dc88a7b99ce821a562": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3b1399c6b3c42ed916c24a3adac98ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f76eea2d29f246598346a60d2a2cda6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8705c1ed3e34dbb823289c3f26bb725": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9993deb114b4a9db5fcf2d731e519e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbfbaa07ea354ea188e5616ec371b588": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89ac185e81094a72bb5419995311635a",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7e69309c14f4aea8c44af4126433ad9",
            "value": 481
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}