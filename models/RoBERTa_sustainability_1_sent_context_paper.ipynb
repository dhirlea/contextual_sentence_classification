{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ex_4NNmtMT2",
        "outputId": "ef4320b9-2e0c-4042-a21d-56d0f57b0dda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 6.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 76.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 76.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 77.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n",
            "Collecting datasets\n",
            "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
            "\u001b[K     |████████████████████████████████| 290 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 76.8 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 79.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.1.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.7)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 93.9 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 91.8 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 79.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.8.0 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 datasets-1.15.1 frozenlist-1.2.0 fsspec-2021.11.0 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n",
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install pytorch-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Utm8lRFa7Tdt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import  DataLoader\n",
        "from torchcrf import CRF\n",
        "\n",
        "import transformers\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import RobertaTokenizer \n",
        "from transformers.models.roberta import RobertaModel\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_metric\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9kckp85tQGY",
        "outputId": "a385f750-e2a6-4dfb-cbee-a71e6aee1914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI3EsaCQicd8",
        "outputId": "c29a5b9e-9b47-4f30-86c4-84b09e22a813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "%cd /content/drive/MyDrive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chQJjqSw7Tdu",
        "outputId": "9665fd39-928f-4205-b673-b84cbea3f44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "print(use_cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TR1-pIFXtB9t"
      },
      "outputs": [],
      "source": [
        "# Create list of training data files\n",
        "def load_from_directory(directory):\n",
        "    \"\"\"\n",
        "    Utility function to load all json-converted reports into a dataset.\n",
        "    params: directory: string representing location on disk of json files\n",
        "    returns: dataset: list of deserialised jsons\n",
        "    \"\"\"\n",
        "    path = os.getcwd()\n",
        "    path = os.path.join(path, directory)\n",
        "    json_files = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')]\n",
        "\n",
        "    dataset = [] \n",
        "\n",
        "    for filename in json_files: \n",
        "        with open(path+filename, \"r\", encoding='utf-8') as read_file:\n",
        "            dataset.append(json.load(read_file))\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "train_folder = 'json_train/'\n",
        "train_dataset = load_from_directory(train_folder)\n",
        "\n",
        "dev_folder = 'json_develop/'\n",
        "development_dataset = load_from_directory(dev_folder)\n",
        "\n",
        "test_folder = 'json_test/'\n",
        "test_dataset = load_from_directory(test_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xG-4ESe7tB9u"
      },
      "outputs": [],
      "source": [
        "def filter_dataset(input_dataset):\n",
        "    \"\"\" \n",
        "    Utility function to convert input dataset into custom data structure\n",
        "    params: input_dataset: list of deserialised jsons\n",
        "    returns: dictionary with the following structure:\n",
        "            key:  sentence_global_idx value , value:list of dictionaries\n",
        "            dict0: key: report_no, value: int \n",
        "            dict1: key: text, value: string\n",
        "            dict2: key: has_initiative, value: boolean\n",
        "            dict3: key: list_of_initiatives, value: list of strings with initiative IDs\n",
        "            dict4: key: sector, value: list of strings\n",
        "            dict5: key: sdg, value: list of sgd strings (representing sgd number)\n",
        "            dict6: key: sentence_length, value: int  \n",
        "    \"\"\"\n",
        "    structured_data = {}\n",
        "    total_no_reports = len(input_dataset)\n",
        "    sentence_global_idx = 0\n",
        "    re_punctuation_string = '[“”|()%&\\s,_:;/\\'!?-]'\n",
        "\n",
        "    for report_no in range(total_no_reports): \n",
        "        no_sentences_per_report = len(input_dataset[report_no]['tokenised_sentences'])\n",
        "        for sentence_no in range(no_sentences_per_report):\n",
        "            tokenized_sentence = re.split(re_punctuation_string, input_dataset[report_no]['tokenised_sentences'][sentence_no]['text'])\n",
        "            tokenized_sentence = list(filter(None, tokenized_sentence))\n",
        "            if (len(tokenized_sentence) == 0):           \n",
        "                continue\n",
        "            else:\n",
        "                structured_data[sentence_global_idx] = []\n",
        "                structured_data[sentence_global_idx].append({'report_no':report_no}) \n",
        "                structured_data[sentence_global_idx].append({'text':' '.join([elem.lower() for elem in tokenized_sentence])})\n",
        "                if len(input_dataset[report_no]['tokenised_sentences'][sentence_no]['initiative_ids']) > 0:\n",
        "                  structured_data[sentence_global_idx].append({'has_initiative':1})\n",
        "                else:\n",
        "                   structured_data[sentence_global_idx].append({'has_initiative':0})\n",
        "                structured_data[sentence_global_idx].append({'list_of_initiatives': input_dataset[report_no]['tokenised_sentences'][sentence_no]['initiative_ids']}) \n",
        "                \n",
        "                structured_data[sentence_global_idx].append({'sentence_length':len(tokenized_sentence)}) \n",
        "                sentence_global_idx +=1\n",
        "    \n",
        "    return structured_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rqb_rDqdtB9w"
      },
      "outputs": [],
      "source": [
        "# Set up datasets from json files\n",
        "training_data = filter_dataset(train_dataset)\n",
        "development_data = filter_dataset(development_dataset)\n",
        "testing_data = filter_dataset(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uJ2h2bUHtB9y"
      },
      "outputs": [],
      "source": [
        "def assisted_labelling(data, lower_threshold, upper_threshold):\n",
        "    \"\"\"\n",
        "    Utility function which labels all sentences with fewer than the threshold number of tokens as not having a sustainability initiative.\n",
        "    params: data: list of dictionaries\n",
        "            threshold: int representing number of tokens\n",
        "    returns: dictionary {global_sentence_index:boolean label}\n",
        "    \"\"\"\n",
        "    labeled_dataset = {}\n",
        "    for sentence_no in range(len(data)):\n",
        "        tokenized_sentence = re.split(' ', data[sentence_no][1]['text'])\n",
        "        tokenized_sentence_with_alphabetical_chars = [word for word in tokenized_sentence if re.search('[a-zA-Z]', word)]\n",
        "        if (data[sentence_no][4]['sentence_length'] > lower_threshold) & (len(tokenized_sentence_with_alphabetical_chars)!=0) & (data[sentence_no][4]['sentence_length']<upper_threshold):\n",
        "            labeled_dataset[sentence_no] = 1 \n",
        "        else:\n",
        "            labeled_dataset[sentence_no] = 0 # label short, long and non-alphabetical sentences as not having an initiative\n",
        "    return labeled_dataset\n",
        "\n",
        "assistant_labeled_training_data = assisted_labelling(training_data,lower_threshold=5, upper_threshold=100)\n",
        "assistant_labeled_dev_data = assisted_labelling(development_data,lower_threshold=5, upper_threshold=100)\n",
        "assistant_labeled_test_data = assisted_labelling(testing_data, lower_threshold=5, upper_threshold=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Lq_Q9UCl33gd"
      },
      "outputs": [],
      "source": [
        "def reader(dataset, assisted_labels, initiative_dict):\n",
        "    \"\"\"\n",
        "    Utility function read in the data together with assisted labels and return a train dictionary and a pre-labelled dictionary.\n",
        "    params: dataset: dict {global_sentence_index : list of 7 dictionaries}\n",
        "            assisted_labels: dict {global_sentence_index : assistant label}\n",
        "    returns: train_dict: dict\n",
        "             pre_labelled_dict\n",
        "    \"\"\"\n",
        "    texts = []\n",
        "    labels = []\n",
        "    positions = []\n",
        "    initiative_IDs = []\n",
        "    report_no = []\n",
        "    \n",
        "    pre_labeled_texts =[]\n",
        "    pre_labeled_labels =[]\n",
        "    pre_labeled_positions =[]\n",
        "    pre_labeled_IDs = []\n",
        "\n",
        "    for sentence_no in range(len(dataset)):\n",
        "        if assisted_labels[sentence_no] == 1:\n",
        "            report_no.append(dataset[sentence_no][0]['report_no'])\n",
        "            texts.append(dataset[sentence_no][1]['text'])\n",
        "            if dataset[sentence_no][3]['list_of_initiatives']: #check whether the sentence has an initiative\n",
        "              initiative_unique_reference = dataset[sentence_no][3]['list_of_initiatives'][0] + '_' + str(dataset[sentence_no][0]['report_no'])\n",
        "              if len(initiative_dict[initiative_unique_reference]) == 1:\n",
        "                labels.append(dataset[sentence_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "              elif initiative_dict[initiative_unique_reference].index(sentence_no) == 0:\n",
        "                labels.append(2) #append 2 for beginning of initiative\n",
        "              elif initiative_dict[initiative_unique_reference].index(sentence_no) == (len(initiative_dict[initiative_unique_reference]) - 1):\n",
        "                labels.append(4) #append 4 for end of initiative\n",
        "              else:\n",
        "                labels.append(3) #append 3 for inside an initiative\n",
        "            else:\n",
        "              labels.append(dataset[sentence_no][2]['has_initiative'])\n",
        "            positions.append(sentence_no)\n",
        "            initiative_IDs.append(dataset[sentence_no][3]['list_of_initiatives'])\n",
        "        else:\n",
        "            pre_labeled_texts.append(dataset[sentence_no][1]['text'])\n",
        "            pre_labeled_labels.append(assisted_labels[sentence_no]) # append 0 for non-initiative sentences\n",
        "            pre_labeled_positions.append(sentence_no)\n",
        "            pre_labeled_IDs.append(dataset[sentence_no][3]['list_of_initiatives'])\n",
        "\n",
        "    actual_data_dict = {'texts':texts, 'labels':labels, 'positions':positions, 'ID_list':initiative_IDs, 'report_no':report_no}\n",
        "    pre_labeled_dict = {'texts':pre_labeled_texts, 'labels':pre_labeled_labels, 'positions': pre_labeled_positions, 'ID_list':pre_labeled_IDs}\n",
        "            \n",
        "    return actual_data_dict, pre_labeled_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FrxI7zhZzd_I"
      },
      "outputs": [],
      "source": [
        "def context_builder(data_dict, left_context_size = 0, right_context_size = 0):\n",
        "    context = []\n",
        "    multi_sentence_labels = []\n",
        "    for sentence_index in range(len(data_dict['texts'])):\n",
        "        sentence_context = []\n",
        "        sentence_context_labels = []\n",
        "        if (sentence_index - left_context_size >= 0) and (sentence_index + right_context_size < len(data_dict['texts'])):\n",
        "            # test if target sentence is in the middle of the corpus\n",
        "            for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                if data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]:\n",
        "                    sentence_context.append(data_dict['texts'][context_index])\n",
        "                    sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        elif sentence_index - left_context_size >= 0: #if target sentence is at end of the corpus \n",
        "            for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                if context_index < len(data_dict['texts']): # add in a smaller context window at end of the corpus\n",
        "                    if (data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]):\n",
        "                        sentence_context.append(data_dict['texts'][context_index])\n",
        "                        sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        elif sentence_index + right_context_size < len(data_dict['texts']): #if target sentence is at beginning of the corpus \n",
        "                for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                    if context_index >= 0: # add in smaller context window at the beginning of the corpus\n",
        "                        if (data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]):\n",
        "                            sentence_context.append(data_dict['texts'][context_index])\n",
        "                            sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        context.append(sentence_context)\n",
        "        while len(sentence_context_labels) < (1 + left_context_size + right_context_size): # pad with 0 labels for senteces with a smaller context eg. beginning/end of docs\n",
        "          sentence_context_labels.append(0)\n",
        "        multi_sentence_labels.append(sentence_context_labels)\n",
        "    return context, multi_sentence_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9D9lIa3R6cRb"
      },
      "outputs": [],
      "source": [
        "class SustainableDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Dataset class inheriting from pytorch to be used by dataloaders.\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer, input_set, input_context, input_multi_sentence_labels, max_paragraph_length, global_target_sentence_index):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = input_set['texts']\n",
        "        self.labels = input_set['labels']\n",
        "        self.report_nos = input_set['report_no']\n",
        "        self.contexts = input_context\n",
        "        self.context_labels = input_multi_sentence_labels\n",
        "        self.max_paragraph_length = max_paragraph_length\n",
        "        self.global_target_sentence_index = global_target_sentence_index\n",
        "        \n",
        "        \n",
        "    def collate_fn(self, batch):\n",
        "        texts = [b['text'] for b in batch]\n",
        "        labels = [b['label'] for b in batch]\n",
        "        contexts = [b['context'] for b in batch]\n",
        "        context_labels = [b['context_label'] for b in batch]\n",
        "        encodings, sep_positions = self.custom_tokenizer(batch = contexts) \n",
        "        encodings['labels'] =  torch.tensor(context_labels) # pass through labels for all sentences\n",
        "        encodings['sep_positions'] = sep_positions\n",
        "        return encodings\n",
        "    \n",
        "    def custom_collate_fn(self, batch):\n",
        "      texts = [b['text'] for b in batch]\n",
        "      labels = [b['label'] for b in batch]\n",
        "      contexts = [b['context'] for b in batch]\n",
        "      context_labels = [b['context_label'] for b in batch]\n",
        "      return {'texts':texts, 'labels':labels, 'contexts':contexts, 'context_labels':context_labels}\n",
        "    \n",
        "\n",
        "    def custom_tokenizer(self, batch):\n",
        "      \"\"\" Utility functions to tokenize a list of sentences using [SEP] at the beginning of each sentence with fixed positions.\n",
        "      \"\"\"\n",
        "      batch_sequences = []\n",
        "      batch_sep_positions = []\n",
        "      for sequence_list in batch:\n",
        "        augmented_sequence = ' '\n",
        "        for sentence in sequence_list:     \n",
        "          if sentence != sequence_list[-1]:\n",
        "                augmented_sequence += sentence + ' </s> '\n",
        "          else:\n",
        "            augmented_sequence += sentence\n",
        "        batch_sequences.append(augmented_sequence)\n",
        "      encoded_batch = self.tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt')\n",
        "      for encoded_sequence in encoded_batch['input_ids']:\n",
        "          sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==2]\n",
        "          while len(sep_positions) < self.max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "            sep_positions.append(sep_positions[-1])\n",
        "          batch_sep_positions.append(sep_positions)\n",
        "       \n",
        "      return encoded_batch, batch_sep_positions\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {'text': self.texts[idx],\n",
        "                'label': self.labels[idx],\n",
        "                'context': self.contexts[idx],\n",
        "                'context_label' : self.context_labels[idx],\n",
        "                }\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U9odLvcadGWg"
      },
      "outputs": [],
      "source": [
        "def get_sep_positions(data_loader, global_target_sentence_index, max_paragraph_length, tokenizer):\n",
        "  \"\"\" Utility function to get sep positions for given dataset.\n",
        "  \"\"\"\n",
        "  dataset_sep_positions = []\n",
        "  for batch in data_loader:\n",
        "      batch_sep_positions = []\n",
        "      batch_sequences = []\n",
        "      for sequence_list in batch['contexts']:\n",
        "        augmented_sequence = ' '\n",
        "        for sentence in sequence_list:\n",
        "            if sentence != sequence_list[-1]:\n",
        "              augmented_sequence += sentence + ' </s> '\n",
        "            else:\n",
        "              augmented_sequence += sentence\n",
        "        batch_sequences.append(augmented_sequence)\n",
        "      encoded_batch = tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt')\n",
        "      for encoded_sequence in encoded_batch['input_ids']:\n",
        "          sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==2]\n",
        "          while len(sep_positions) < max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "            sep_positions.append(sep_positions[-1])\n",
        "          batch_sep_positions.append(sep_positions)\n",
        "      dataset_sep_positions.extend([sublist[:-1] for sublist in batch_sep_positions]) \n",
        "  return dataset_sep_positions\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "r92owFJgsoJV"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary with ID_reportNo as keys and values as list of sentence indices\n",
        "def create_init_dict(data):\n",
        "    \"\"\" Utility function to extract individual initiatives as keys of a dict and a list of corresponding global sentence indices.\n",
        "    \"\"\"\n",
        "    initiative_dict = {} #keys are initiative IDs, values are counts of IDs \n",
        "    for sentence_no in range(len(data)):\n",
        "        if data[sentence_no][2]['has_initiative']:\n",
        "            initiative_ID = data[sentence_no][3]['list_of_initiatives'][0]\n",
        "            if (initiative_ID + '_' + str(data[sentence_no][0]['report_no'])) not in initiative_dict.keys():\n",
        "                initiative_dict[initiative_ID + '_' + str(data[sentence_no][0]['report_no'])] = [sentence_no]\n",
        "            else:\n",
        "                initiative_dict[initiative_ID + '_' + str(data[sentence_no][0]['report_no'])].append(sentence_no)\n",
        "    return initiative_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "46563f938bf0488995ea53e990067399",
            "05ff10b0ba1d4fa396e2de1976c02123",
            "f99984bd7f944116b5605df94a79d466",
            "884198cbbfdc49b3a31912949a8ee609",
            "5522641cd03e4d10886e6b8dbeee8d28",
            "6004835f30804ac8bff327562298ec13",
            "0923bf33f7724bab905736a5a4553499",
            "1559bf92eb3b49c2ae5671dc7492c5f9",
            "2be9497f32e84f33a4845168c62e48f0",
            "97a78e07c31641cb9f070db303cdddb3",
            "49a929be29df4ec99dbde254a1c3590d",
            "d1684fef136743edb236573b35a0e1cf",
            "e5f2e570a3be4219a4830c732bac8b9b",
            "9bc7e3478a5440de9d14c412a7cb4bfc",
            "ec690f4ed17b4249b6f80fdb2b850615",
            "52b89de29ee04c2a9cb8f120c4008cfc",
            "3fbb6c84c427457ca8a8f92dba18bf42",
            "0c19c239e96e44d3892a9691db39dc6c",
            "459548995942432bb021ba7b82561c3f",
            "e260f0f3d9654f28b6477289f25704cc",
            "f67a99c9db434d878f5d85d6356a04e2",
            "efd20e002067437db791dbdd46a907a9",
            "e29d387d3448421f9e53a7c823c64148",
            "0c0c6271c6df4c5f9471a1ff820c1de5",
            "27ee695101f04e48b310fbdb2b7e00c2",
            "4e23221d18114bc48eb6c70c987571ac",
            "c169f4f6895d49dd9cbbc84d57e56451",
            "d248ef5a6b6d471ca80518a70e908a16",
            "d1b04aacaddf4b04b6639655a1fd043b",
            "b5f9cbce8b8147ae90b063b31914472a",
            "0b2ef6653873432e8ece10eee9623af0",
            "c874ca81bdcd4da8b62019658fa63363",
            "2c0ba0fe310f46cf95d118e839a1c220",
            "b938e304634241e09815c912922e5acb",
            "c2db1a6328a44caa87b4191bb37081cb",
            "3ee96daaf2884757b5c0e39727e7e4a4",
            "da4fefb003b84b58bd6a32cc05f927b3",
            "4bc9ce86464b451e88f8c31fa4d22769",
            "b25ed60c8ddb48fbadafafa074a9ba1a",
            "817ab743b25949fb8a09e17a6095b992",
            "fb0ec07f210d4783a9844a914aa87785",
            "8406395e291b42b797ed5a5cbac8469d",
            "0a952b998d7e4e5381a4504ed1c80d34",
            "e8a120688ae04eb69018ecbd94f9e5d8"
          ]
        },
        "id": "TyZQtXwj4ixr",
        "outputId": "e7787a3f-0be7-47bc-f79b-b725520f6a66"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46563f938bf0488995ea53e990067399",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1684fef136743edb236573b35a0e1cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e29d387d3448421f9e53a7c823c64148",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b938e304634241e09815c912922e5acb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "global_target_sentence_index = 1 \n",
        "\n",
        "# Create gold standard initiative dictionaries\n",
        "train_initiative_dict = create_init_dict(training_data)\n",
        "dev_initiative_dict = create_init_dict(development_data)\n",
        "test_initiative_dict = create_init_dict(testing_data)\n",
        "\n",
        "# Read in training and dev data and split into data to feed into the model and pre-labeled data\n",
        "train_data, pre_labeled_train_data = reader(training_data, assistant_labeled_training_data, train_initiative_dict)\n",
        "dev_data, pre_labeled_dev_data = reader(development_data, assistant_labeled_dev_data, dev_initiative_dict)\n",
        "test_data, pre_labeled_test_data = reader(testing_data, assistant_labeled_test_data, test_initiative_dict)\n",
        "\n",
        "# Construct context around each sentence per dataset\n",
        "train_context, train_multi_sentence_labels = context_builder(train_data, left_context_size = 1, right_context_size = 1) \n",
        "dev_context, dev_multi_sentence_labels = context_builder(dev_data, left_context_size = 1, right_context_size = 1) \n",
        "test_context, test_multi_sentence_labels = context_builder(test_data, left_context_size = 1, right_context_size = 1)\n",
        "\n",
        "max_paragraph_length = max([len(label_sequence) for label_sequence in train_multi_sentence_labels])\n",
        "\n",
        "# Only data to be fed into the model is built into datasets\n",
        "train_dataset = SustainableDataset(tokenizer, train_data, train_context, train_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "dev_dataset = SustainableDataset(tokenizer, dev_data, dev_context, dev_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "test_dataset = SustainableDataset(tokenizer, test_data, test_context, test_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "\n",
        "# Create train and dev dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, collate_fn = train_dataset.custom_collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False, collate_fn = dev_dataset.custom_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn = test_dataset.custom_collate_fn)\n",
        "\n",
        "# Record sep positions for dev dataset (to be used for early stopping during training)\n",
        "dev_sep_positions = get_sep_positions(dev_loader, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "N-KwKMBsULGd"
      },
      "outputs": [],
      "source": [
        "# Unit tests for building context assuming a window\n",
        "mock_train_context, mock_train_multi_sentence_labels = context_builder(train_data, left_context_size = 1, right_context_size = 1)\n",
        "mock_dev_context, mock_dev_multi_sentence_labels = context_builder(dev_data, left_context_size = 1, right_context_size = 1)\n",
        "mock_train_dataset = SustainableDataset(tokenizer, train_data, mock_train_context, mock_train_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "mock_dev_dataset = SustainableDataset(tokenizer, dev_data, mock_dev_context, mock_dev_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "assert mock_train_dataset.contexts[11] == [mock_train_dataset.texts[10], mock_train_dataset.texts[11], mock_train_dataset.texts[12]]  #random corpus context\n",
        "assert len(mock_train_dataset.contexts) == len(mock_train_dataset.texts) #there is a context for every target sentence in the train set\n",
        "assert mock_dev_dataset.contexts[11] == [mock_dev_dataset.texts[10], mock_dev_dataset.texts[11], dev_dataset.texts[12]] #random corpus context\n",
        "assert len(mock_dev_dataset.contexts) == len(mock_dev_dataset.texts) #there is a context for every target sentence in the dev set\n",
        "assert [mock_train_dataset.texts[0], mock_train_dataset.texts[1] , mock_train_dataset.texts[2]] ==  mock_train_dataset.contexts[1] #the context for the first sentence in the corpus is only the following sentence\n",
        "assert [mock_train_dataset.texts[-2] , mock_train_dataset.texts[-1]] == mock_train_dataset.contexts[-1] #the context for the last sentence in the corpus is only the preceding sentence\n",
        "assert [mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)] , mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)+1]]== mock_train_dataset.contexts[mock_train_dataset.report_nos.index(1)] # first sentence of second report should have a context of only its following sentence\n",
        "assert [mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)-2], mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)-1]] == mock_train_dataset.contexts[mock_train_dataset.report_nos.index(1)-1] # last sentence of first report should have a context of only its preceding sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5Fyf-E4gtB90"
      },
      "outputs": [],
      "source": [
        "# Unit tests -> check if assisted data labelling has been performed correctly\n",
        "assert len(set(pre_labeled_train_data['positions']).intersection(set(train_data['positions']))) == 0 \n",
        "assert (len(train_data['texts']) + len(pre_labeled_train_data['texts'])) == len(training_data)\n",
        "assert set(pre_labeled_train_data['positions']).union(set(train_data['positions'])) == set(range(len(training_data)))\n",
        "assert (len(dev_data['texts']) + len(pre_labeled_dev_data['texts'])) == len(development_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NUOfidVU_zE8"
      },
      "outputs": [],
      "source": [
        "class Sustainable_RoBERTa(RobertaModel):\n",
        "    \"\"\" Transformer model class with custom output layer for fine-tuning.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.roberta = RobertaModel(config)\n",
        "        self.projection = torch.nn.Sequential(torch.nn.Dropout(0.1), torch.nn.Linear(config.hidden_size, 5))              \n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        past_key_values=None,\n",
        "        use_cache=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,):\n",
        " \n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids, \n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        logits = self.projection(outputs.last_hidden_state) \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "O2aWTy5uAHGj"
      },
      "outputs": [],
      "source": [
        "class Trainer_Sustainable(Trainer):\n",
        "    \"\"\" Class inheriting from Trainer to configure loss function used.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "        crf_model,\n",
        "        model = None,\n",
        "        args = None,\n",
        "        data_collator = None,\n",
        "        train_dataset = None,\n",
        "        eval_dataset = None,\n",
        "        tokenizer = None,\n",
        "        model_init = None,\n",
        "        compute_metrics = None,\n",
        "        callbacks = None,\n",
        "        optimizers = (None, None),        \n",
        "        ):\n",
        "        super().__init__(model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\n",
        "        self.crf_model = crf_model\n",
        "\n",
        "    def compute_loss(self, model, inputs, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, return_outputs=False):\n",
        "\n",
        "        labels = inputs.pop('labels')\n",
        "        sep_positions = inputs.pop('sep_positions') # take all sep positions\n",
        "        outputs = model(**inputs)\n",
        "        batch_preds = []\n",
        "        for i, sentence_sep_positions in zip(range(outputs.shape[0]), sep_positions):\n",
        "          sentence_preds = []\n",
        "          for j in sentence_sep_positions:\n",
        "            sentence_preds.append(outputs[i,j])\n",
        "          batch_preds.append(torch.cat(sentence_preds[:-1])) #ignore last sep token as we don't predict from it\n",
        "\n",
        "        preds = torch.cat(batch_preds).reshape((-1, max_paragraph_length, 5)).permute(1,0,2)\n",
        "        labels = labels.permute(1,0)\n",
        " \n",
        "        loss = -1 * self.crf_model(preds, labels)\n",
        "        \n",
        "        if return_outputs: \n",
        "            return (loss, (loss, outputs)) \n",
        "        else:\n",
        "            return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oxRyedCktB91"
      },
      "outputs": [],
      "source": [
        "def model_predict(model, tokenizer, dataloader, device, global_target_sentence_index, max_paragraph_length, crf_model):\n",
        "    \"\"\" Utility function to set the model to GPU and infer of given dataloader.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch_sequences = []\n",
        "            batch_sep_positions = []\n",
        "            for sequence_list in batch['contexts']:\n",
        "              augmented_sequence = ' '\n",
        "              for sentence in sequence_list:\n",
        "                if sentence != sequence_list[-1]:\n",
        "                  augmented_sequence += sentence + ' </s> '\n",
        "                else:\n",
        "                  augmented_sequence += sentence\n",
        "              batch_sequences.append(augmented_sequence)\n",
        "            encoded_batch = tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt').to(device)\n",
        "            for encoded_sequence in encoded_batch['input_ids']:\n",
        "                sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==2]\n",
        "                while len(sep_positions) < max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "                  sep_positions.append(sep_positions[-1])\n",
        "                batch_sep_positions.append(sep_positions)\n",
        "                      \n",
        "            output = model(**encoded_batch) \n",
        "            batch_preds = []\n",
        "            \n",
        "            for i, sentence_sep_positions in zip(range(output.shape[0]), batch_sep_positions):\n",
        "              sentence_preds = []\n",
        "              for j in sentence_sep_positions:\n",
        "                sentence_preds.append(output[i,j])\n",
        "              batch_preds.append(torch.cat(sentence_preds[:-1])) #ignore last sep token as we don't predict from it\n",
        "\n",
        "            preds = torch.cat(batch_preds).reshape((-1, max_paragraph_length, 5)).permute(1,0,2)\n",
        "            predicted_tags = [tag[global_target_sentence_index] for tag in crf_model.decode(preds)]\n",
        "            predictions.extend(predicted_tags)\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f6d52e9f29ff4cc7a305f1fc464b8e63",
            "8f486753cf124f6e89e28944a9cc69c2",
            "8c15ec1faa764b2c9405f27efde1d30e",
            "e8b91b19c26246b8bdf60c5fe9f95288",
            "4128076f2c1e42a78ef54a5f2b651e98",
            "50a832ba3cb14e628a6509bb8a2f8957",
            "e024a1b9276b4de29360aa352335e699",
            "7b84d53c869446ffb6a4c49b49a37463",
            "9b4a39e7c63640db89d838422a428781",
            "c8f02ea506d94d8faf1e236ed13613fd",
            "f55fbd712e0147578c9c6a500668578c",
            "f07143eb663843aaa26bbe40b6d07867",
            "9478a640921044fcb2d1943b027e3cff",
            "63e9184d0c0444269a6251c260734c90",
            "d82184e9ae9a462ebff7d43586950a7d",
            "1ec86f6bb49c47d789b9c6d3904d0486",
            "40cbe276694f405c8ea600ee965a9987",
            "6b1f1b338c1841da8f4ce2e830af4cb8",
            "9c4852834a504c6689d50cd6c27c0618",
            "0b8cb9563a414525b92a544850b63f97",
            "16b8d559578940f19fa1b050f1327ec3",
            "64a7cda51e6f475fa3f4d74c91913960"
          ]
        },
        "id": "8MJmka-LAYIV",
        "outputId": "48a4e410-9d2b-4248-dd92-700964d3bad7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6d52e9f29ff4cc7a305f1fc464b8e63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing Sustainable_RoBERTa: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing Sustainable_RoBERTa from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Sustainable_RoBERTa from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Sustainable_RoBERTa were not initialized from the model checkpoint at roberta-base and are newly initialized: ['encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.attention.self.key.weight', 'projection.1.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'projection.1.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f07143eb663843aaa26bbe40b6d07867",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 36920\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 23070\n",
            "/usr/local/lib/python3.7/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorCompare.cpp:255.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16149' max='23070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16149/23070 1:37:41 < 41:52, 2.75 it/s, Epoch 6/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>10.166700</td>\n",
              "      <td>7.844657</td>\n",
              "      <td>0.236568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.477100</td>\n",
              "      <td>8.471578</td>\n",
              "      <td>0.396133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.358600</td>\n",
              "      <td>10.019837</td>\n",
              "      <td>0.385639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.830400</td>\n",
              "      <td>13.585529</td>\n",
              "      <td>0.372322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.923300</td>\n",
              "      <td>16.768320</td>\n",
              "      <td>0.357750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.463500</td>\n",
              "      <td>20.593695</td>\n",
              "      <td>0.372825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.152300</td>\n",
              "      <td>23.861984</td>\n",
              "      <td>0.367553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-2307\n",
            "Configuration saved in ./roberta_paper/checkpoint-2307/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-2307/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-16149] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-4614\n",
            "Configuration saved in ./roberta_paper/checkpoint-4614/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-4614/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-23070] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-6921\n",
            "Configuration saved in ./roberta_paper/checkpoint-6921/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-6921/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-2307] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-9228\n",
            "Configuration saved in ./roberta_paper/checkpoint-9228/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-9228/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-6921] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-11535\n",
            "Configuration saved in ./roberta_paper/checkpoint-11535/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-11535/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-9228] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-13842\n",
            "Configuration saved in ./roberta_paper/checkpoint-13842/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-13842/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-11535] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./roberta_paper/checkpoint-16149\n",
            "Configuration saved in ./roberta_paper/checkpoint-16149/config.json\n",
            "Model weights saved in ./roberta_paper/checkpoint-16149/pytorch_model.bin\n",
            "Deleting older checkpoint [roberta_paper/checkpoint-13842] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./roberta_paper/checkpoint-4614 (score: 0.3961325807348969).\n",
            "Saving model checkpoint to ./final_roberta_1sent_paper\n",
            "Configuration saved in ./final_roberta_1sent_paper/config.json\n",
            "Model weights saved in ./final_roberta_1sent_paper/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "# Instantiate and train model\n",
        "model = Sustainable_RoBERTa.from_pretrained('roberta-base').to(device)\n",
        "\n",
        "total_epochs = 10   \n",
        "learning_rate = 1e-5 \n",
        "\n",
        "# Create evaluation metric F1 score \n",
        "metric = load_metric('f1')\n",
        "\n",
        "def compute_metrics(eval_pred, sep_positions = dev_sep_positions, global_target_sentence_index = global_target_sentence_index):\n",
        "    raw_predictions, raw_labels = eval_pred \n",
        "    pooled_labels = [label[global_target_sentence_index] for label in raw_labels]\n",
        "    pooled_predictions = []\n",
        "    for i, sentence_sep_positions in zip(range(len(raw_predictions)), sep_positions):\n",
        "        sentence_preds = []\n",
        "        for j in sentence_sep_positions:\n",
        "            sentence_preds.append(torch.tensor(raw_predictions[i,j]))\n",
        "        pred = torch.cat(sentence_preds).reshape((-1, max_paragraph_length, 5)).permute(1,0,2).to(device)\n",
        "        predicted_tag = trainer.crf_model.decode(pred)[0][global_target_sentence_index] \n",
        "        pooled_predictions.append(predicted_tag)   \n",
        "    torch.save(trainer.crf_model, f='crf_RoBERTa_1sent_paper.pt')  # save trained crf model to use at inference time\n",
        "    return metric.compute(predictions=pooled_predictions, references=pooled_labels, average = 'macro')\n",
        "\n",
        "# Define optimizer and lr schedule\n",
        "optimizer = transformers.AdamW(model.parameters(),\n",
        "                  lr = learning_rate, \n",
        "                  )\n",
        "\n",
        "total_steps = len(train_loader) * total_epochs \n",
        "warmup = 0.06 * total_steps\n",
        " \n",
        "# Create the learning rate scheduler.\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup, \n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "# Create training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./roberta_paper_1_sent',\n",
        "    save_total_limit = 2,\n",
        "    learning_rate = learning_rate, \n",
        "    logging_strategy = 'epoch',\n",
        "    per_device_train_batch_size=8, \n",
        "    num_train_epochs = total_epochs, \n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    metric_for_best_model = 'f1',\n",
        "    eval_accumulation_steps=0.1*len(dev_loader),\n",
        "    gradient_accumulation_steps = 2, # effective training batch size of 16\n",
        "    )\n",
        "\n",
        "# Define trainer module\n",
        "trainer = Trainer_Sustainable(\n",
        "    model=model,                         \n",
        "    args=training_args,                 \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,                   \n",
        "    data_collator=train_dataset.collate_fn,\n",
        "    callbacks =[transformers.EarlyStoppingCallback(early_stopping_patience = 5, early_stopping_threshold=-0.03)],\n",
        "    compute_metrics = compute_metrics,\n",
        "    optimizers = (optimizer, scheduler),\n",
        "    crf_model = CRF(num_tags=5).to(device),\n",
        "    )\n",
        "\n",
        "trainer.train() \n",
        "\n",
        "trainer.save_model('./final_roberta_1sent_paper')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nqpGGvvisoJU"
      },
      "outputs": [],
      "source": [
        "def reconcile_mapping(model_data, pre_labeled_data, model_predictions):\n",
        "    \"\"\" Utility function to reconcile mapping between pre-labeled data and model predictions.\n",
        "    params: predictions: list of model predictions\n",
        "            pre_labeled_data: dictionary outputted from reader function\n",
        "    returns: pred_mapping: dict\n",
        "             predictions: dict\n",
        "    \"\"\"\n",
        "    pred_mapping = {}\n",
        "    for dataset_text, text_position, prediction in zip(model_data['texts'], model_data['positions'], model_predictions):\n",
        "        pred_mapping[text_position] = (dataset_text, prediction)\n",
        "\n",
        "    pre_labeled_mapping = {}\n",
        "    for text, pos, label in zip(pre_labeled_data['texts'], pre_labeled_data['positions'], pre_labeled_data['labels']):\n",
        "        pre_labeled_mapping[pos] = (text, label)\n",
        "\n",
        "\n",
        "    pred_mapping.update(pre_labeled_mapping)\n",
        "\n",
        "    pred_mapping = {k: v for k, v in sorted(pred_mapping.items(), key=lambda item: item[0])}\n",
        "\n",
        "    predictions =[element[1] for element in list(pred_mapping.values())] \n",
        "\n",
        "    return pred_mapping, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5i2N8mqKULGh"
      },
      "outputs": [],
      "source": [
        "# Create predictions dictionary spanning initiatives\n",
        "def sentence_to_initiative_aggregation(predictions, predictions_report_numbers):\n",
        "    \"\"\" Utility function which takes in a list of IOBES predictions per sentence and aggregates these into a dictionary of initiatives.\n",
        "    params: predictions: list of multi-class predictions\n",
        "    returns: predictions_dict: {initiative_number_report_number:list of sentence positions}\n",
        "    \"\"\"\n",
        "    predictions_dict = {}\n",
        "    initiative_index = 0\n",
        "    prediction_index = 0\n",
        "    while prediction_index < len(predictions):\n",
        "      if predictions[prediction_index] == 0: #no initiative\n",
        "        prediction_index += 1\n",
        "      elif predictions[prediction_index] == 1: #singleton\n",
        "        prediction_span = [prediction_index]\n",
        "        predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "        initiative_index += 1\n",
        "        prediction_index += 1\n",
        "      elif predictions[prediction_index] == 2: #beginning of initiative\n",
        "        if predictions[prediction_index + 1] == 4: # 2 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 2\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 4): #3 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 3\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 3) and (predictions[prediction_index + 3] == 4): #4 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2, prediction_index + 3]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 4\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 3) and (predictions[prediction_index + 3] == 3) and (predictions[prediction_index + 4] == 4): #5 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2, prediction_index + 3, prediction_index + 3]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 5\n",
        "        else:\n",
        "          prediction_span = [prediction_index]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 1\n",
        "      else: # all other initiative predictions which do not form a complete BIE structure are labeled as individual singletons\n",
        "        prediction_span = [prediction_index]\n",
        "        predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "        initiative_index += 1\n",
        "        prediction_index += 1\n",
        "\n",
        "    return predictions_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kncs_eEhsoJV"
      },
      "outputs": [],
      "source": [
        "class Initiative_Evaluation():\n",
        "    \"\"\" Class used to evaluate what % of initiatives have been correctly indentified.\n",
        "    \"\"\"\n",
        "    def __init__(self, initiative_dict, predictions_dict):\n",
        "        self.initiative_dict = initiative_dict\n",
        "        self.predictions_dict = predictions_dict\n",
        "        self.no_initiatives = len(self.initiative_dict)\n",
        "    \n",
        "    def evaluate(self):\n",
        "        if len(self.initiative_dict) == len(self.predictions_dict) == 0:\n",
        "            fully_correctly_labeled_proportion =  1\n",
        "            half_correctly_labeled_proportion = 1\n",
        "            min_correctly_labeled_proportion = 1\n",
        "            fully_correct_F1 = 1\n",
        "            half_correct_F1 = 1\n",
        "            min_correct_F1 = 1\n",
        "            return fully_correctly_labeled_proportion, half_correctly_labeled_proportion, min_correctly_labeled_proportion, fully_correct_F1, half_correct_F1, min_correct_F1\n",
        "        else:\n",
        "            # initiatize counters for true positive predictions\n",
        "            fully_correct_TP = 0\n",
        "            half_correct_TP = 0\n",
        "            min_correct_TP = 0\n",
        "            \n",
        "            # initialize lists which contain prediction IDs\\\n",
        "            #  for the first correct prediction encountered across all initatives\n",
        "            fully_correct_double_count = []\n",
        "            half_correct_double_count = []\n",
        "            min_correct_double_count = []\n",
        "\n",
        "            for initiative_ID, initiative_positions_list in self.initiative_dict.items():\n",
        "                # Keep a record of the first prediction id considered to be a success for each initiative\n",
        "                fully_correct_match_pred_ID = []\n",
        "                half_correct_match_pred_ID = []\n",
        "                min_correct_match_pred_ID = []\n",
        "                for prediction_ID, prediction_positions_list in self.predictions_dict.items():\n",
        "                    if set(initiative_positions_list).intersection(prediction_positions_list): #check if the initiative span overlaps with the predicted span\n",
        "                        if (len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) == 1)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) == 1):\n",
        "                                if (len(fully_correct_match_pred_ID) == 0) and (prediction_ID not in fully_correct_double_count): \n",
        "                                    fully_correct_match_pred_ID.append(prediction_ID)\n",
        "                                    fully_correct_TP += 1\n",
        "                        if(len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) >= 0.5)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) >= 0.5):\n",
        "                                if (len(half_correct_match_pred_ID) == 0) and (prediction_ID not in half_correct_double_count):\n",
        "                                    half_correct_match_pred_ID.append(prediction_ID)\n",
        "                                    half_correct_TP += 1\n",
        "                        if(len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) > 0)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) > 0):\n",
        "                                if (len(min_correct_match_pred_ID) == 0) and (prediction_ID not in min_correct_double_count): \n",
        "                                        min_correct_match_pred_ID.append(prediction_ID)\n",
        "                                        min_correct_TP += 1\n",
        "                fully_correct_double_count.extend(fully_correct_match_pred_ID)\n",
        "                half_correct_double_count.extend(half_correct_match_pred_ID)\n",
        "                min_correct_double_count.extend(min_correct_match_pred_ID)\n",
        "                        \n",
        "\n",
        "            fully_correct_FN, fully_correct_FP = self.compute_FN_FP(fully_correct_TP)\n",
        "            fully_correct_F1, fully_correct_precision, fully_correct_recall = self.compute_F1(fully_correct_TP, fully_correct_FP, fully_correct_FN)\n",
        "\n",
        "            half_correct_FN, half_correct_FP = self.compute_FN_FP(half_correct_TP)\n",
        "            half_correct_F1, half_correct_precision, half_correct_recall = self.compute_F1(half_correct_TP, half_correct_FP, half_correct_FN)\n",
        "\n",
        "            min_correct_FN, min_correct_FP = self.compute_FN_FP(min_correct_TP)\n",
        "            min_correct_F1, min_correct_precision, min_correct_recall = self.compute_F1(min_correct_TP, min_correct_FP, min_correct_FN)\n",
        "\n",
        "            fully_correctly_labeled_proportion = fully_correct_TP/self.no_initiatives\n",
        "            half_correctly_labeled_proportion = half_correct_TP/self.no_initiatives\n",
        "            min_correctly_labeled_proportion = min_correct_TP/self.no_initiatives\n",
        "            \n",
        "            return fully_correctly_labeled_proportion, half_correctly_labeled_proportion, min_correctly_labeled_proportion, fully_correct_F1, half_correct_F1, min_correct_F1, fully_correct_precision, fully_correct_recall, half_correct_precision, half_correct_recall, min_correct_precision, min_correct_recall\n",
        "    \n",
        "    def compute_F1(self, TP, FP, FN):\n",
        "        \"\"\" Utility method to compute F1 score\n",
        "        \"\"\"\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        if precision == recall == 0:\n",
        "            F1 = 0\n",
        "        else:\n",
        "            F1 = 2 * precision * recall /(precision + recall)\n",
        "        return F1, precision, recall\n",
        "    \n",
        "    def compute_FN_FP(self, TP):\n",
        "        \"\"\" Utility method to compute FN and FP initiatives given the no of TP \n",
        "        (defined as the set intersection between gold initiative span and prediction span)\n",
        "        \"\"\"\n",
        "        FN = len(self.initiative_dict) - TP\n",
        "        FP = len(self.predictions_dict) - TP\n",
        "        return FN, FP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7R7dTM4hULGj"
      },
      "outputs": [],
      "source": [
        "# Unit tests for Initiative_Evaluation Class\n",
        "mock_initiative_dict_1 = {1:[1,2], 2:[3,4]}\n",
        "mock_predictions_dict_1 = {1: [1,2], 2:[3], 3:[4]}\n",
        "mock_evaluation_1 = Initiative_Evaluation(mock_initiative_dict_1, mock_predictions_dict_1)\n",
        "mock_init_strict_accuracy_1, mock_init_medium_accuracy_1, mock_init_lenient_accuracy_1, mock1_fully_correct_F1, mock1_half_correct_F1, mock1_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_1.evaluate()\n",
        "assert mock_init_strict_accuracy_1 == 0.5\n",
        "assert mock_init_medium_accuracy_1 == 1\n",
        "assert mock_init_lenient_accuracy_1 == 1\n",
        "assert mock1_fully_correct_F1 == 0.4\n",
        "assert mock1_half_correct_F1 == mock1_min_correct_F1 == 0.8\n",
        "\n",
        "\n",
        "mock_initiative_dict_2 = {1:[1,2], 2:[4,5,6]}\n",
        "mock_predictions_dict_2 = {1: [1,2], 2:[4,5,6]}\n",
        "mock_evaluation_2 = Initiative_Evaluation(mock_initiative_dict_2, mock_predictions_dict_2)\n",
        "mock_init_strict_accuracy_2, mock_init_medium_accuracy_2, mock_init_lenient_accuracy_2, mock2_fully_correct_F1, mock2_half_correct_F1, mock2_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_2.evaluate()\n",
        "assert mock_init_strict_accuracy_2 == 1\n",
        "assert mock_init_medium_accuracy_2 == 1\n",
        "assert mock_init_lenient_accuracy_2 == 1\n",
        "assert mock2_fully_correct_F1 == mock2_half_correct_F1 == mock2_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_3 = {1:[1,2], 2:[3,4]}\n",
        "mock_predictions_dict_3 = {1: [1,2], 2:[3,4]}\n",
        "mock_evaluation_3 = Initiative_Evaluation(mock_initiative_dict_3, mock_predictions_dict_3)\n",
        "mock_init_strict_accuracy_3, mock_init_medium_accuracy_3, mock_init_lenient_accuracy_3, mock3_fully_correct_F1, mock3_half_correct_F1, mock3_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_3.evaluate()\n",
        "assert mock_init_strict_accuracy_3 == 1\n",
        "assert mock_init_medium_accuracy_3 == 1\n",
        "assert mock_init_lenient_accuracy_3 == 1\n",
        "assert mock3_fully_correct_F1 == mock3_half_correct_F1 == mock3_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_4 = {}\n",
        "mock_predictions_dict_4 = {}\n",
        "mock_evaluation_4 = Initiative_Evaluation(mock_initiative_dict_4, mock_predictions_dict_4)\n",
        "mock_init_strict_accuracy_4, mock_init_medium_accuracy_4, mock_init_lenient_accuracy_4, mock4_fully_correct_F1, mock4_half_correct_F1, mock4_min_correct_F1 = mock_evaluation_4.evaluate()\n",
        "assert mock_init_strict_accuracy_4 == 1\n",
        "assert mock_init_medium_accuracy_4 == 1\n",
        "assert mock_init_lenient_accuracy_4 == 1\n",
        "assert mock4_fully_correct_F1 == mock4_half_correct_F1 == mock4_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_5 = {1:[1,2], 2:[3,4,5], 3:[6]}\n",
        "mock_predictions_dict_5 = {1:[1], 2:[2], 3:[3], 4:[4], 5:[5]}\n",
        "mock_evaluation_5 = Initiative_Evaluation(mock_initiative_dict_5, mock_predictions_dict_5)\n",
        "mock_init_strict_accuracy_5, mock_init_medium_accuracy_5, mock_init_lenient_accuracy_5, mock5_fully_correct_F1, mock5_half_correct_F1, mock5_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_5.evaluate()\n",
        "assert mock_init_strict_accuracy_5 == 0\n",
        "assert mock_init_medium_accuracy_5 == 1/3\n",
        "assert mock_init_lenient_accuracy_5 == 2/3\n",
        "assert mock5_fully_correct_F1 == 0\n",
        "assert mock5_half_correct_F1 == 0.25\n",
        "assert mock5_min_correct_F1 == 0.5\n",
        "\n",
        "mock_initiative_dict_6 = {1:[1,2], 2:[3,4,5], 3:[6]}\n",
        "mock_predictions_dict_6 = {1:[1,2,3,4,5,6]}\n",
        "mock_evaluation_6 = Initiative_Evaluation(mock_initiative_dict_6, mock_predictions_dict_6)\n",
        "mock_init_strict_accuracy_6, mock_init_medium_accuracy_6, mock_init_lenient_accuracy_6, mock6_fully_correct_F1, mock6_half_correct_F1, mock6_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_6.evaluate()\n",
        "assert mock_init_strict_accuracy_6 == 0\n",
        "assert mock_init_medium_accuracy_6 == 1/3\n",
        "assert mock_init_lenient_accuracy_6 == 1/3\n",
        "assert mock6_fully_correct_F1 == 0\n",
        "assert mock6_half_correct_F1 == mock6_min_correct_F1 == 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM5U12qZtB92",
        "outputId": "89835ac0-77d4-4afa-81a7-4395ce97d2de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchcrf/__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorCompare.cpp:255.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting results on dev set took 168.2027246952057 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform context predictions on dev dataset\n",
        "start_time = time.time()\n",
        "sustainable_model = Sustainable_RoBERTa.from_pretrained('final_roberta_1sent_paper') \n",
        "loaded_crf_model = torch.load('crf_RoBERTa_1sent_paper.pt') \n",
        "dev_predictions_list = model_predict(sustainable_model, tokenizer, dev_loader, device, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, crf_model = loaded_crf_model)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on dev set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the dev set\n",
        "dev_pred_mapping, dev_predictions = reconcile_mapping(dev_data, pre_labeled_dev_data, dev_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioIJdeSTtB92",
        "outputId": "4e455450-90e1-43c5-8705-f9b54a95856c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on the Development Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9804    0.9867    0.9836     53854\n",
            "    Singleton     0.3355    0.3135    0.3241       504\n",
            "    Beginning     0.3450    0.3077    0.3253       481\n",
            "       Inside     0.2377    0.0935    0.1343       310\n",
            "          End     0.2604    0.2204    0.2387       481\n",
            "\n",
            "     accuracy                         0.9632     55630\n",
            "    macro avg     0.4318    0.3844    0.4012     55630\n",
            " weighted avg     0.9587    0.9632    0.9607     55630\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract ground truth dev data labels\n",
        "dev_label_values = []\n",
        "dev_report_numbers = []\n",
        "for sent_no in range(len(development_data)):\n",
        "  dev_report_numbers.append(development_data[sent_no][0]['report_no'])\n",
        "  if development_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = development_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(development_data[sent_no][0]['report_no'])\n",
        "    if len(dev_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      dev_label_values.append(development_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif dev_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      dev_label_values.append(2) #append 2 for beginning of initiative\n",
        "    elif dev_initiative_dict[initiative_unique_reference].index(sent_no) == (len(dev_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      dev_label_values.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      dev_label_values.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    dev_label_values.append(development_data[sent_no][2]['has_initiative'])\n",
        "\n",
        "\n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Development Dataset \\n')\n",
        "print(classification_report(dev_label_values, np.array(dev_predictions), target_names = target_names, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkeXSSd8soJW",
        "outputId": "f1377d3d-b8e4-4589-b847-66ba3332a9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 50.86% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 43.45% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 27.01% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 46.78% \n",
            "\n",
            "Precision score where at least 1 sentence is identified is 43.30% \n",
            "\n",
            "Recall score where at least 1 sentence is identified is 50.86% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 39.96% \n",
            "\n",
            "Precision score where 50% of sentences are identified is 36.99% \n",
            "\n",
            "Recal score where 50% of sentences are identified is 43.45% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 24.84% \n",
            "\n",
            "Precision score where 100% of sentences are identified is 22.99% \n",
            "\n",
            "Recall score where 100% of sentences are identified is 27.01% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "dev_predictions_dict = sentence_to_initiative_aggregation(dev_predictions, dev_report_numbers)\n",
        "dev_init_evaluation = Initiative_Evaluation(dev_initiative_dict, dev_predictions_dict)\n",
        "dev_init_strict_accuracy, dev_init_medium_accuracy, dev_init_lenient_accuracy, dev_strict_F1, dev_medium_F1, dev_lenient_F1, dev_strict_precision, dev_strict_recall, dev_medium_precision, dev_medium_recall, dev_lenient_precision, dev_lenient_recall = dev_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {dev_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {dev_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {dev_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {dev_lenient_F1:.2%} \\n')\n",
        "print(f'Precision score where at least 1 sentence is identified is {dev_lenient_precision:.2%} \\n')\n",
        "print(f'Recall score where at least 1 sentence is identified is {dev_lenient_recall:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {dev_medium_F1:.2%} \\n')\n",
        "print(f'Precision score where 50% of sentences are identified is {dev_medium_precision:.2%} \\n')\n",
        "print(f'Recal score where 50% of sentences are identified is {dev_medium_recall:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {dev_strict_F1:.2%} \\n')\n",
        "print(f'Precision score where 100% of sentences are identified is {dev_strict_precision:.2%} \\n')\n",
        "print(f'Recall score where 100% of sentences are identified is {dev_strict_recall:.2%} \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TKuUMTlaWZp",
        "outputId": "7d86c0dc-ec97-47d8-c227-e95692ec58c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting results on test set took 164.93664526939392 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform predictions on test dataset\n",
        "start_time = time.time()\n",
        "test_predictions_list = model_predict(sustainable_model, tokenizer, test_loader, device,  global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, crf_model = loaded_crf_model)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on test set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the train set\n",
        "test_pred_mapping, test_predictions = reconcile_mapping(test_data, pre_labeled_test_data, test_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5UC4ohhaWZp",
        "outputId": "59008866-f2d0-4762-cbf4-caccc2e9880f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on the Test Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9809    0.9763    0.9786     48175\n",
            "    Singleton     0.2875    0.3553    0.3178       577\n",
            "    Beginning     0.2939    0.3445    0.3172       447\n",
            "       Inside     0.2652    0.2060    0.2319       233\n",
            "          End     0.2086    0.2394    0.2229       447\n",
            "\n",
            "     accuracy                         0.9532     49879\n",
            "    macro avg     0.4072    0.4243    0.4137     49879\n",
            " weighted avg     0.9564    0.9532    0.9547     49879\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_label_values = []\n",
        "test_report_numbers = []\n",
        "for sent_no in range(len(testing_data)):\n",
        "  test_report_numbers.append(testing_data[sent_no][0]['report_no'])\n",
        "  if testing_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = testing_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(testing_data[sent_no][0]['report_no'])\n",
        "    if len(test_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      test_label_values.append(testing_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif test_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      test_label_values.append(2) #append 2 for beginning of initiative\n",
        "    elif test_initiative_dict[initiative_unique_reference].index(sent_no) == (len(test_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      test_label_values.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      test_label_values.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    test_label_values.append(testing_data[sent_no][2]['has_initiative'])\n",
        "\n",
        "\n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Test Dataset \\n')\n",
        "print(classification_report(test_label_values, np.array(test_predictions), target_names = target_names, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHREX4AzaWZp",
        "outputId": "f23d7ff5-678b-48fc-f26c-fd42e622be46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 53.52% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 47.07% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 30.18% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 41.75% \n",
            "\n",
            "Precision score where at least 1 sentence is identified is 34.23% \n",
            "\n",
            "Recall score where at least 1 sentence is identified is 53.52% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 36.72% \n",
            "\n",
            "Precision score where 50% of sentences are identified is 30.11% \n",
            "\n",
            "Recal score where 50% of sentences are identified is 47.07% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 23.54% \n",
            "\n",
            "Precision score where 100% of sentences are identified is 19.30% \n",
            "\n",
            "Recall score where 100% of sentences are identified is 30.18% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "test_predictions_dict = sentence_to_initiative_aggregation(test_predictions, test_report_numbers)\n",
        "test_init_evaluation = Initiative_Evaluation(test_initiative_dict, test_predictions_dict)\n",
        "test_init_strict_accuracy, test_init_medium_accuracy, test_init_lenient_accuracy, test_strict_F1, test_medium_F1, test_lenient_F1, test_strict_precision, test_strict_recall, test_medium_precision, test_medium_recall, test_lenient_precision, test_lenient_recall  = test_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {test_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {test_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {test_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {test_lenient_F1:.2%} \\n')\n",
        "print(f'Precision score where at least 1 sentence is identified is {test_lenient_precision:.2%} \\n')\n",
        "print(f'Recall score where at least 1 sentence is identified is {test_lenient_recall:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {test_medium_F1:.2%} \\n')\n",
        "print(f'Precision score where 50% of sentences are identified is {test_medium_precision:.2%} \\n')\n",
        "print(f'Recal score where 50% of sentences are identified is {test_medium_recall:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {test_strict_F1:.2%} \\n')\n",
        "print(f'Precision score where 100% of sentences are identified is {test_strict_precision:.2%} \\n')\n",
        "print(f'Recall score where 100% of sentences are identified is {test_strict_recall:.2%} \\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf2aN65ztB92",
        "outputId": "fffadc66-1ce4-4cf6-b4e6-b1d26a9c7a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting results on train set took 270.84886932373047 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform predictions on train dataset\n",
        "start_time = time.time()\n",
        "train_predictions_list = model_predict(sustainable_model, tokenizer, train_loader, device,  global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, crf_model = loaded_crf_model)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on train set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the train set\n",
        "train_pred_mapping, train_predictions = reconcile_mapping(train_data, pre_labeled_train_data, train_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daVKMN0stB93",
        "outputId": "414fd93d-5424-4958-8724-49bba1b6bc43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on the Training Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9939    0.9834    0.9886     83801\n",
            "    Singleton     0.5351    0.6641    0.5927      1045\n",
            "    Beginning     0.5724    0.7990    0.6669       995\n",
            "       Inside     0.6532    0.6130    0.6324       633\n",
            "          End     0.5545    0.7106    0.6229       995\n",
            "\n",
            "     accuracy                         0.9717     87469\n",
            "    macro avg     0.6618    0.7540    0.7007     87469\n",
            " weighted avg     0.9761    0.9717    0.9735     87469\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_labels = []\n",
        "train_report_numbers = []\n",
        "for sent_no in range(len(training_data)):\n",
        "  train_report_numbers.append(training_data[sent_no][0]['report_no'])\n",
        "  if training_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = training_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(training_data[sent_no][0]['report_no'])\n",
        "    if len(train_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      training_labels.append(training_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif train_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      training_labels.append(2) #append 2 for beginning of initiative\n",
        "    elif train_initiative_dict[initiative_unique_reference].index(sent_no) == (len(train_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      training_labels.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      training_labels.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    training_labels.append(training_data[sent_no][2]['has_initiative'])\n",
        "    \n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Training Dataset \\n')\n",
        "print(classification_report(training_labels, np.array(train_predictions), target_names = target_names, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY5BwgnLsoJX",
        "outputId": "ed94bcc0-cacc-4932-f6da-f200e6842a3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 88.24% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 81.52% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 62.11% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 66.38% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 61.33% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 46.73% \n",
            "\n",
            "Evaluating initiatives on the train set took 2.505409002304077 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "train_predictions_dict = sentence_to_initiative_aggregation(train_predictions, train_report_numbers)\n",
        "train_init_evaluation = Initiative_Evaluation(train_initiative_dict, train_predictions_dict)\n",
        "train_init_strict_accuracy, train_init_medium_accuracy, train_init_lenient_accuracy, train_strict_F1, train_medium_F1, train_lenient_F1, train_strict_precision, train_strict_recall, train_medium_precision, train_medium_recall, train_lenient_precision, train_lenient_recall  = train_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {train_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {train_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {train_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {train_lenient_F1:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {train_medium_F1:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {train_strict_F1:.2%} \\n')\n",
        "end_time = time.time()\n",
        "print(f'Evaluating initiatives on the train set took {end_time-start_time} seconds')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "RoBERTa_sustainability_1_sent_paper.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "83822c0cf896608929095f1043a98f7e1bb9e3e58b660cf90b3c0a24621313f4"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('sustainability': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05ff10b0ba1d4fa396e2de1976c02123": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0923bf33f7724bab905736a5a4553499": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a952b998d7e4e5381a4504ed1c80d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b2ef6653873432e8ece10eee9623af0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b8cb9563a414525b92a544850b63f97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0c6271c6df4c5f9471a1ff820c1de5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c19c239e96e44d3892a9691db39dc6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1559bf92eb3b49c2ae5671dc7492c5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16b8d559578940f19fa1b050f1327ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ec86f6bb49c47d789b9c6d3904d0486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64a7cda51e6f475fa3f4d74c91913960",
            "placeholder": "​",
            "style": "IPY_MODEL_16b8d559578940f19fa1b050f1327ec3",
            "value": " 5.29k/? [00:00&lt;00:00, 159kB/s]"
          }
        },
        "27ee695101f04e48b310fbdb2b7e00c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1b04aacaddf4b04b6639655a1fd043b",
            "placeholder": "​",
            "style": "IPY_MODEL_d248ef5a6b6d471ca80518a70e908a16",
            "value": "Downloading: 100%"
          }
        },
        "2be9497f32e84f33a4845168c62e48f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c0ba0fe310f46cf95d118e839a1c220": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee96daaf2884757b5c0e39727e7e4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_817ab743b25949fb8a09e17a6095b992",
            "placeholder": "​",
            "style": "IPY_MODEL_b25ed60c8ddb48fbadafafa074a9ba1a",
            "value": "Downloading: 100%"
          }
        },
        "3fbb6c84c427457ca8a8f92dba18bf42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40cbe276694f405c8ea600ee965a9987": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4128076f2c1e42a78ef54a5f2b651e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f55fbd712e0147578c9c6a500668578c",
            "placeholder": "​",
            "style": "IPY_MODEL_c8f02ea506d94d8faf1e236ed13613fd",
            "value": " 478M/478M [00:14&lt;00:00, 34.7MB/s]"
          }
        },
        "459548995942432bb021ba7b82561c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46563f938bf0488995ea53e990067399": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f99984bd7f944116b5605df94a79d466",
              "IPY_MODEL_884198cbbfdc49b3a31912949a8ee609",
              "IPY_MODEL_5522641cd03e4d10886e6b8dbeee8d28"
            ],
            "layout": "IPY_MODEL_05ff10b0ba1d4fa396e2de1976c02123"
          }
        },
        "49a929be29df4ec99dbde254a1c3590d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc9ce86464b451e88f8c31fa4d22769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a120688ae04eb69018ecbd94f9e5d8",
            "placeholder": "​",
            "style": "IPY_MODEL_0a952b998d7e4e5381a4504ed1c80d34",
            "value": " 481/481 [00:00&lt;00:00, 19.9kB/s]"
          }
        },
        "4e23221d18114bc48eb6c70c987571ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b2ef6653873432e8ece10eee9623af0",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5f9cbce8b8147ae90b063b31914472a",
            "value": 1355863
          }
        },
        "50a832ba3cb14e628a6509bb8a2f8957": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52b89de29ee04c2a9cb8f120c4008cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efd20e002067437db791dbdd46a907a9",
            "placeholder": "​",
            "style": "IPY_MODEL_f67a99c9db434d878f5d85d6356a04e2",
            "value": " 446k/446k [00:00&lt;00:00, 1.12MB/s]"
          }
        },
        "5522641cd03e4d10886e6b8dbeee8d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a929be29df4ec99dbde254a1c3590d",
            "placeholder": "​",
            "style": "IPY_MODEL_97a78e07c31641cb9f070db303cdddb3",
            "value": " 878k/878k [00:00&lt;00:00, 1.18MB/s]"
          }
        },
        "6004835f30804ac8bff327562298ec13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63e9184d0c0444269a6251c260734c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b1f1b338c1841da8f4ce2e830af4cb8",
            "placeholder": "​",
            "style": "IPY_MODEL_40cbe276694f405c8ea600ee965a9987",
            "value": "Downloading: "
          }
        },
        "64a7cda51e6f475fa3f4d74c91913960": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1f1b338c1841da8f4ce2e830af4cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b84d53c869446ffb6a4c49b49a37463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "817ab743b25949fb8a09e17a6095b992": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8406395e291b42b797ed5a5cbac8469d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "884198cbbfdc49b3a31912949a8ee609": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be9497f32e84f33a4845168c62e48f0",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1559bf92eb3b49c2ae5671dc7492c5f9",
            "value": 898823
          }
        },
        "8c15ec1faa764b2c9405f27efde1d30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e024a1b9276b4de29360aa352335e699",
            "placeholder": "​",
            "style": "IPY_MODEL_50a832ba3cb14e628a6509bb8a2f8957",
            "value": "Downloading: 100%"
          }
        },
        "8f486753cf124f6e89e28944a9cc69c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9478a640921044fcb2d1943b027e3cff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97a78e07c31641cb9f070db303cdddb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b4a39e7c63640db89d838422a428781": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc7e3478a5440de9d14c412a7cb4bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c19c239e96e44d3892a9691db39dc6c",
            "placeholder": "​",
            "style": "IPY_MODEL_3fbb6c84c427457ca8a8f92dba18bf42",
            "value": "Downloading: 100%"
          }
        },
        "9c4852834a504c6689d50cd6c27c0618": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b25ed60c8ddb48fbadafafa074a9ba1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5f9cbce8b8147ae90b063b31914472a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b938e304634241e09815c912922e5acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ee96daaf2884757b5c0e39727e7e4a4",
              "IPY_MODEL_da4fefb003b84b58bd6a32cc05f927b3",
              "IPY_MODEL_4bc9ce86464b451e88f8c31fa4d22769"
            ],
            "layout": "IPY_MODEL_c2db1a6328a44caa87b4191bb37081cb"
          }
        },
        "c169f4f6895d49dd9cbbc84d57e56451": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c0ba0fe310f46cf95d118e839a1c220",
            "placeholder": "​",
            "style": "IPY_MODEL_c874ca81bdcd4da8b62019658fa63363",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 2.89MB/s]"
          }
        },
        "c2db1a6328a44caa87b4191bb37081cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c874ca81bdcd4da8b62019658fa63363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8f02ea506d94d8faf1e236ed13613fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1684fef136743edb236573b35a0e1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bc7e3478a5440de9d14c412a7cb4bfc",
              "IPY_MODEL_ec690f4ed17b4249b6f80fdb2b850615",
              "IPY_MODEL_52b89de29ee04c2a9cb8f120c4008cfc"
            ],
            "layout": "IPY_MODEL_e5f2e570a3be4219a4830c732bac8b9b"
          }
        },
        "d1b04aacaddf4b04b6639655a1fd043b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d248ef5a6b6d471ca80518a70e908a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d82184e9ae9a462ebff7d43586950a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b8cb9563a414525b92a544850b63f97",
            "max": 2069,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c4852834a504c6689d50cd6c27c0618",
            "value": 2069
          }
        },
        "da4fefb003b84b58bd6a32cc05f927b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8406395e291b42b797ed5a5cbac8469d",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb0ec07f210d4783a9844a914aa87785",
            "value": 481
          }
        },
        "e024a1b9276b4de29360aa352335e699": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e260f0f3d9654f28b6477289f25704cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e29d387d3448421f9e53a7c823c64148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27ee695101f04e48b310fbdb2b7e00c2",
              "IPY_MODEL_4e23221d18114bc48eb6c70c987571ac",
              "IPY_MODEL_c169f4f6895d49dd9cbbc84d57e56451"
            ],
            "layout": "IPY_MODEL_0c0c6271c6df4c5f9471a1ff820c1de5"
          }
        },
        "e5f2e570a3be4219a4830c732bac8b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a120688ae04eb69018ecbd94f9e5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b91b19c26246b8bdf60c5fe9f95288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b4a39e7c63640db89d838422a428781",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b84d53c869446ffb6a4c49b49a37463",
            "value": 501200538
          }
        },
        "ec690f4ed17b4249b6f80fdb2b850615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e260f0f3d9654f28b6477289f25704cc",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_459548995942432bb021ba7b82561c3f",
            "value": 456318
          }
        },
        "efd20e002067437db791dbdd46a907a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f07143eb663843aaa26bbe40b6d07867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e9184d0c0444269a6251c260734c90",
              "IPY_MODEL_d82184e9ae9a462ebff7d43586950a7d",
              "IPY_MODEL_1ec86f6bb49c47d789b9c6d3904d0486"
            ],
            "layout": "IPY_MODEL_9478a640921044fcb2d1943b027e3cff"
          }
        },
        "f55fbd712e0147578c9c6a500668578c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67a99c9db434d878f5d85d6356a04e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6d52e9f29ff4cc7a305f1fc464b8e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c15ec1faa764b2c9405f27efde1d30e",
              "IPY_MODEL_e8b91b19c26246b8bdf60c5fe9f95288",
              "IPY_MODEL_4128076f2c1e42a78ef54a5f2b651e98"
            ],
            "layout": "IPY_MODEL_8f486753cf124f6e89e28944a9cc69c2"
          }
        },
        "f99984bd7f944116b5605df94a79d466": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0923bf33f7724bab905736a5a4553499",
            "placeholder": "​",
            "style": "IPY_MODEL_6004835f30804ac8bff327562298ec13",
            "value": "Downloading: 100%"
          }
        },
        "fb0ec07f210d4783a9844a914aa87785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
