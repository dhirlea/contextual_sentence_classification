{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ex_4NNmtMT2",
        "outputId": "af1164a5-d396-4459-c851-6befbce660e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 49.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 70.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.2\n",
            "Collecting datasets\n",
            "  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 70.5 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0,>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.17)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 40.7 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 73.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 datasets-1.12.1 fsspec-2021.10.0 multidict-5.2.0 xxhash-2.0.2 yarl-1.6.3\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Utm8lRFa7Tdt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import transformers\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import BertTokenizer \n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "\n",
        "from datasets import load_metric\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9kckp85tQGY",
        "outputId": "b9583573-f7e9-41f6-d2d5-a2c0961ea156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsFcUtG-9pSu",
        "outputId": "51b193e0-766a-4b2b-9f0f-d577ad7eb7dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "# DELETE CELL IF RUNNING ON LOCAL MACHINE INSTEAD OF GOOGLE COLAB\n",
        "cd /content/drive/MyDrive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chQJjqSw7Tdu",
        "outputId": "03f35e88-b802-4c10-d36d-039fa8961729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "print(use_cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TR1-pIFXtB9t"
      },
      "outputs": [],
      "source": [
        "# Create list of training data files\n",
        "def load_from_directory(directory):\n",
        "    \"\"\"\n",
        "    Utility function to load all json-converted reports into a dataset.\n",
        "    params: directory: string representing location on disk of json files\n",
        "    returns: dataset: list of deserialised jsons\n",
        "    \"\"\"\n",
        "    path = os.getcwd()\n",
        "    path = os.path.join(path, directory)\n",
        "    json_files = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')]\n",
        "\n",
        "    dataset = [] \n",
        "\n",
        "    for filename in json_files:\n",
        "        with open(path+filename, \"r\", encoding='utf-8') as read_file:\n",
        "            dataset.append(json.load(read_file))\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "train_folder = 'json_train/'\n",
        "train_dataset = load_from_directory(train_folder)\n",
        "\n",
        "dev_folder = 'json_develop/'\n",
        "development_dataset = load_from_directory(dev_folder)\n",
        "\n",
        "test_folder = 'json_test/'\n",
        "test_dataset = load_from_directory(test_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xG-4ESe7tB9u"
      },
      "outputs": [],
      "source": [
        "def filter_dataset(input_dataset):\n",
        "    \"\"\" \n",
        "    Utility function to convert input dataset into custom data structure\n",
        "    params: input_dataset: list of deserialised jsons\n",
        "    returns: dictionary with the following structure:\n",
        "            key:  sentence_global_idx value , value:list of dictionaries\n",
        "            dict0: key: report_no, value: int \n",
        "            dict1: key: text, value: string\n",
        "            dict2: key: has_initiative, value: boolean\n",
        "            dict3: key: list_of_initiatives, value: list of strings with initiative IDs\n",
        "            dict4: key: sector, value: list of strings\n",
        "            dict5: key: sdg, value: list of sgd strings (representing sgd number)\n",
        "            dict6: key: sentence_length, value: int  \n",
        "    \"\"\"\n",
        "    structured_data = {}\n",
        "    total_no_reports = len(input_dataset)\n",
        "    sentence_global_idx = 0\n",
        "    re_punctuation_string = '[“”|()%&\\s,_:;/\\'!?-]'\n",
        "\n",
        "    for report_no in range(total_no_reports): \n",
        "        no_sentences_per_report = len(input_dataset[report_no]['tokenised_sentences'])\n",
        "        for sentence_no in range(no_sentences_per_report):\n",
        "            tokenized_sentence = re.split(re_punctuation_string, input_dataset[report_no]['tokenised_sentences'][sentence_no]['text'])\n",
        "            tokenized_sentence = list(filter(None, tokenized_sentence))\n",
        "            if (len(tokenized_sentence) == 0):           \n",
        "                continue\n",
        "            else:\n",
        "                structured_data[sentence_global_idx] = []\n",
        "                structured_data[sentence_global_idx].append({'report_no':report_no}) \n",
        "                structured_data[sentence_global_idx].append({'text':' '.join([elem.lower() for elem in tokenized_sentence])})\n",
        "                if len(input_dataset[report_no]['tokenised_sentences'][sentence_no]['initiative_ids']) > 0:\n",
        "                  structured_data[sentence_global_idx].append({'has_initiative':1})\n",
        "                else:\n",
        "                   structured_data[sentence_global_idx].append({'has_initiative':0})\n",
        "                structured_data[sentence_global_idx].append({'list_of_initiatives': input_dataset[report_no]['tokenised_sentences'][sentence_no]['initiative_ids']}) \n",
        "                \n",
        "                structured_data[sentence_global_idx].append({'sentence_length':len(tokenized_sentence)}) \n",
        "                sentence_global_idx +=1\n",
        "    \n",
        "    return structured_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rqb_rDqdtB9w"
      },
      "outputs": [],
      "source": [
        "# Set up datasets from json files\n",
        "training_data = filter_dataset(train_dataset)\n",
        "development_data = filter_dataset(development_dataset)\n",
        "testing_data = filter_dataset(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uJ2h2bUHtB9y"
      },
      "outputs": [],
      "source": [
        "def assisted_labelling(data, lower_threshold, upper_threshold):\n",
        "    \"\"\"\n",
        "    Utility function which labels all sentences with fewer than the threshold number of tokens as not having a sustainability initiative.\n",
        "    params: data: list of dictionaries\n",
        "            threshold: int representing number of tokens\n",
        "    returns: dictionary {global_sentence_index:boolean label}\n",
        "    \"\"\"\n",
        "    labeled_dataset = {}\n",
        "    for sentence_no in range(len(data)):\n",
        "        tokenized_sentence = re.split(' ', data[sentence_no][1]['text'])\n",
        "        tokenized_sentence_with_alphabetical_chars = [word for word in tokenized_sentence if re.search('[a-zA-Z]', word)]\n",
        "        if (data[sentence_no][4]['sentence_length'] > lower_threshold) & (len(tokenized_sentence_with_alphabetical_chars)!=0) & (data[sentence_no][4]['sentence_length']<upper_threshold):\n",
        "            labeled_dataset[sentence_no] = 1 \n",
        "        else:\n",
        "            labeled_dataset[sentence_no] = 0 # label short, long and non-alphabetical sentences as not having an initiative\n",
        "    return labeled_dataset\n",
        "\n",
        "assistant_labeled_training_data = assisted_labelling(training_data,lower_threshold=5, upper_threshold=100)\n",
        "assistant_labeled_dev_data = assisted_labelling(development_data,lower_threshold=5, upper_threshold=100)\n",
        "assistant_labeled_test_data = assisted_labelling(testing_data, lower_threshold=5, upper_threshold=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Lq_Q9UCl33gd"
      },
      "outputs": [],
      "source": [
        "def reader(dataset, assisted_labels, initiative_dict):\n",
        "    \"\"\"\n",
        "    Utility function read in the data together with assisted labels and return a train dictionary and a pre-labelled dictionary.\n",
        "    params: dataset: dict {global_sentence_index : list of 7 dictionaries}\n",
        "            assisted_labels: dict {global_sentence_index : assistant label}\n",
        "    returns: train_dict: dict\n",
        "             pre_labelled_dict\n",
        "    \"\"\"\n",
        "    texts = []\n",
        "    labels = []\n",
        "    positions = []\n",
        "    initiative_IDs = []\n",
        "    report_no = []\n",
        "    \n",
        "    pre_labeled_texts =[]\n",
        "    pre_labeled_labels =[]\n",
        "    pre_labeled_positions =[]\n",
        "    pre_labeled_IDs = []\n",
        "\n",
        "    for sentence_no in range(len(dataset)):\n",
        "        if assisted_labels[sentence_no] == 1:\n",
        "            report_no.append(dataset[sentence_no][0]['report_no'])\n",
        "            texts.append(dataset[sentence_no][1]['text'])\n",
        "            if dataset[sentence_no][3]['list_of_initiatives']: #check whether the sentence has an initiative\n",
        "              initiative_unique_reference = dataset[sentence_no][3]['list_of_initiatives'][0] + '_' + str(dataset[sentence_no][0]['report_no'])\n",
        "              if len(initiative_dict[initiative_unique_reference]) == 1:\n",
        "                labels.append(dataset[sentence_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "              elif initiative_dict[initiative_unique_reference].index(sentence_no) == 0:\n",
        "                labels.append(2) #append 2 for beginning of initiative\n",
        "              elif initiative_dict[initiative_unique_reference].index(sentence_no) == (len(initiative_dict[initiative_unique_reference]) - 1):\n",
        "                labels.append(4) #append 4 for end of initiative\n",
        "              else:\n",
        "                labels.append(3) #append 3 for inside an initiative\n",
        "            else:\n",
        "              labels.append(dataset[sentence_no][2]['has_initiative'])\n",
        "            positions.append(sentence_no)\n",
        "            initiative_IDs.append(dataset[sentence_no][3]['list_of_initiatives'])\n",
        "        else:\n",
        "            pre_labeled_texts.append(dataset[sentence_no][1]['text'])\n",
        "            pre_labeled_labels.append(assisted_labels[sentence_no]) # append 0 for non-initiative sentences\n",
        "            pre_labeled_positions.append(sentence_no)\n",
        "            pre_labeled_IDs.append(dataset[sentence_no][3]['list_of_initiatives'])\n",
        "\n",
        "    actual_data_dict = {'texts':texts, 'labels':labels, 'positions':positions, 'ID_list':initiative_IDs, 'report_no':report_no}\n",
        "    pre_labeled_dict = {'texts':pre_labeled_texts, 'labels':pre_labeled_labels, 'positions': pre_labeled_positions, 'ID_list':pre_labeled_IDs}\n",
        "            \n",
        "    return actual_data_dict, pre_labeled_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FrxI7zhZzd_I"
      },
      "outputs": [],
      "source": [
        "def context_builder(data_dict, left_context_size = 0, right_context_size = 0):\n",
        "    context = []\n",
        "    multi_sentence_labels = []\n",
        "    for sentence_index in range(len(data_dict['texts'])):\n",
        "        sentence_context = []\n",
        "        sentence_context_labels = []\n",
        "        if (sentence_index - left_context_size >= 0) and (sentence_index + right_context_size < len(data_dict['texts'])):\n",
        "            # test if target sentence is in the middle of the corpus\n",
        "            for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                if data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]:\n",
        "                    sentence_context.append(data_dict['texts'][context_index])\n",
        "                    sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        elif sentence_index - left_context_size >= 0: #if target sentence is at end of the corpus \n",
        "            for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                if context_index < len(data_dict['texts']): # add in a smaller context window at end of the corpus\n",
        "                    if (data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]):\n",
        "                        sentence_context.append(data_dict['texts'][context_index])\n",
        "                        sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        elif sentence_index + right_context_size < len(data_dict['texts']): #if target sentence is at beginning of the corpus \n",
        "                for context_index in range(sentence_index - left_context_size, sentence_index + right_context_size + 1):\n",
        "                    if context_index >= 0: # add in smaller context window at the beginning of the corpus\n",
        "                        if (data_dict['report_no'][sentence_index] == data_dict['report_no'][context_index]):\n",
        "                            sentence_context.append(data_dict['texts'][context_index])\n",
        "                            sentence_context_labels.append(data_dict['labels'][context_index])\n",
        "        context.append(sentence_context)\n",
        "        while len(sentence_context_labels) < (1 + left_context_size + right_context_size): # pad with 0 labels for senteces with a smaller context eg. beginning/end of docs\n",
        "          sentence_context_labels.append(0)\n",
        "        multi_sentence_labels.append(sentence_context_labels)\n",
        "    return context, multi_sentence_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9D9lIa3R6cRb"
      },
      "outputs": [],
      "source": [
        "class SustainableDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Dataset class inheriting from pytorch to be used by dataloaders.\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer, input_set, input_context, input_multi_sentence_labels, max_paragraph_length, global_target_sentence_index):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = input_set['texts']\n",
        "        self.labels = input_set['labels']\n",
        "        self.report_nos = input_set['report_no']\n",
        "        self.contexts = input_context\n",
        "        self.context_labels = input_multi_sentence_labels\n",
        "        self.max_paragraph_length = max_paragraph_length\n",
        "        self.global_target_sentence_index = global_target_sentence_index\n",
        "        \n",
        "        \n",
        "    def collate_fn(self, batch):\n",
        "        texts = [b['text'] for b in batch]\n",
        "        labels = [b['label'] for b in batch]\n",
        "        contexts = [b['context'] for b in batch]\n",
        "        context_labels = [b['context_label'] for b in batch]\n",
        "        encodings, sep_positions = self.custom_tokenizer(batch = contexts) \n",
        "        encodings['labels'] =  torch.tensor(labels) \n",
        "        encodings['sep_positions'] = sep_positions\n",
        "        return encodings\n",
        "    \n",
        "    def custom_collate_fn(self, batch):\n",
        "      texts = [b['text'] for b in batch]\n",
        "      labels = [b['label'] for b in batch]\n",
        "      contexts = [b['context'] for b in batch]\n",
        "      context_labels = [b['context_label'] for b in batch]\n",
        "      return {'texts':texts, 'labels':labels, 'contexts':contexts, 'context_labels':context_labels}\n",
        "    \n",
        "\n",
        "    def custom_tokenizer(self, batch):\n",
        "      \"\"\" Utility functions to tokenize a list of sentences using [SEP] at the beginning of each sentence with fixed positions.\n",
        "      \"\"\"\n",
        "      batch_sequences = []\n",
        "      batch_sep_positions = []\n",
        "      batch_token_type_ids = []\n",
        "      for sequence_list in batch:\n",
        "        augmented_sequence = ''\n",
        "        for sentence in sequence_list:\n",
        "            augmented_sequence += '[SEP]' + sentence\n",
        "        augmented_sequence.strip()\n",
        "        batch_sequences.append(augmented_sequence)\n",
        "      encoded_batch = self.tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt')\n",
        "      for encoded_sequence in encoded_batch['input_ids']:\n",
        "          sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==102]\n",
        "          while len(sep_positions) < self.max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "            sep_positions.append(sep_positions[-1])\n",
        "          batch_sep_positions.append(sep_positions[global_target_sentence_index])\n",
        "          if self.global_target_sentence_index in range(len(sep_positions)-1): # check to see that the target sentence is actually part of the context\n",
        "            custom_token_type_ids = [ 1 if index in range(sep_positions[self.global_target_sentence_index], sep_positions[self.global_target_sentence_index+1]+1) else 0 for index in range(len(encoded_sequence))]\n",
        "          else:\n",
        "            custom_token_type_ids = [1 for index in range(len(encoded_sequence))]\n",
        "          batch_token_type_ids.append(custom_token_type_ids)\n",
        "       \n",
        "      encoded_batch['token_type_ids'] = torch.tensor(batch_token_type_ids)\n",
        "      return encoded_batch, batch_sep_positions\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {'text': self.texts[idx],\n",
        "                'label': self.labels[idx],\n",
        "                'context': self.contexts[idx],\n",
        "                'context_label' : self.context_labels[idx],\n",
        "                }\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U9odLvcadGWg"
      },
      "outputs": [],
      "source": [
        "def get_sep_positions(data_loader, global_target_sentence_index, max_paragraph_length):\n",
        "  \"\"\" Utility function to get sep positions for given dataset.\n",
        "  \"\"\"\n",
        "  dataset_sep_positions = []\n",
        "  for batch in data_loader:\n",
        "      batch_sep_positions = []\n",
        "      batch_sequences = []\n",
        "      for sequence_list in batch['contexts']:\n",
        "        augmented_sequence = ''\n",
        "        for sentence in sequence_list:\n",
        "            augmented_sequence += '[SEP]' + sentence\n",
        "        augmented_sequence.strip()\n",
        "        batch_sequences.append(augmented_sequence)\n",
        "      encoded_batch = tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt')\n",
        "      for encoded_sequence in encoded_batch['input_ids']:\n",
        "          sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==102]\n",
        "          while len(sep_positions) < max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "            sep_positions.append(sep_positions[-1])\n",
        "          batch_sep_positions.append(sep_positions[global_target_sentence_index])\n",
        "      dataset_sep_positions.extend(batch_sep_positions) \n",
        "  return dataset_sep_positions\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "r92owFJgsoJV"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary with ID_reportNo as keys and values as list of sentence indices\n",
        "def create_init_dict(data):\n",
        "    \"\"\" Utility function to extract individual initiatives as keys of a dict and a list of corresponding global sentence indices.\n",
        "    \"\"\"\n",
        "    initiative_dict = {} #keys are initiative IDs, values are counts of IDs \n",
        "    for sentence_no in range(len(data)):\n",
        "        if data[sentence_no][2]['has_initiative']:\n",
        "            initiative_ID = data[sentence_no][3]['list_of_initiatives'][0]\n",
        "            if (initiative_ID + '_' + str(data[sentence_no][0]['report_no'])) not in initiative_dict.keys():\n",
        "                initiative_dict[initiative_ID + '_' + str(data[sentence_no][0]['report_no'])] = [sentence_no]\n",
        "            else:\n",
        "                initiative_dict[initiative_ID + '_' + str(data[sentence_no][0]['report_no'])].append(sentence_no)\n",
        "    return initiative_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "6b3ccb26b9894030ba9db958abec970f",
            "34d83819b828451385b91c5dcd7eecbc",
            "effcd29d85f644e1a2dc861e55e69cee",
            "75be063e64444fc7afe06cfc787fa3e0",
            "6fc7b13bd91f4c7fbd2157699dd9deed",
            "73f6281d1f8d4f94b3a41c019d00255e",
            "9a51274f4b8c47e08a6feea18974119b",
            "79e2b1671c234369b99c9c61d2737e69",
            "c4ae4f48453b4709a0c811d658296ba9",
            "ce4c66aefc724a479e63c532e5e729a9",
            "605a3800aef9494eb9069f3b4d9a25a8",
            "556db7b225484cbd940b3ecc33d8e556",
            "8a4af21e3b654017845b51ce67039fee",
            "a7121c23d2cd4579a45f7491144440c0",
            "ae5f8d7612a749279caddfc9aba0f7a9",
            "a50d69ce06c6415aac7afcca1417c7e1",
            "a5130127ff9f4fb2a51b1d8ed813c4bb",
            "15c12dfc37f4477dbd98b451473f18e6",
            "6dfe963778eb48d68b829b761adc5b17",
            "56d4171a9adb4698819f2705bbc5aebc",
            "8b1e2a8f036b471ea2e8d568607f9f12",
            "d6ca2d5222234fbf85b4afebaf8879f6",
            "f29db967817c4012a2dd4fe5eb807e32",
            "8d6b062d9b784b77bed33dc31dc3680f",
            "9e02ad13080f4a84b53c70c8be229d90",
            "9b99d267c18340edbfebaaff5e93ff40",
            "d26b25291f5a4b18808e492bdd108c41",
            "64bbaa9deaac49ceb783dcae5fcf91b5",
            "59f8b008512d4ff3ad8426ace743980d",
            "c810babecd1d4bacb842f3c58aa3242f",
            "c8cafb33d5384c5dae64670463784a75",
            "28b4269a46a542b39edcce4ebe038c62",
            "5c6e8b206a404049bf91a0216b0c0b68",
            "1343fcd335a3476ba658c8920ea11621",
            "8193b4bfbe3e40e4a19dbc2160df0b52",
            "44f892e3241144858e890c2c0c50f0ac",
            "c3059571217b4b81821bab6d01fe3618",
            "d1cd73cbaf58452791541ccbdd6cde7f",
            "b687e57010f84f8c992240cf5d2a8ebc",
            "fbe58c2a7e5446a193292dd6384f5c33",
            "b287f079e51e4d39954ddfaf6ab8da39",
            "379457ed3a3e4ee0886058e1e9152088",
            "1837c22ecfb5420088aaf568198c007a",
            "aba52250d50c4ba88c5da24b335b858a"
          ]
        },
        "id": "TyZQtXwj4ixr",
        "outputId": "3b0b9cbd-4e81-42be-f7e4-e7722fb565e7",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b3ccb26b9894030ba9db958abec970f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "556db7b225484cbd940b3ecc33d8e556",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f29db967817c4012a2dd4fe5eb807e32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1343fcd335a3476ba658c8920ea11621",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "global_target_sentence_index = 0 \n",
        "\n",
        "# Create gold standard initiative dictionaries\n",
        "train_initiative_dict = create_init_dict(training_data)\n",
        "dev_initiative_dict = create_init_dict(development_data)\n",
        "test_initiative_dict = create_init_dict(testing_data)\n",
        "\n",
        "# Read in training and dev data and split into data to feed into the model and pre-labeled data\n",
        "train_data, pre_labeled_train_data = reader(training_data, assistant_labeled_training_data, train_initiative_dict)\n",
        "dev_data, pre_labeled_dev_data = reader(development_data, assistant_labeled_dev_data, dev_initiative_dict)\n",
        "test_data, pre_labeled_test_data = reader(testing_data, assistant_labeled_test_data, test_initiative_dict)\n",
        "\n",
        "# Construct context around each sentence per dataset\n",
        "train_context, train_multi_sentence_labels = context_builder(train_data, left_context_size = 0, right_context_size = 0) \n",
        "dev_context, dev_multi_sentence_labels = context_builder(dev_data, left_context_size = 0, right_context_size = 0)\n",
        "test_context, test_multi_sentence_labels = context_builder(test_data, left_context_size = 0, right_context_size = 0)\n",
        "\n",
        "max_paragraph_length = max([len(label_sequence) for label_sequence in train_multi_sentence_labels])\n",
        "\n",
        "# Only data to be fed into the model is built into datasets\n",
        "train_dataset = SustainableDataset(tokenizer, train_data, train_context, train_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "dev_dataset = SustainableDataset(tokenizer, dev_data, dev_context, dev_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "test_dataset = SustainableDataset(tokenizer, test_data, test_context, test_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "\n",
        "# Create train and dev dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False, collate_fn = train_dataset.custom_collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False, collate_fn = dev_dataset.custom_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn = test_dataset.custom_collate_fn)\n",
        "\n",
        "# Record sep positions for dev dataset (to be used for early stopping during training)\n",
        "dev_sep_positions = get_sep_positions(dev_loader, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "N-KwKMBsULGd"
      },
      "outputs": [],
      "source": [
        "# Unit tests for building context assuming a window\n",
        "mock_train_context, mock_train_multi_sentence_labels = context_builder(train_data, left_context_size = 1, right_context_size = 1)\n",
        "mock_dev_context, mock_dev_multi_sentence_labels = context_builder(dev_data, left_context_size = 1, right_context_size = 1)\n",
        "mock_train_dataset = SustainableDataset(tokenizer, train_data, mock_train_context, mock_train_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "mock_dev_dataset = SustainableDataset(tokenizer, dev_data, mock_dev_context, mock_dev_multi_sentence_labels, max_paragraph_length = max_paragraph_length, global_target_sentence_index = global_target_sentence_index)\n",
        "assert mock_train_dataset.contexts[11] == [mock_train_dataset.texts[10], mock_train_dataset.texts[11], mock_train_dataset.texts[12]]  #random corpus context\n",
        "assert len(mock_train_dataset.contexts) == len(mock_train_dataset.texts) #there is a context for every target sentence in the train set\n",
        "assert mock_dev_dataset.contexts[11] == [mock_dev_dataset.texts[10], mock_dev_dataset.texts[11], dev_dataset.texts[12]] #random corpus context\n",
        "assert len(mock_dev_dataset.contexts) == len(mock_dev_dataset.texts) #there is a context for every target sentence in the dev set\n",
        "assert [mock_train_dataset.texts[0], mock_train_dataset.texts[1] , mock_train_dataset.texts[2]] ==  mock_train_dataset.contexts[1] #the context for the first sentence in the corpus is only the following sentence\n",
        "assert [mock_train_dataset.texts[-2] , mock_train_dataset.texts[-1]] == mock_train_dataset.contexts[-1] #the context for the last sentence in the corpus is only the preceding sentence\n",
        "assert [mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)] , mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)+1]]== mock_train_dataset.contexts[mock_train_dataset.report_nos.index(1)] # first sentence of second report should have a context of only its following sentence\n",
        "assert [mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)-2], mock_train_dataset.texts[mock_train_dataset.report_nos.index(1)-1]] == mock_train_dataset.contexts[mock_train_dataset.report_nos.index(1)-1] # last sentence of first report should have a context of only its preceding sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5Fyf-E4gtB90"
      },
      "outputs": [],
      "source": [
        "# Unit tests -> check if assisted data labelling has been performed correctly\n",
        "assert len(set(pre_labeled_train_data['positions']).intersection(set(train_data['positions']))) == 0 \n",
        "assert (len(train_data['texts']) + len(pre_labeled_train_data['texts'])) == len(training_data)\n",
        "assert set(pre_labeled_train_data['positions']).union(set(train_data['positions'])) == set(range(len(training_data)))\n",
        "assert (len(dev_data['texts']) + len(pre_labeled_dev_data['texts'])) == len(development_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NUOfidVU_zE8"
      },
      "outputs": [],
      "source": [
        "class Sustainable_BERT(BertPreTrainedModel):\n",
        "    \"\"\" Transformer model class with custom output layer for fine-tuning.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.projection = torch.nn.Sequential(torch.nn.Dropout(0.1), torch.nn.Linear(config.hidden_size, 5))               \n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None):\n",
        " \n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        logits = F.log_softmax(self.projection(outputs.last_hidden_state), dim = 2)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "O2aWTy5uAHGj"
      },
      "outputs": [],
      "source": [
        "class Trainer_Sustainable(Trainer):\n",
        "    \"\"\" Class inheriting from Trainer to configure loss function used.\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss(self, model, inputs, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length, return_outputs=False):\n",
        "\n",
        "        labels = inputs.pop('labels')\n",
        "        sep_positions = inputs.pop('sep_positions') # take all sep positions\n",
        "        outputs = model(**inputs)\n",
        "        batch_preds = []\n",
        "        for i, sep_position in zip(range(outputs.shape[0]), sep_positions):\n",
        "            batch_preds.append(outputs[i,sep_position,:])\n",
        "\n",
        "        preds = torch.cat(batch_preds).reshape(-1,5)\n",
        "\n",
        "        loss = nn.NLLLoss() \n",
        " \n",
        "        loss = loss(preds, labels)\n",
        "        \n",
        "        if return_outputs: \n",
        "            return (loss, (loss, outputs)) \n",
        "        else:\n",
        "            return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oxRyedCktB91"
      },
      "outputs": [],
      "source": [
        "def model_predict(model, tokenizer, dataloader, device, global_target_sentence_index, max_paragraph_length):\n",
        "    \"\"\" Utility function to set the model to GPU and infer of given dataloader.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch_sequences = []\n",
        "            batch_sep_positions = []\n",
        "            batch_token_type_ids = []\n",
        "            for sequence_list in batch['contexts']:\n",
        "              augmented_sequence = ''\n",
        "              for sentence in sequence_list:\n",
        "                  augmented_sequence += '[SEP]' + sentence\n",
        "              augmented_sequence.strip()\n",
        "              batch_sequences.append(augmented_sequence)\n",
        "            encoded_batch = tokenizer(batch_sequences, padding='longest', truncation=True, max_length=512, return_tensors='pt').to(device)\n",
        "            for encoded_sequence in encoded_batch['input_ids']:\n",
        "                sep_positions = [index for index in range(len(encoded_sequence)) if encoded_sequence[index]==102]\n",
        "                while len(sep_positions) < max_paragraph_length + 1: # repeat last sep position to get full sequence \n",
        "                  sep_positions.append(sep_positions[-1])\n",
        "                batch_sep_positions.append(sep_positions[global_target_sentence_index])\n",
        "                if global_target_sentence_index in range(len(sep_positions)-1): # check to see that the target sentence is actually part of the context\n",
        "                  custom_token_type_ids = [ 1 if index in range(sep_positions[global_target_sentence_index], sep_positions[global_target_sentence_index+1]+1) else 0 for index in range(len(encoded_sequence))]\n",
        "                else:\n",
        "                  custom_token_type_ids = [1 for index in range(len(encoded_sequence))]\n",
        "                batch_token_type_ids.append(custom_token_type_ids)\n",
        "            \n",
        "            encoded_batch['token_type_ids'] = torch.tensor(batch_token_type_ids).to(device)\n",
        "            output = model(**encoded_batch) \n",
        "            target_sep_preds = [output[i,j] for i,j in zip(range(output.shape[0]), batch_sep_positions)]\n",
        "            preds = [torch.argmax(prediction).cpu().detach().item() for prediction in target_sep_preds]\n",
        "            predictions.extend(preds)\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8ec4c29591b04f3194533395ea1bcbb3",
            "42c40e63b603486999b0ccbf3642c558",
            "4c220e54afdf4346a3eabcd300fabcd6",
            "821fd93444b34735a8726373b586214d",
            "a856f8f9da894d998d0ea8647acf26ca",
            "87977b14817d420a9db166528706e93e",
            "6072ba9d5e2445dba39b7a182eb3dca5",
            "884a992e98a74e1fbc2e2bd4ecdfcd04",
            "a2e58fc8af214042bcb130736847b3e2",
            "2eef0ef010d24fdb9455db7381758425",
            "bfc1a7e230c84d649d8610284b2911ad",
            "c229492433f1451d84463b7c026117ec",
            "8d4558989b854b14a39cd0d5cccb1d7b",
            "808d8586113b4cb888bdc16533010a4d",
            "9665c47056294b859a21a0062e771c62",
            "ea9953c4f21e4345bbffd61e52e9a862",
            "80acac8663ed4b1aa4a38d97540c40bd",
            "11d980fc7e0f46ceb394f073034bbfe1",
            "30e42fb7b1334f91a3b00dc100993ea7",
            "65df527c5a5e4b2fa64f5a463cfb1656",
            "ba6f082e2273467ab6179a641da8cee1",
            "c3327224ff974a3290d3f875c49271de"
          ]
        },
        "id": "8MJmka-LAYIV",
        "outputId": "b8c26495-e239-4696-d6d3-a7620a3951e9",
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ec4c29591b04f3194533395ea1bcbb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing Sustainable_BERT: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing Sustainable_BERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Sustainable_BERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Sustainable_BERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['projection.1.weight', 'projection.1.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c229492433f1451d84463b7c026117ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.96k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 36920\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 23070\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23070' max='23070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23070/23070 1:04:02, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.461800</td>\n",
              "      <td>0.367263</td>\n",
              "      <td>0.212919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.325700</td>\n",
              "      <td>0.333414</td>\n",
              "      <td>0.294696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.257300</td>\n",
              "      <td>0.398820</td>\n",
              "      <td>0.295845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.188400</td>\n",
              "      <td>0.508757</td>\n",
              "      <td>0.312626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.131000</td>\n",
              "      <td>0.616877</td>\n",
              "      <td>0.320198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.092400</td>\n",
              "      <td>0.698087</td>\n",
              "      <td>0.312930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.748401</td>\n",
              "      <td>0.309670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.038000</td>\n",
              "      <td>0.811674</td>\n",
              "      <td>0.309039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.027400</td>\n",
              "      <td>0.832385</td>\n",
              "      <td>0.305547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.017300</td>\n",
              "      <td>0.864540</td>\n",
              "      <td>0.307791</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-2307\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-2307/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-2307/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-9348] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-4614\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-4614/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-4614/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-11685] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-6921\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-6921/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-6921/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-2307] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-9228\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-9228/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-9228/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-4614] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-11535\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-11535/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-11535/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-6921] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-13842\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-13842/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-13842/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-9228] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-16149\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-16149/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-16149/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-13842] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-18456\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-18456/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-18456/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-16149] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-20763\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-20763/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-20763/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-18456] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20402\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to BERT_IOBES_no_context_paper/checkpoint-23070\n",
            "Configuration saved in BERT_IOBES_no_context_paper/checkpoint-23070/config.json\n",
            "Model weights saved in BERT_IOBES_no_context_paper/checkpoint-23070/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT_IOBES_no_context_paper/checkpoint-20763] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from BERT_IOBES_no_context_paper/checkpoint-11535 (score: 0.3201975213065153).\n",
            "Saving model checkpoint to final_BERT_IOBES_no_context_paper\n",
            "Configuration saved in final_BERT_IOBES_no_context_paper/config.json\n",
            "Model weights saved in final_BERT_IOBES_no_context_paper/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "# Instantiate and train model\n",
        "model = Sustainable_BERT.from_pretrained('bert-base-uncased').to(device) \n",
        "\n",
        "total_epochs = 10 \n",
        "learning_rate = 1e-5 \n",
        "\n",
        "# Create evaluation metric F1 score \n",
        "metric = load_metric('f1')\n",
        "\n",
        "def compute_metrics(eval_pred, sep_positions = dev_sep_positions, global_target_sentence_index = global_target_sentence_index):\n",
        "    raw_predictions, raw_labels = eval_pred \n",
        "    pooled_predictions = []\n",
        "    for i, sep_position in zip(range(len(raw_predictions)), sep_positions):\n",
        "       pooled_predictions.append(np.argmax(np.array(raw_predictions[i,sep_position])))   \n",
        "    return metric.compute(predictions=pooled_predictions, references=raw_labels, average = 'macro')\n",
        "\n",
        "# Define optimizer and lr schedule\n",
        "optimizer = transformers.AdamW(model.parameters(),\n",
        "                  lr = learning_rate, \n",
        "                  )\n",
        "\n",
        "total_steps = len(train_loader) * total_epochs \n",
        "warmup = 0.06 * total_steps\n",
        " \n",
        "# Create the learning rate scheduler.\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup, \n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "# Create training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='BERT_IOBES_no_context_paper',\n",
        "    save_total_limit = 2,\n",
        "    learning_rate = learning_rate, \n",
        "    logging_strategy = 'epoch',\n",
        "    per_device_train_batch_size=8, \n",
        "    num_train_epochs = total_epochs, \n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    metric_for_best_model = 'f1',\n",
        "    eval_accumulation_steps=0.1*len(dev_loader),\n",
        "    gradient_accumulation_steps = 2, # effective training batch size of 16\n",
        "    )\n",
        "\n",
        "# Define trainer module\n",
        "trainer = Trainer_Sustainable(\n",
        "    model=model,                         \n",
        "    args=training_args,                 \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,                   \n",
        "    data_collator=train_dataset.collate_fn,\n",
        "    callbacks =[transformers.EarlyStoppingCallback(early_stopping_patience = 5, early_stopping_threshold=-0.03)],\n",
        "    compute_metrics = compute_metrics,\n",
        "    optimizers = (optimizer, scheduler),\n",
        "    )\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model('final_BERT_IOBES_no_context_paper')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nqpGGvvisoJU"
      },
      "outputs": [],
      "source": [
        "def reconcile_mapping(model_data, pre_labeled_data, model_predictions):\n",
        "    \"\"\" Utility function to reconcile mapping between pre-labeled data and model predictions.\n",
        "    params: predictions: list of model predictions\n",
        "            pre_labeled_data: dictionary outputted from reader function\n",
        "    returns: pred_mapping: dict\n",
        "             predictions: dict\n",
        "    \"\"\"\n",
        "    pred_mapping = {}\n",
        "    for dataset_text, text_position, prediction in zip(model_data['texts'], model_data['positions'], model_predictions):\n",
        "        pred_mapping[text_position] = (dataset_text, prediction)\n",
        "\n",
        "    pre_labeled_mapping = {}\n",
        "    for text, pos, label in zip(pre_labeled_data['texts'], pre_labeled_data['positions'], pre_labeled_data['labels']):\n",
        "        pre_labeled_mapping[pos] = (text, label)\n",
        "\n",
        "\n",
        "    pred_mapping.update(pre_labeled_mapping)\n",
        "\n",
        "    pred_mapping = {k: v for k, v in sorted(pred_mapping.items(), key=lambda item: item[0])}\n",
        "\n",
        "    predictions =[element[1] for element in list(pred_mapping.values())] \n",
        "\n",
        "    return pred_mapping, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5i2N8mqKULGh",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create predictions dictionary spanning initiatives\n",
        "def sentence_to_initiative_aggregation(predictions, predictions_report_numbers):\n",
        "    \"\"\" Utility function which takes in a list of IOBES predictions per sentence and aggregates these into a dictionary of initiatives.\n",
        "    params: predictions: list of multi-class predictions\n",
        "    returns: predictions_dict: {initiative_number_report_number:list of sentence positions}\n",
        "    \"\"\"\n",
        "    predictions_dict = {}\n",
        "    initiative_index = 0\n",
        "    prediction_index = 0\n",
        "    while prediction_index < len(predictions):\n",
        "      if predictions[prediction_index] == 0: #no initiative\n",
        "        prediction_index += 1\n",
        "      elif predictions[prediction_index] == 1: #singleton\n",
        "        prediction_span = [prediction_index]\n",
        "        predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "        initiative_index += 1\n",
        "        prediction_index += 1\n",
        "      elif predictions[prediction_index] == 2: #beginning of initiative\n",
        "        if predictions[prediction_index + 1] == 4: # 2 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 2\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 4): #3 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 3\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 3) and (predictions[prediction_index + 3] == 4): #4 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2, prediction_index + 3]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 4\n",
        "        elif (predictions[prediction_index + 1] == 3) and (predictions[prediction_index + 2] == 3) and (predictions[prediction_index + 3] == 3) and (predictions[prediction_index + 4] == 4): #5 sentence initiative\n",
        "          prediction_span = [prediction_index, prediction_index + 1, prediction_index + 2, prediction_index + 3, prediction_index + 3]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 5\n",
        "        else:\n",
        "          prediction_span = [prediction_index]\n",
        "          predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "          initiative_index += 1\n",
        "          prediction_index += 1\n",
        "      else: # all other initiative predictions which do not form a complete BIE structure are labeled as individual singletons\n",
        "        prediction_span = [prediction_index]\n",
        "        predictions_dict[str(initiative_index)+'_'+str(predictions_report_numbers[prediction_index])] = prediction_span\n",
        "        initiative_index += 1\n",
        "        prediction_index += 1\n",
        "\n",
        "    return predictions_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kncs_eEhsoJV"
      },
      "outputs": [],
      "source": [
        "class Initiative_Evaluation():\n",
        "    \"\"\" Class used to evaluate what % of initiatives have been correctly indentified.\n",
        "    \"\"\"\n",
        "    def __init__(self, initiative_dict, predictions_dict):\n",
        "        self.initiative_dict = initiative_dict\n",
        "        self.predictions_dict = predictions_dict\n",
        "        self.no_initiatives = len(self.initiative_dict)\n",
        "    \n",
        "    def evaluate(self):\n",
        "        if len(self.initiative_dict) == len(self.predictions_dict) == 0:\n",
        "            fully_correctly_labeled_proportion =  1\n",
        "            half_correctly_labeled_proportion = 1\n",
        "            min_correctly_labeled_proportion = 1\n",
        "            fully_correct_F1 = 1\n",
        "            half_correct_F1 = 1\n",
        "            min_correct_F1 = 1\n",
        "            return fully_correctly_labeled_proportion, half_correctly_labeled_proportion, min_correctly_labeled_proportion, fully_correct_F1, half_correct_F1, min_correct_F1\n",
        "        else:\n",
        "            # initiatize counters for true positive predictions\n",
        "            fully_correct_TP = 0\n",
        "            half_correct_TP = 0\n",
        "            min_correct_TP = 0\n",
        "            \n",
        "            # initialize lists which contain prediction IDs\\\n",
        "            #  for the first correct prediction encountered across all initatives\n",
        "            fully_correct_double_count = []\n",
        "            half_correct_double_count = []\n",
        "            min_correct_double_count = []\n",
        "\n",
        "            for initiative_ID, initiative_positions_list in self.initiative_dict.items():\n",
        "                # Keep a record of the first prediction id considered to be a success for each initiative\n",
        "                fully_correct_match_pred_ID = []\n",
        "                half_correct_match_pred_ID = []\n",
        "                min_correct_match_pred_ID = []\n",
        "                for prediction_ID, prediction_positions_list in self.predictions_dict.items():\n",
        "                    if set(initiative_positions_list).intersection(prediction_positions_list): #check if the initiative span overlaps with the predicted span\n",
        "                        if (len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) == 1)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) == 1):\n",
        "                                if (len(fully_correct_match_pred_ID) == 0) and (prediction_ID not in fully_correct_double_count): \n",
        "                                    fully_correct_match_pred_ID.append(prediction_ID)\n",
        "                                    fully_correct_TP += 1\n",
        "                        if(len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) >= 0.5)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) >= 0.5):\n",
        "                                if (len(half_correct_match_pred_ID) == 0) and (prediction_ID not in half_correct_double_count):\n",
        "                                    half_correct_match_pred_ID.append(prediction_ID)\n",
        "                                    half_correct_TP += 1\n",
        "                        if(len(set(initiative_positions_list).intersection(prediction_positions_list))/len(initiative_positions_list) > 0)\\\n",
        "                            and (len(set(prediction_positions_list).intersection(initiative_positions_list))/len(prediction_positions_list) > 0):\n",
        "                                if (len(min_correct_match_pred_ID) == 0) and (prediction_ID not in min_correct_double_count): \n",
        "                                        min_correct_match_pred_ID.append(prediction_ID)\n",
        "                                        min_correct_TP += 1\n",
        "                fully_correct_double_count.extend(fully_correct_match_pred_ID)\n",
        "                half_correct_double_count.extend(half_correct_match_pred_ID)\n",
        "                min_correct_double_count.extend(min_correct_match_pred_ID)\n",
        "                        \n",
        "\n",
        "            fully_correct_FN, fully_correct_FP = self.compute_FN_FP(fully_correct_TP)\n",
        "            fully_correct_F1, fully_correct_precision, fully_correct_recall = self.compute_F1(fully_correct_TP, fully_correct_FP, fully_correct_FN)\n",
        "\n",
        "            half_correct_FN, half_correct_FP = self.compute_FN_FP(half_correct_TP)\n",
        "            half_correct_F1, half_correct_precision, half_correct_recall = self.compute_F1(half_correct_TP, half_correct_FP, half_correct_FN)\n",
        "\n",
        "            min_correct_FN, min_correct_FP = self.compute_FN_FP(min_correct_TP)\n",
        "            min_correct_F1, min_correct_precision, min_correct_recall = self.compute_F1(min_correct_TP, min_correct_FP, min_correct_FN)\n",
        "\n",
        "            fully_correctly_labeled_proportion = fully_correct_TP/self.no_initiatives\n",
        "            half_correctly_labeled_proportion = half_correct_TP/self.no_initiatives\n",
        "            min_correctly_labeled_proportion = min_correct_TP/self.no_initiatives\n",
        "            \n",
        "            return fully_correctly_labeled_proportion, half_correctly_labeled_proportion, min_correctly_labeled_proportion, fully_correct_F1, half_correct_F1, min_correct_F1, fully_correct_precision, fully_correct_recall, half_correct_precision, half_correct_recall, min_correct_precision, min_correct_recall\n",
        "    \n",
        "    def compute_F1(self, TP, FP, FN):\n",
        "        \"\"\" Utility method to compute F1 score\n",
        "        \"\"\"\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        if precision == recall == 0:\n",
        "            F1 = 0\n",
        "        else:\n",
        "            F1 = 2 * precision * recall /(precision + recall)\n",
        "        return F1, precision, recall\n",
        "    \n",
        "    def compute_FN_FP(self, TP):\n",
        "        \"\"\" Utility method to compute FN and FP initiatives given the no of TP \n",
        "        (defined as the set intersection between gold initiative span and prediction span)\n",
        "        \"\"\"\n",
        "        FN = len(self.initiative_dict) - TP\n",
        "        FP = len(self.predictions_dict) - TP\n",
        "        return FN, FP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7R7dTM4hULGj"
      },
      "outputs": [],
      "source": [
        "# Unit tests for Initiative_Evaluation Class\n",
        "mock_initiative_dict_1 = {1:[1,2], 2:[3,4]}\n",
        "mock_predictions_dict_1 = {1: [1,2], 2:[3], 3:[4]}\n",
        "mock_evaluation_1 = Initiative_Evaluation(mock_initiative_dict_1, mock_predictions_dict_1)\n",
        "mock_init_strict_accuracy_1, mock_init_medium_accuracy_1, mock_init_lenient_accuracy_1, mock1_fully_correct_F1, mock1_half_correct_F1, mock1_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_1.evaluate()\n",
        "assert mock_init_strict_accuracy_1 == 0.5\n",
        "assert mock_init_medium_accuracy_1 == 1\n",
        "assert mock_init_lenient_accuracy_1 == 1\n",
        "assert mock1_fully_correct_F1 == 0.4\n",
        "assert mock1_half_correct_F1 == mock1_min_correct_F1 == 0.8\n",
        "\n",
        "\n",
        "mock_initiative_dict_2 = {1:[1,2], 2:[4,5,6]}\n",
        "mock_predictions_dict_2 = {1: [1,2], 2:[4,5,6]}\n",
        "mock_evaluation_2 = Initiative_Evaluation(mock_initiative_dict_2, mock_predictions_dict_2)\n",
        "mock_init_strict_accuracy_2, mock_init_medium_accuracy_2, mock_init_lenient_accuracy_2, mock2_fully_correct_F1, mock2_half_correct_F1, mock2_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_2.evaluate()\n",
        "assert mock_init_strict_accuracy_2 == 1\n",
        "assert mock_init_medium_accuracy_2 == 1\n",
        "assert mock_init_lenient_accuracy_2 == 1\n",
        "assert mock2_fully_correct_F1 == mock2_half_correct_F1 == mock2_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_3 = {1:[1,2], 2:[3,4]}\n",
        "mock_predictions_dict_3 = {1: [1,2], 2:[3,4]}\n",
        "mock_evaluation_3 = Initiative_Evaluation(mock_initiative_dict_3, mock_predictions_dict_3)\n",
        "mock_init_strict_accuracy_3, mock_init_medium_accuracy_3, mock_init_lenient_accuracy_3, mock3_fully_correct_F1, mock3_half_correct_F1, mock3_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_3.evaluate()\n",
        "assert mock_init_strict_accuracy_3 == 1\n",
        "assert mock_init_medium_accuracy_3 == 1\n",
        "assert mock_init_lenient_accuracy_3 == 1\n",
        "assert mock3_fully_correct_F1 == mock3_half_correct_F1 == mock3_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_4 = {}\n",
        "mock_predictions_dict_4 = {}\n",
        "mock_evaluation_4 = Initiative_Evaluation(mock_initiative_dict_4, mock_predictions_dict_4)\n",
        "mock_init_strict_accuracy_4, mock_init_medium_accuracy_4, mock_init_lenient_accuracy_4, mock4_fully_correct_F1, mock4_half_correct_F1, mock4_min_correct_F1 = mock_evaluation_4.evaluate()\n",
        "assert mock_init_strict_accuracy_4 == 1\n",
        "assert mock_init_medium_accuracy_4 == 1\n",
        "assert mock_init_lenient_accuracy_4 == 1\n",
        "assert mock4_fully_correct_F1 == mock4_half_correct_F1 == mock4_min_correct_F1 == 1\n",
        "\n",
        "mock_initiative_dict_5 = {1:[1,2], 2:[3,4,5], 3:[6]}\n",
        "mock_predictions_dict_5 = {1:[1], 2:[2], 3:[3], 4:[4], 5:[5]}\n",
        "mock_evaluation_5 = Initiative_Evaluation(mock_initiative_dict_5, mock_predictions_dict_5)\n",
        "mock_init_strict_accuracy_5, mock_init_medium_accuracy_5, mock_init_lenient_accuracy_5, mock5_fully_correct_F1, mock5_half_correct_F1, mock5_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_5.evaluate()\n",
        "assert mock_init_strict_accuracy_5 == 0\n",
        "assert mock_init_medium_accuracy_5 == 1/3\n",
        "assert mock_init_lenient_accuracy_5 == 2/3\n",
        "assert mock5_fully_correct_F1 == 0\n",
        "assert mock5_half_correct_F1 == 0.25\n",
        "assert mock5_min_correct_F1 == 0.5\n",
        "\n",
        "mock_initiative_dict_6 = {1:[1,2], 2:[3,4,5], 3:[6]}\n",
        "mock_predictions_dict_6 = {1:[1,2,3,4,5,6]}\n",
        "mock_evaluation_6 = Initiative_Evaluation(mock_initiative_dict_6, mock_predictions_dict_6)\n",
        "mock_init_strict_accuracy_6, mock_init_medium_accuracy_6, mock_init_lenient_accuracy_6, mock6_fully_correct_F1, mock6_half_correct_F1, mock6_min_correct_F1,_,_,_,_,_,_ = mock_evaluation_6.evaluate()\n",
        "assert mock_init_strict_accuracy_6 == 0\n",
        "assert mock_init_medium_accuracy_6 == 1/3\n",
        "assert mock_init_lenient_accuracy_6 == 1/3\n",
        "assert mock6_fully_correct_F1 == 0\n",
        "assert mock6_half_correct_F1 == mock6_min_correct_F1 == 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM5U12qZtB92",
        "outputId": "aa27585f-2358-44cc-c5ef-0a1d959e95e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file final_BERT_IOBES_no_context_paper/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"Sustainable_BERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.11.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file final_BERT_IOBES_no_context_paper/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing Sustainable_BERT.\n",
            "\n",
            "All the weights of Sustainable_BERT were initialized from the model checkpoint at final_BERT_IOBES_no_context_paper.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Sustainable_BERT for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting results on dev set took 96.33897829055786 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform context predictions on dev dataset\n",
        "start_time = time.time()\n",
        "sustainable_model = Sustainable_BERT.from_pretrained('final_BERT_IOBES_no_context_paper')\n",
        "dev_predictions_list = model_predict(sustainable_model, tokenizer, dev_loader, device, global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on dev set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the dev set\n",
        "dev_pred_mapping, dev_predictions = reconcile_mapping(dev_data, pre_labeled_dev_data, dev_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioIJdeSTtB92",
        "outputId": "c6732c2d-633a-43ce-8112-2bf00940d6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on the Development Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9776    0.9876    0.9825     53854\n",
            "    Singleton     0.3031    0.1726    0.2200       504\n",
            "    Beginning     0.2389    0.1788    0.2045       481\n",
            "       Inside     0.1000    0.0419    0.0591       310\n",
            "          End     0.1696    0.1580    0.1636       481\n",
            "\n",
            "     accuracy                         0.9607     55630\n",
            "    macro avg     0.3578    0.3078    0.3259     55630\n",
            " weighted avg     0.9532    0.9607    0.9567     55630\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract ground truth dev data labels\n",
        "dev_label_values = []\n",
        "dev_report_numbers = []\n",
        "for sent_no in range(len(development_data)):\n",
        "  dev_report_numbers.append(development_data[sent_no][0]['report_no'])\n",
        "  if development_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = development_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(development_data[sent_no][0]['report_no'])\n",
        "    if len(dev_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      dev_label_values.append(development_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif dev_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      dev_label_values.append(2) #append 2 for beginning of initiative\n",
        "    elif dev_initiative_dict[initiative_unique_reference].index(sent_no) == (len(dev_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      dev_label_values.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      dev_label_values.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    dev_label_values.append(development_data[sent_no][2]['has_initiative'])\n",
        "\n",
        "\n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Development Dataset \\n')\n",
        "print(classification_report(dev_label_values, np.array(dev_predictions), target_names = target_names, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkeXSSd8soJW",
        "outputId": "26b4bc62-3e1d-4fb7-f322-87b3f47311c4",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 46.60% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 36.95% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 21.52% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 42.34% \n",
            "\n",
            "Precision score where at least 1 sentence is identified is 38.80% \n",
            "\n",
            "Recall score where at least 1 sentence is identified is 46.60% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 33.58% \n",
            "\n",
            "Precision score where 50% of sentences are identified is 30.77% \n",
            "\n",
            "Recal score where 50% of sentences are identified is 36.95% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 19.56% \n",
            "\n",
            "Precision score where 100% of sentences are identified is 17.92% \n",
            "\n",
            "Recall score where 100% of sentences are identified is 21.52% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "dev_predictions_dict = sentence_to_initiative_aggregation(dev_predictions, dev_report_numbers)\n",
        "dev_init_evaluation = Initiative_Evaluation(dev_initiative_dict, dev_predictions_dict)\n",
        "dev_init_strict_accuracy, dev_init_medium_accuracy, dev_init_lenient_accuracy, dev_strict_F1, dev_medium_F1, dev_lenient_F1, dev_strict_precision, dev_strict_recall, dev_medium_precision, dev_medium_recall, dev_lenient_precision, dev_lenient_recall = dev_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {dev_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {dev_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {dev_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {dev_lenient_F1:.2%} \\n')\n",
        "print(f'Precision score where at least 1 sentence is identified is {dev_lenient_precision:.2%} \\n')\n",
        "print(f'Recall score where at least 1 sentence is identified is {dev_lenient_recall:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {dev_medium_F1:.2%} \\n')\n",
        "print(f'Precision score where 50% of sentences are identified is {dev_medium_precision:.2%} \\n')\n",
        "print(f'Recal score where 50% of sentences are identified is {dev_medium_recall:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {dev_strict_F1:.2%} \\n')\n",
        "print(f'Precision score where 100% of sentences are identified is {dev_strict_precision:.2%} \\n')\n",
        "print(f'Recall score where 100% of sentences are identified is {dev_strict_recall:.2%} \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaqqQmje9pS_",
        "outputId": "3873ae01-8670-42d5-cbe3-1cf4c45c630a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file final_BERT_IOBES_no_context_paper/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"Sustainable_BERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.11.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file final_BERT_IOBES_no_context_paper/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing Sustainable_BERT.\n",
            "\n",
            "All the weights of Sustainable_BERT were initialized from the model checkpoint at final_BERT_IOBES_no_context_paper.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Sustainable_BERT for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting results on test set took 106.21684050559998 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform predictions on test dataset\n",
        "start_time = time.time()\n",
        "sustainable_model = Sustainable_BERT.from_pretrained('final_BERT_IOBES_no_context_paper')\n",
        "test_predictions_list = model_predict(sustainable_model, tokenizer, test_loader, device,  global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on test set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the train set\n",
        "test_pred_mapping, test_predictions = reconcile_mapping(test_data, pre_labeled_test_data, test_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDuhvOaK9pS_",
        "outputId": "415a445e-5f44-4618-d51e-e3e7b7712eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on the Test Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9768    0.9787    0.9777     48175\n",
            "    Singleton     0.2907    0.2444    0.2655       577\n",
            "    Beginning     0.1862    0.1812    0.1837       447\n",
            "       Inside     0.0897    0.0601    0.0720       233\n",
            "          End     0.1330    0.1588    0.1448       447\n",
            "\n",
            "     accuracy                         0.9514     49879\n",
            "    macro avg     0.3353    0.3246    0.3287     49879\n",
            " weighted avg     0.9500    0.9514    0.9507     49879\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_label_values = []\n",
        "test_report_numbers = []\n",
        "for sent_no in range(len(testing_data)):\n",
        "  test_report_numbers.append(testing_data[sent_no][0]['report_no'])\n",
        "  if testing_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = testing_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(testing_data[sent_no][0]['report_no'])\n",
        "    if len(test_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      test_label_values.append(testing_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif test_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      test_label_values.append(2) #append 2 for beginning of initiative\n",
        "    elif test_initiative_dict[initiative_unique_reference].index(sent_no) == (len(test_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      test_label_values.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      test_label_values.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    test_label_values.append(testing_data[sent_no][2]['has_initiative'])\n",
        "\n",
        "\n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Test Dataset \\n')\n",
        "print(classification_report(test_label_values, np.array(test_predictions), target_names = target_names, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZqHPAFU9pS_",
        "outputId": "c80dec95-2435-4510-e56c-1f9f42aecaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 46.19% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 37.60% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 24.51% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 36.87% \n",
            "\n",
            "Precision score where at least 1 sentence is identified is 30.67% \n",
            "\n",
            "Recall score where at least 1 sentence is identified is 46.19% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 30.01% \n",
            "\n",
            "Precision score where 50% of sentences are identified is 24.97% \n",
            "\n",
            "Recal score where 50% of sentences are identified is 37.60% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 19.56% \n",
            "\n",
            "Precision score where 100% of sentences are identified is 16.28% \n",
            "\n",
            "Recall score where 100% of sentences are identified is 24.51% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_predictions_dict = sentence_to_initiative_aggregation(test_predictions, test_report_numbers)\n",
        "test_init_evaluation = Initiative_Evaluation(test_initiative_dict, test_predictions_dict)\n",
        "test_init_strict_accuracy, test_init_medium_accuracy, test_init_lenient_accuracy, test_strict_F1, test_medium_F1, test_lenient_F1, test_strict_precision, test_strict_recall, test_medium_precision, test_medium_recall, test_lenient_precision, test_lenient_recall  = test_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {test_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {test_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {test_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {test_lenient_F1:.2%} \\n')\n",
        "print(f'Precision score where at least 1 sentence is identified is {test_lenient_precision:.2%} \\n')\n",
        "print(f'Recall score where at least 1 sentence is identified is {test_lenient_recall:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {test_medium_F1:.2%} \\n')\n",
        "print(f'Precision score where 50% of sentences are identified is {test_medium_precision:.2%} \\n')\n",
        "print(f'Recal score where 50% of sentences are identified is {test_medium_recall:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {test_strict_F1:.2%} \\n')\n",
        "print(f'Precision score where 100% of sentences are identified is {test_strict_precision:.2%} \\n')\n",
        "print(f'Recall score where 100% of sentences are identified is {test_strict_recall:.2%} \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf2aN65ztB92",
        "outputId": "cdaad578-2050-48ac-88a3-72daafd848f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting results on train set took 144.54099082946777 seconds\n"
          ]
        }
      ],
      "source": [
        "# Perform predictions on train dataset\n",
        "start_time = time.time()\n",
        "train_predictions_list = model_predict(sustainable_model, tokenizer, train_loader, device,  global_target_sentence_index = global_target_sentence_index, max_paragraph_length = max_paragraph_length)\n",
        "end_time = time.time()\n",
        "print(f'Predicting results on train set took {end_time-start_time} seconds')\n",
        "\n",
        "# Reconcile predictions on the train set\n",
        "train_pred_mapping, train_predictions = reconcile_mapping(train_data, pre_labeled_train_data, train_predictions_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daVKMN0stB93",
        "outputId": "b1a3e638-ad39-4060-d03f-841926324ef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report on the Training Dataset \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Initiative     0.9983    0.9987    0.9985     83801\n",
            "    Singleton     0.8993    0.9311    0.9149      1045\n",
            "    Beginning     0.9088    0.8513    0.8791       995\n",
            "       Inside     0.8568    0.6430    0.7347       633\n",
            "          End     0.7810    0.8995    0.8361       995\n",
            "\n",
            "     accuracy                         0.9925     87469\n",
            "    macro avg     0.8888    0.8647    0.8726     87469\n",
            " weighted avg     0.9926    0.9925    0.9924     87469\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_labels = []\n",
        "train_report_numbers = []\n",
        "for sent_no in range(len(training_data)):\n",
        "  train_report_numbers.append(training_data[sent_no][0]['report_no'])\n",
        "  if training_data[sent_no][3]['list_of_initiatives']:\n",
        "    initiative_unique_reference = training_data[sent_no][3]['list_of_initiatives'][0] + '_' + str(training_data[sent_no][0]['report_no'])\n",
        "    if len(train_initiative_dict[initiative_unique_reference]) == 1:\n",
        "      training_labels.append(training_data[sent_no][2]['has_initiative']) # append 1 for singletons or 0 for non-initiative sentences\n",
        "    elif train_initiative_dict[initiative_unique_reference].index(sent_no) == 0:\n",
        "      training_labels.append(2) #append 2 for beginning of initiative\n",
        "    elif train_initiative_dict[initiative_unique_reference].index(sent_no) == (len(train_initiative_dict[initiative_unique_reference]) - 1):\n",
        "      training_labels.append(4) #append 4 for end of initiative\n",
        "    else:\n",
        "      training_labels.append(3) #append 3 for inside an initiative\n",
        "  else:\n",
        "    training_labels.append(training_data[sent_no][2]['has_initiative'])\n",
        "    \n",
        "target_names = ['No Initiative', 'Singleton', 'Beginning', 'Inside', 'End']\n",
        "print(f'Classification Report on the Training Dataset \\n')\n",
        "print(classification_report(training_labels, np.array(train_predictions), target_names = target_names, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY5BwgnLsoJX",
        "outputId": "12e349f5-a3cc-4373-e8f4-89a7b99e3571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of correctly predicted initiatives where at least 1 sentence is identified is 98.14% \n",
            "\n",
            "Percentage of correctly predicted initiatives where more than 50% of sentences are identified is 90.39% \n",
            "\n",
            "Percentage of correctly predicted initiatives where 100% of sentences are identified is 75.69% \n",
            "\n",
            "F1 score where at least 1 sentence is identified is 83.11% \n",
            "\n",
            "F1 score where 50% of sentences are identified is 76.55% \n",
            "\n",
            "F1 score where 100% of sentences are identified is 64.09% \n",
            "\n",
            "Evaluating initiatives on the train set took 2.136638641357422 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "train_predictions_dict = sentence_to_initiative_aggregation(train_predictions, train_report_numbers)\n",
        "train_init_evaluation = Initiative_Evaluation(train_initiative_dict, train_predictions_dict)\n",
        "train_init_strict_accuracy, train_init_medium_accuracy, train_init_lenient_accuracy, train_strict_F1, train_medium_F1, train_lenient_F1, train_strict_precision, train_strict_recall, train_medium_precision, train_medium_recall, train_lenient_precision, train_lenient_recall  = train_init_evaluation.evaluate()\n",
        "\n",
        "print(f'Percentage of correctly predicted initiatives where at least 1 sentence is identified is {train_init_lenient_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where more than 50% of sentences are identified is {train_init_medium_accuracy:.2%} \\n')\n",
        "print(f'Percentage of correctly predicted initiatives where 100% of sentences are identified is {train_init_strict_accuracy:.2%} \\n')\n",
        "print(f'F1 score where at least 1 sentence is identified is {train_lenient_F1:.2%} \\n')\n",
        "print(f'F1 score where 50% of sentences are identified is {train_medium_F1:.2%} \\n')\n",
        "print(f'F1 score where 100% of sentences are identified is {train_strict_F1:.2%} \\n')\n",
        "end_time = time.time()\n",
        "print(f'Evaluating initiatives on the train set took {end_time-start_time} seconds')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BERT_IOBES_no_context_paper.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "83822c0cf896608929095f1043a98f7e1bb9e3e58b660cf90b3c0a24621313f4"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('sustainability': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11d980fc7e0f46ceb394f073034bbfe1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1343fcd335a3476ba658c8920ea11621": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44f892e3241144858e890c2c0c50f0ac",
              "IPY_MODEL_c3059571217b4b81821bab6d01fe3618",
              "IPY_MODEL_d1cd73cbaf58452791541ccbdd6cde7f"
            ],
            "layout": "IPY_MODEL_8193b4bfbe3e40e4a19dbc2160df0b52"
          }
        },
        "15c12dfc37f4477dbd98b451473f18e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1837c22ecfb5420088aaf568198c007a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28b4269a46a542b39edcce4ebe038c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eef0ef010d24fdb9455db7381758425": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30e42fb7b1334f91a3b00dc100993ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34d83819b828451385b91c5dcd7eecbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379457ed3a3e4ee0886058e1e9152088": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c40e63b603486999b0ccbf3642c558": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f892e3241144858e890c2c0c50f0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbe58c2a7e5446a193292dd6384f5c33",
            "placeholder": "​",
            "style": "IPY_MODEL_b687e57010f84f8c992240cf5d2a8ebc",
            "value": "Downloading: 100%"
          }
        },
        "4c220e54afdf4346a3eabcd300fabcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6072ba9d5e2445dba39b7a182eb3dca5",
            "placeholder": "​",
            "style": "IPY_MODEL_87977b14817d420a9db166528706e93e",
            "value": "Downloading: 100%"
          }
        },
        "556db7b225484cbd940b3ecc33d8e556": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7121c23d2cd4579a45f7491144440c0",
              "IPY_MODEL_ae5f8d7612a749279caddfc9aba0f7a9",
              "IPY_MODEL_a50d69ce06c6415aac7afcca1417c7e1"
            ],
            "layout": "IPY_MODEL_8a4af21e3b654017845b51ce67039fee"
          }
        },
        "56d4171a9adb4698819f2705bbc5aebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59f8b008512d4ff3ad8426ace743980d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6e8b206a404049bf91a0216b0c0b68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605a3800aef9494eb9069f3b4d9a25a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6072ba9d5e2445dba39b7a182eb3dca5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64bbaa9deaac49ceb783dcae5fcf91b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65df527c5a5e4b2fa64f5a463cfb1656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b3ccb26b9894030ba9db958abec970f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_effcd29d85f644e1a2dc861e55e69cee",
              "IPY_MODEL_75be063e64444fc7afe06cfc787fa3e0",
              "IPY_MODEL_6fc7b13bd91f4c7fbd2157699dd9deed"
            ],
            "layout": "IPY_MODEL_34d83819b828451385b91c5dcd7eecbc"
          }
        },
        "6dfe963778eb48d68b829b761adc5b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fc7b13bd91f4c7fbd2157699dd9deed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_605a3800aef9494eb9069f3b4d9a25a8",
            "placeholder": "​",
            "style": "IPY_MODEL_ce4c66aefc724a479e63c532e5e729a9",
            "value": " 226k/226k [00:00&lt;00:00, 235kB/s]"
          }
        },
        "73f6281d1f8d4f94b3a41c019d00255e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75be063e64444fc7afe06cfc787fa3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4ae4f48453b4709a0c811d658296ba9",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79e2b1671c234369b99c9c61d2737e69",
            "value": 231508
          }
        },
        "79e2b1671c234369b99c9c61d2737e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "808d8586113b4cb888bdc16533010a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11d980fc7e0f46ceb394f073034bbfe1",
            "placeholder": "​",
            "style": "IPY_MODEL_80acac8663ed4b1aa4a38d97540c40bd",
            "value": "Downloading: "
          }
        },
        "80acac8663ed4b1aa4a38d97540c40bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8193b4bfbe3e40e4a19dbc2160df0b52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821fd93444b34735a8726373b586214d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2e58fc8af214042bcb130736847b3e2",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_884a992e98a74e1fbc2e2bd4ecdfcd04",
            "value": 440473133
          }
        },
        "87977b14817d420a9db166528706e93e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "884a992e98a74e1fbc2e2bd4ecdfcd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a4af21e3b654017845b51ce67039fee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b1e2a8f036b471ea2e8d568607f9f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d4558989b854b14a39cd0d5cccb1d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d6b062d9b784b77bed33dc31dc3680f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec4c29591b04f3194533395ea1bcbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c220e54afdf4346a3eabcd300fabcd6",
              "IPY_MODEL_821fd93444b34735a8726373b586214d",
              "IPY_MODEL_a856f8f9da894d998d0ea8647acf26ca"
            ],
            "layout": "IPY_MODEL_42c40e63b603486999b0ccbf3642c558"
          }
        },
        "9665c47056294b859a21a0062e771c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65df527c5a5e4b2fa64f5a463cfb1656",
            "max": 1957,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30e42fb7b1334f91a3b00dc100993ea7",
            "value": 1957
          }
        },
        "9a51274f4b8c47e08a6feea18974119b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b99d267c18340edbfebaaff5e93ff40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cafb33d5384c5dae64670463784a75",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c810babecd1d4bacb842f3c58aa3242f",
            "value": 466062
          }
        },
        "9e02ad13080f4a84b53c70c8be229d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59f8b008512d4ff3ad8426ace743980d",
            "placeholder": "​",
            "style": "IPY_MODEL_64bbaa9deaac49ceb783dcae5fcf91b5",
            "value": "Downloading: 100%"
          }
        },
        "a2e58fc8af214042bcb130736847b3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50d69ce06c6415aac7afcca1417c7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ca2d5222234fbf85b4afebaf8879f6",
            "placeholder": "​",
            "style": "IPY_MODEL_8b1e2a8f036b471ea2e8d568607f9f12",
            "value": " 28.0/28.0 [00:00&lt;00:00, 822B/s]"
          }
        },
        "a5130127ff9f4fb2a51b1d8ed813c4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7121c23d2cd4579a45f7491144440c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15c12dfc37f4477dbd98b451473f18e6",
            "placeholder": "​",
            "style": "IPY_MODEL_a5130127ff9f4fb2a51b1d8ed813c4bb",
            "value": "Downloading: 100%"
          }
        },
        "a856f8f9da894d998d0ea8647acf26ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfc1a7e230c84d649d8610284b2911ad",
            "placeholder": "​",
            "style": "IPY_MODEL_2eef0ef010d24fdb9455db7381758425",
            "value": " 420M/420M [00:08&lt;00:00, 51.4MB/s]"
          }
        },
        "aba52250d50c4ba88c5da24b335b858a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae5f8d7612a749279caddfc9aba0f7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56d4171a9adb4698819f2705bbc5aebc",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dfe963778eb48d68b829b761adc5b17",
            "value": 28
          }
        },
        "b287f079e51e4d39954ddfaf6ab8da39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b687e57010f84f8c992240cf5d2a8ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba6f082e2273467ab6179a641da8cee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfc1a7e230c84d649d8610284b2911ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c229492433f1451d84463b7c026117ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_808d8586113b4cb888bdc16533010a4d",
              "IPY_MODEL_9665c47056294b859a21a0062e771c62",
              "IPY_MODEL_ea9953c4f21e4345bbffd61e52e9a862"
            ],
            "layout": "IPY_MODEL_8d4558989b854b14a39cd0d5cccb1d7b"
          }
        },
        "c3059571217b4b81821bab6d01fe3618": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_379457ed3a3e4ee0886058e1e9152088",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b287f079e51e4d39954ddfaf6ab8da39",
            "value": 570
          }
        },
        "c3327224ff974a3290d3f875c49271de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ae4f48453b4709a0c811d658296ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c810babecd1d4bacb842f3c58aa3242f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8cafb33d5384c5dae64670463784a75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce4c66aefc724a479e63c532e5e729a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1cd73cbaf58452791541ccbdd6cde7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aba52250d50c4ba88c5da24b335b858a",
            "placeholder": "​",
            "style": "IPY_MODEL_1837c22ecfb5420088aaf568198c007a",
            "value": " 570/570 [00:00&lt;00:00, 17.8kB/s]"
          }
        },
        "d26b25291f5a4b18808e492bdd108c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c6e8b206a404049bf91a0216b0c0b68",
            "placeholder": "​",
            "style": "IPY_MODEL_28b4269a46a542b39edcce4ebe038c62",
            "value": " 455k/455k [00:00&lt;00:00, 406kB/s]"
          }
        },
        "d6ca2d5222234fbf85b4afebaf8879f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea9953c4f21e4345bbffd61e52e9a862": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3327224ff974a3290d3f875c49271de",
            "placeholder": "​",
            "style": "IPY_MODEL_ba6f082e2273467ab6179a641da8cee1",
            "value": " 4.64k/? [00:00&lt;00:00, 133kB/s]"
          }
        },
        "effcd29d85f644e1a2dc861e55e69cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a51274f4b8c47e08a6feea18974119b",
            "placeholder": "​",
            "style": "IPY_MODEL_73f6281d1f8d4f94b3a41c019d00255e",
            "value": "Downloading: 100%"
          }
        },
        "f29db967817c4012a2dd4fe5eb807e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e02ad13080f4a84b53c70c8be229d90",
              "IPY_MODEL_9b99d267c18340edbfebaaff5e93ff40",
              "IPY_MODEL_d26b25291f5a4b18808e492bdd108c41"
            ],
            "layout": "IPY_MODEL_8d6b062d9b784b77bed33dc31dc3680f"
          }
        },
        "fbe58c2a7e5446a193292dd6384f5c33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
